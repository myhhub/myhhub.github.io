<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="https://www.ljjyy.com">
    <!--SEO-->

    <meta name="keywords" content="知识图谱,stanfordnlp,opennre,tensorflow">


    <meta name="description" content="一. 简介 在数据爬取过程中，想尝试复现一个经典的神经网络关系抽取模型。经过看论文筛选最终确定清华的Neural Relation Extraction with Selective Atten...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>从零开始学习知识图谱 之 九.百科知识图谱构建 3.基于TensorFlow神经网络关系抽取的数据集构建(使用OpenNRE) | 来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</title>


    <link rel="alternate" href="/atom.xml" title="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
        <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
        <script>LA.init({id: "JgbNOaw1xxsmUUsQ",ck: "JgbNOaw1xxsmUUsQ"})</script>
	</div>






    
    <meta name="baidu-site-verification" content="dTHILoORpx">


    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  >
    <div class="main-header-box">
        <!--a class="header-avatar" href="/" title='Ljjyy.com'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a-->
        <div class="branding">
            
                <h2> 多读书多实践，勤思考善领悟 </h2>
            
    	  </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">

        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="web-logo"  href="/" title='Ljjyy.com'></a>
                    <!--a class="navbar-brand" href="https://www.ljjyy.com">来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</a-->
                </div>
                <div class="collapse navbar-collapse" id="main-menu" style="">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/cloud/"><i class="fa "></i>云计算</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/front/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/back/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/devops/"><i class="fa "></i>运维</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/crack/"><i class="fa "></i>破解</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/penetration/"><i class="fa "></i>渗透</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tool/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/other/"><i class="fa "></i>其他</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="从零开始学习知识图谱 之 九.百科知识图谱构建 3.基于TensorFlow神经网络关系抽取的数据集构建(使用OpenNRE)">
            
	            从零开始学习知识图谱 之 九.百科知识图谱构建 3.基于TensorFlow神经网络关系抽取的数据集构建(使用OpenNRE)
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/cloud/">云计算</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/opennre/">opennre</a> <a class="tag-link" href="/tags/stanfordnlp/">stanfordnlp</a> <a class="tag-link" href="/tags/tensorflow/">tensorflow</a> <a class="tag-link" href="/tags/knowledgegraph/">知识图谱</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/10/28</span>
        </span>
        
    
</div>
            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>1260</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <h1 id="一-简介"><a href="#一-简介" class="headerlink" title="一. 简介"></a>一. 简介</h1><p> 在数据爬取过程中，想尝试复现一个经典的神经网络关系抽取模型。经过看论文筛选最终确定清华的<a href="http://www.aclweb.org/anthology/P16-1200" target="_blank" rel="noopener">Neural Relation Extraction with Selective Attention over Instances</a>。但在看了开源的代码后感觉自己现在造一遍轮子也不如人家的…因此就按照NYT的论文描述做了一个远程监督数据集，并在<a href="https://github.com/thunlp/OpenNRE/tree/modelrefine" target="_blank" rel="noopener">OpenNRE</a> 上跑了一遍。 </p>
<p>本教程的项目代码放在github上，下载地址为<a href="https://github.com/myhhub/zero_knowledge_graph" target="_blank" rel="noopener">《从零开始学习知识图谱》项目源代码</a> 。</p>
<h1 id="二-环境准备"><a href="#二-环境准备" class="headerlink" title="二. 环境准备"></a>二. 环境准备</h1><h2 id="1-操作系统"><a href="#1-操作系统" class="headerlink" title="1. 操作系统"></a>1. 操作系统</h2><p>支持操作系统：windows、macOS、Linux。为了方便大家搭建开发环境，笔者尽可能在windows下构建，系列篇未特意说明时操作系统都是<strong>windows</strong>。Linux安装可以参考<a href="100590.html">VirtualBox虚拟机安装Ubuntu</a>或<a href="100589.html">VirtualBox虚拟机安装CentOS8</a>进行安装。</p>
<h2 id="2-jdk"><a href="#2-jdk" class="headerlink" title="2. jdk"></a>2. jdk</h2><p>安装参见<a href="100604.html">windows系统安装JDK</a></p>
<h2 id="3-Python3"><a href="#3-Python3" class="headerlink" title="3. Python3"></a>3. Python3</h2><p>安装参见<a href="100591.html#4-Python3">从零开始学习知识图谱 之 一</a></p>
<h2 id="4-Stanford-NLP"><a href="#4-Stanford-NLP" class="headerlink" title="4. Stanford NLP"></a>4. Stanford NLP</h2><p>Stanford NLP 团队发布了包含 53 种语言预训练模型的自然语言处理工具包 StanfordNLP，该工具包支持 Python 3.6 及之后版本，并基于 PyTorch，支持多种语言的完整文本分析管道，包括分词、词性标注、词形归并和依存关系解析，此外它还提供了与 CoreNLP 的 Python 接口。 </p>
<p>StanfordCoreNLP提供了一系列用于自然语言的技术工具。它可以给出不管是公司名还是人名亦或标准化日期、时间和数量等单词的基本形式，词性等。如下图所示它还可以根据短语和句法依存关系标记句子结构，指明哪些名词短语表示相同的实体，指明情感，提取实体及之间的特定或开放类关系，获取名人名言等等。</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>1）首先从<a href="https://stanfordnlp.github.io/CoreNLP/download.html" target="_blank" rel="noopener">stanford NLP网页</a>下载两个包，分别是<a href="https://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip" target="_blank" rel="noopener">stanford-corenlp-full-2018-10-05.zip</a>和中文处理包<a href="http://nlp.stanford.edu/software/stanford-chinese-corenlp-2018-10-05-models.jar" target="_blank" rel="noopener">stanford-chinese-corenlp-2018-10-05-models.jar</a>，下载后解压stanford-corenlp-full-2018-10-05.zip压缩包,然后将stanford-chinese-corenlp-2018-10-05-models.jar放入解压文件夹中。</p>
<p>2) 安装Python的stanfordnlp库，在命令提示符中切换到安装Python的路径的Scripts文件夹下执行命令<code>pip install stanfordnlp</code>、<code>pip install stanforcorednlp</code>, 安装完成后就可以开始使用了。 </p>
<figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:<span class="symbol">\m</span>y<span class="symbol">\P</span>ython<span class="symbol">\S</span>cripts&gt;pip install stanfordnlp</span><br><span class="line">C:<span class="symbol">\m</span>y<span class="symbol">\P</span>ython<span class="symbol">\S</span>cripts&gt;pip install stanforcorednlp</span><br></pre></td></tr></table></figure>
<p> <code>pip install stanforcorednlp</code> 命令一直安装不了，最后使用下面这条镜像命令就可以安装了，被墙了。  选择USTC镜像安装（安装速度很快，毕竟国内镜像）：<code>pip install stanfordcorenlp -i http://pypi.mirrors.ustc.edu.cn/simple/ --trusted-host pypi.mirrors.ustc.edu.cn</code></p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">C:</span>\my\Python\Scripts&gt;pip install stanfordcorenlp -i <span class="symbol">http:</span>/<span class="regexp">/pypi.mirrors.ustc.edu.cn/simple</span><span class="regexp">/ --trusted-host pypi.mirrors.ustc.edu.cn</span></span><br><span class="line"><span class="regexp"></span></span><br><span class="line"><span class="regexp">Looking in indexes: http:/</span><span class="regexp">/pypi.mirrors.ustc.edu.cn/simple</span><span class="regexp">/</span></span><br><span class="line"><span class="regexp">WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError("HTTPSConnectionPool(host='mirrors.ustc.edu.cn', port=443): Read timed out. (read timeout=15)")': /pypi</span><span class="regexp">/web/simple</span><span class="regexp">/stanfordcorenlp/</span></span><br><span class="line">Collecting stanfordcorenlp</span><br><span class="line">  Downloading <span class="symbol">https:</span>/<span class="regexp">/mirrors.tuna.tsinghua.edu.cn/pypi</span><span class="regexp">/web/packages</span><span class="regexp">/35/cb</span><span class="regexp">/0a271890bbe3a77fc1aca2bc3a58b14e11799ea77cb5f7d6fb0a8b4c46fa/stanfordcorenlp</span>-<span class="number">3.9</span>.<span class="number">1.1</span>-py2.py3-none-any.whl</span><br><span class="line">Requirement already <span class="symbol">satisfied:</span> requests in <span class="symbol">c:</span>\my\python\<span class="class"><span class="keyword">lib</span>\<span class="title">site</span>-<span class="title">packages</span> (<span class="title">from</span> <span class="title">stanfordcorenlp</span>) (2.22.0)</span></span><br><span class="line">Collecting psutil</span><br><span class="line">  Downloading <span class="symbol">https:</span>/<span class="regexp">/mirrors.tuna.tsinghua.edu.cn/pypi</span><span class="regexp">/web/packages</span><span class="regexp">/7c/</span><span class="number">58</span>/f5d68ddca37480d8557b8566a20bf6108d7e1c6c9b9208ee0786e0cd012b/psutil-<span class="number">5.6</span>.<span class="number">3</span>-cp37-cp37m-win_amd64.whl (<span class="number">234</span>kB)</span><br><span class="line">     |████████████████████████████████| <span class="number">235</span>kB <span class="number">467</span>kB/s</span><br><span class="line">Requirement already <span class="symbol">satisfied:</span> urllib3!=<span class="number">1.25</span>.<span class="number">0</span>,!=<span class="number">1.25</span>.<span class="number">1</span>,&lt;<span class="number">1.26</span>,&gt;=<span class="number">1.21</span>.<span class="number">1</span> in <span class="symbol">c:</span>\my\python\<span class="class"><span class="keyword">lib</span>\<span class="title">site</span>-<span class="title">packages</span> (<span class="title">from</span> <span class="title">requests</span>-&gt;<span class="title">stanfordcorenlp</span>) (1.25.6)</span></span><br><span class="line">Requirement already <span class="symbol">satisfied:</span> idna&lt;<span class="number">2.9</span>,&gt;=<span class="number">2.5</span> in <span class="symbol">c:</span>\my\python\<span class="class"><span class="keyword">lib</span>\<span class="title">site</span>-<span class="title">packages</span> (<span class="title">from</span> <span class="title">requests</span>-&gt;<span class="title">stanfordcorenlp</span>) (2.8)</span></span><br><span class="line">Requirement already <span class="symbol">satisfied:</span> certifi&gt;=<span class="number">2017.4</span>.<span class="number">17</span> in <span class="symbol">c:</span>\my\python\<span class="class"><span class="keyword">lib</span>\<span class="title">site</span>-<span class="title">packages</span> (<span class="title">from</span> <span class="title">requests</span>-&gt;<span class="title">stanfordcorenlp</span>) (2019.9.11)</span></span><br><span class="line">Requirement already <span class="symbol">satisfied:</span> chardet&lt;<span class="number">3.1</span>.<span class="number">0</span>,&gt;=<span class="number">3.0</span>.<span class="number">2</span> in <span class="symbol">c:</span>\my\python\<span class="class"><span class="keyword">lib</span>\<span class="title">site</span>-<span class="title">packages</span> (<span class="title">from</span> <span class="title">requests</span>-&gt;<span class="title">stanfordcorenlp</span>) (3.0.4)</span></span><br><span class="line">Installing collected <span class="symbol">packages:</span> psutil, stanfordcorenlp</span><br><span class="line">Successfully installed psutil-<span class="number">5.6</span>.<span class="number">3</span> stanfordcorenlp-<span class="number">3.9</span>.<span class="number">1.1</span></span><br></pre></td></tr></table></figure>
<p>3) 在Python中引用模型，执行下面语句： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> stanfordcorenlp <span class="keyword">import</span> StanfordCoreNLP</span><br><span class="line">nlp=StanfordCoreNLP(<span class="string">r'C:\my\stanford-corenlp'</span>,lang=<span class="string">'zh'</span>)</span><br></pre></td></tr></table></figure>
<p>4) 启动服务</p>
<p> Stanford CoreNLP附带一个内置服务器，该服务器仅需要CoreNLP依赖项。要运行此服务器，只需运行：<br> <figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run the server using all jars in the current directory (e.g., the CoreNLP home directory)</span></span><br><span class="line">java -mx4g -cp <span class="string">"*"</span> edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port <span class="number">9000</span> -<span class="keyword">timeout</span> <span class="number">15000</span></span><br></pre></td></tr></table></figure></p>
<p><strong>请注意，超时时间以毫秒为单位。</strong></p>
<p>如果要处理非英语语言，请将此命令与适当的语言属性一起使用，下面为中文语言：<br><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># <span class="selector-tag">Run</span> <span class="selector-tag">a</span> <span class="selector-tag">server</span> <span class="selector-tag">using</span> <span class="selector-tag">Chinese</span> <span class="selector-tag">properties</span></span><br><span class="line"><span class="selector-tag">java</span> <span class="selector-tag">-Xmx4g</span> <span class="selector-tag">-cp</span> "*" <span class="selector-tag">edu</span><span class="selector-class">.stanford</span><span class="selector-class">.nlp</span><span class="selector-class">.pipeline</span><span class="selector-class">.StanfordCoreNLPServer</span> <span class="selector-tag">-serverProperties</span> <span class="selector-tag">StanfordCoreNLP-chinese</span><span class="selector-class">.properties</span> <span class="selector-tag">-port</span> 9000 <span class="selector-tag">-timeout</span> 15000</span><br></pre></td></tr></table></figure></p>
<p>如果未<code>port</code>提供的值，则默认使用端口9000。然后，您可以通过访问来测试服务器。</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">http:</span><span class="comment">//localhost:9000/</span></span><br></pre></td></tr></table></figure>
<h2 id="5-word2vec"><a href="#5-word2vec" class="headerlink" title="5. word2vec"></a>5. word2vec</h2><p>word2vec是Google在2013年提出的一款开源工具，其是一个Deep Learning(深度学习)模型（实际上该模型层次较浅，严格上还不能算是深层模型，如果word2vec上层再套一层与具体应用相关的输出层，如Softmax，便更像是一个深层模型），它将词表征成实数值向量，采用CBOW（Continuous Bag-Of-Words Model，连续词袋模型）和Skip-Gram(Continuous Skip-GramModel)两种模型。具体原理，网上有很多。Google word2vec需要linux环境，下载地址为：<a href="http://word2vec.googlecode.com/svn/trunk/。" target="_blank" rel="noopener">http://word2vec.googlecode.com/svn/trunk/。</a></p>
<p>有小伙伴们移植了word2vec的Windows版本，可以像在Linux上一样直接在命令行里运行，下载地址<a href="https://github.com/anoidgit/word2vec-win/releases" target="_blank" rel="noopener">https://github.com/anoidgit/word2vec-win/releases</a> 。您可以尝试使用dev c ++构建的文件，它们更加通用，可以轻松地在许多具有不同版本的Windows上运行。 </p>
<p>笔者使用 <a href="https://github.com/anoidgit/word2vec-win/releases/download/0.5/word2vec-win_devc_x64.zip" target="_blank" rel="noopener">word2vec-win_devc_x64.zip</a> ，下载解压即可调用，我放在C:\my\word2vec。</p>
<h2 id="6-OpenNRE"><a href="#6-OpenNRE" class="headerlink" title="6. OpenNRE"></a>6. OpenNRE</h2><p><a href="https://github.com/thunlp/OpenNRE/tree/modelrefine" target="_blank" rel="noopener">OpenNRE</a> 是神经关系提取的开源框架。它是基于TensorFlow的框架，用于轻松建立关系提取（RE）模型。我们将关系提取流水线分为四个部分，即嵌入，编码器，选择器（用于远程监视）和分类器。 </p>
<p>1). <strong>下载OpenNRE存储库：</strong></p>
<p>官方下载地址：<a href="https://codeload.github.com/thunlp/OpenNRE/zip/modelrefine" target="_blank" rel="noopener">https://codeload.github.com/thunlp/OpenNRE/zip/modelrefine</a></p>
<p>百度云下载地址（笔者用的OpenNRE，已改代码）：<a href="https://pan.baidu.com/s/1JQYe57Ade8E0pv8_JZ9VYA" target="_blank" rel="noopener">https://pan.baidu.com/s/1JQYe57Ade8E0pv8_JZ9VYA</a>  提取码：xqv2 </p>
<p>2).下载后解压，我把放在C:\my\OpenNRE</p>
<p>3).  然后安装所有依赖</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">C:</span>\my\OpenNRE&gt;pip install --index-url <span class="string">https:</span><span class="comment">//pypi.douban.com/simple Numpy</span></span><br><span class="line"><span class="string">C:</span>\my\OpenNRE&gt;pip install --index-url <span class="string">https:</span><span class="comment">//pypi.douban.com/simple tensorflow==1.15.0</span></span><br><span class="line"><span class="string">C:</span>\my\OpenNRE&gt;pip install --index-url <span class="string">https:</span><span class="comment">//pypi.douban.com/simple Matplotlib</span></span><br><span class="line"><span class="string">C:</span>\my\OpenNRE&gt;pip install --index-url <span class="string">https:</span><span class="comment">//pypi.douban.com/simple scikit-learn</span></span><br></pre></td></tr></table></figure>
<p>4). <strong>按以下结构制作数据文件夹</strong></p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">OpenNRE</span><br><span class="line">|<span class="string">-- ... </span></span><br><span class="line">|<span class="string">-- data</span></span><br><span class="line"><span class="string">    </span>|</span><br><span class="line">    |<span class="string">-- &#123;DATASET_NAME_1&#125;</span></span><br><span class="line"><span class="string">    </span>|<span class="string">   </span>|</span><br><span class="line">    |<span class="string">   </span>|<span class="string">-- train.json</span></span><br><span class="line"><span class="string">    </span>|<span class="string">   </span>|<span class="string">-- test.json</span></span><br><span class="line"><span class="string">    </span>|<span class="string">   </span>|<span class="string">-- word_vec.json</span></span><br><span class="line"><span class="string">    </span>|<span class="string">   </span>|<span class="string">-- rel2id.json</span></span><br><span class="line"><span class="string">    </span>|</span><br><span class="line">    |<span class="string">-- &#123;DATASET_NAME_2&#125;</span></span><br><span class="line"><span class="string">    </span>|<span class="string">   </span>|</span><br><span class="line">    |<span class="string">   </span>|<span class="string">-- ...</span></span><br><span class="line"><span class="string">    </span>|</span><br><span class="line">    |<span class="string">-- ...</span></span><br></pre></td></tr></table></figure>
<h1 id="三-远程监督数据集的获取"><a href="#三-远程监督数据集的获取" class="headerlink" title="三. 远程监督数据集的获取"></a>三. 远程监督数据集的获取</h1><p>NYT 数据集依靠 Freebase知识库，采用非百科类文本 - New York Times Corpus 来生成远程监督数据集。包含53 个可能的关系(包含NA)，训练数据集包含句子 522 611， 实体对 281 270， 关系事实 18252，测试集包含句子 172 448， 实体对 96678， 关系事实1950. 原始论文链接为<a href="https://www.jianguoyun.com/p/DUS7EyoQq_6CBxi_9ZoB" target="_blank" rel="noopener">Modeling Relations and Their Mentions without Labeled Text</a>。</p>
<p>由于是学习性质，就采用百科内的文本作为数据集，没有额外去爬取非百科类的数据来训练。</p>
<p>下面我们介绍数据集的生成步骤。</p>
<h2 id="1-加载字典"><a href="#1-加载字典" class="headerlink" title="1. 加载字典"></a>1. 加载字典</h2><p>为了提高最终数据集的有效性，我们需要尽量保证实体对中的两个实体是实体。。。这是因为在产生NA关系的实体对时，若对两个实体的要求不严格，将会产生大量的 垃圾 关系对。因此我们采用 jieba 分词 和 stanfordCorenlp 的NER模块来保证实体的有效性。</p>
<p>对于 jieba 分词，我们可以采用百度词条的全部 title 生成的外挂字典来提升最终分词结果的准确性(也可以使用其他通用领域的外挂字典，如腾讯那个)。不过我试验了一下，百度词条的外挂字典的提升效果有限，我才有可能是因为百度词条的标题有时候不能严格算一个单词的缘故，所以这个外挂字典不是很准确。而且还会拖慢生成速度。</p>
<p>因为jieba 没有ner标记功能，因此采用 <a href="https://stanfordnlp.github.io/CoreNLP/download.html" target="_blank" rel="noopener">stanfordCorenlp</a>来做NER，它的使用也很简单。</p>
<h2 id="2-从数据库导出数据并清洗"><a href="#2-从数据库导出数据并清洗" class="headerlink" title="2. 从数据库导出数据并清洗"></a>2. 从数据库导出数据并清洗</h2><p>程序 gen_re_from_baidu.py 是生成语料的核心程序。它的输入包含：</p>
<ul>
<li>百度 410 万 词条的 标题 文件， 410_title.csv。它可以直接从数据库导出获得。</li>
<li>百度 410 万 词条的 消岐名称-标题 文件， 410_title_disambi.csv。从数据库直接导出获得。</li>
<li>百度 6 万 词条的 词条 标题 title, 消岐名称 disambi， 词条文本 all_text 文件。从数据库直接导出获得。</li>
<li>百度 410 万词条的 消岐名称-属性-属性值文件，410_disambi_attr_title.csv。它是程序<a href="https://github.com/myhhub/zero_knowledge_graph/blob/master/ie/struct_to_rdf/baidu2neo4j/gen_disambi_infobox.py" target="_blank" rel="noopener">gen_disambi_infobox.py</a>的输出(410_disambi_infobox_out.csv)。</li>
</ul>
<p>以 6w_disambi_text.csv 文件为例，从数据库导出文件语句如下所示：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> title, disambi, all_text <span class="keyword">from</span> lemmas <span class="keyword">where</span> title_id &lt; <span class="number">60000</span> <span class="keyword">into</span> <span class="keyword">outfile</span> <span class="string">'C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/6w_disambi_text.csv'</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span> <span class="keyword">optionally</span> <span class="keyword">enclosed</span> <span class="keyword">by</span> <span class="string">'"'</span> <span class="keyword">lines</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\r\n'</span>;</span><br></pre></td></tr></table></figure>
<p>在得到数据后，我们调用clean_sql_output() 函数对 6w_disambi_text.csv 进行初步的清洗，主要目的是去除文本中的特殊符号和换行符。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_sql_output</span><span class="params">(in_file, out_file)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(in_file, <span class="string">"r"</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> inf, open(out_file, <span class="string">"w"</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> ouf:</span><br><span class="line">        total_lines = linecount(in_file)</span><br><span class="line">        <span class="keyword">for</span> line_num <span class="keyword">in</span> tqdm(range(total_lines)):</span><br><span class="line">            line = inf.readline()</span><br><span class="line">            line = re.sub(<span class="string">u"[\.\!#&amp;%@\^\*\(\)\+“”：』『《》$￥\&lt;\&gt;\\\:\&#123;\&#125;]"</span>, <span class="string">""</span>, line)</span><br><span class="line">            line = re.sub(<span class="string">u"\[.*?\]"</span>, <span class="string">""</span>, line)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> line.endswith(<span class="string">"\r\n"</span>):</span><br><span class="line">                ouf.write(line.strip())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ouf.write(line.strip() + <span class="string">"\n"</span>)</span><br><span class="line">                </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linecount</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    count = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> count, line <span class="keyword">in</span> enumerate(open(file_path, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>)): <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">return</span> count + <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>把6w_disambi_text.csv移动到re_cnn_att\data文件夹中。</p>
<h2 id="3-生成数据"><a href="#3-生成数据" class="headerlink" title="3. 生成数据"></a>3. 生成数据</h2><p>把输入的文410_title.csv、410_title_disambi.csv、…等文件移动到re_cnn_att\data文件夹中。</p>
<p>清洗完数据后，就该用它来生成数据啦，这一部分工作由 build_entity_relation() 函数完成。这个函数首先生成三个字典和两个集合：</p>
<ul>
<li>disambi_dict 包含每一个词条的消岐名称 和对应的属性-属性值。形式为”{“上海”: “(所属地， 中国)..”}”</li>
<li>title_id 保存了所有的词条的标题作为key值，value 是按顺序得到的序号。</li>
<li>disambi_id 包含所有 消岐名称作为 key 值，value 是按顺序得到的序号。</li>
<li>tt_pair_set 保存了所有 标题-属性对，其中属性被约束为标题(即非标题的属性不被认为是实体，被丢弃)。</li>
<li>all_title 包含所有标题的集合。</li>
</ul>
<p>而后函数分两部分得到关系事实和NA关系实体对。</p>
<p>对于关系事实，我们对于对于每一个词条，读取disambi_dict 的属性和属性值，并组装出 title-attr_title 三元组，对于每个三元组，我们去每句话中进行查找。</p>
<p>对于关系事实，其生成步骤如下所示：</p>
<ul>
<li>我们对于对于每一个词条，读取disambi_dict 的属性和属性值，并组装出 title-attr_title 三元组</li>
<li>调用 stanfordCorenlp 对三元组进行命名实体识别，排除非命名实体以及命名实体中的 ‘MONEY’、’PERCENT’、’DATE’、’NUMBER’、’ORDINAL’几类，这是因为它们包含的范围太广泛了，会对得到大量的数字，对数据集质量造成影响。</li>
<li>对于每个三元组，我们将在词条的每句话中进行寻找。</li>
<li>为了保证准确性，在查找之前先调用 jieba对每句话进行分词</li>
<li>在分词结果中进行查找，若三元组中的两个实体同时出现在一句话中，且两个实体不相同，那么就认为这句话表达了该三元组的关系。</li>
</ul>
<p>重复上述过程就可以得到关系事实了。</p>
<p>对于NA关系，为了保证数据集的质量，规定了如下要求：</p>
<ul>
<li>两个实体对必须不在现有知识库的关系中，这个没啥好说的。。。</li>
<li>每个词条中获得的NA关系不得大于15，这个是观察NYT数据集的NA和关系事实的比例得到的，防止出现太多的NA。也可以使用max_NA_in_lemmas 进行更改。</li>
<li>每句话中最多被使用1次，防止一句话被多个NA关系利用。</li>
<li>NA关系的实体必须通过 stanfordCorenlp 的NER 标记。</li>
</ul>
<p>对于满足以上要求的实体对，我们就将其作为数据集的一部分了。生成数据集后，将前80%作为训练集，后20%作为测试集。</p>
<p>运行程序 gen_re_from_baidu.py</p>
<p><strong>用户根据实际的Stanford CoreNLP安装路径，修改gen_re_from_baidu.py中stanford_path的值。</strong></p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">C:</span>\my\Python\python.exe <span class="string">C:</span><span class="regexp">/d/</span>mmm<span class="regexp">/pycharm/</span>re_cnn_att/gen_re_from_baidu.py</span><br><span class="line"><span class="string">error_counts:</span>  <span class="number">32</span></span><br><span class="line">  <span class="number">0</span>%|          | <span class="number">0</span><span class="regexp">/1 [00:00&lt;?, ?it/</span>s]<span class="string">count_re:</span>  <span class="number">50</span> 	 <span class="string">count_na:</span>  <span class="number">50</span> 	 <span class="string">count_total:</span>  <span class="number">120</span></span><br><span class="line"><span class="string">total_sentence_used:</span>  <span class="number">60</span></span><br><span class="line"><span class="number">100</span>%|██████████| <span class="number">1</span><span class="regexp">/1 [00:00&lt;00:00, 55.71it/</span>s]</span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h2 id="4-数据集的格式"><a href="#4-数据集的格式" class="headerlink" title="4. 数据集的格式"></a>4. 数据集的格式</h2><p>为了使用OpenNRE，对于训练集和数据集的格式和 OpenNRE 的要求一致，格式为：</p>
<figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="symbol">'sentence</span><span class="symbol">':</span> <span class="symbol">'Bill</span> Gates is the founder of Microsoft .',</span><br><span class="line">        <span class="symbol">'head</span><span class="symbol">':</span> &#123;<span class="symbol">'word</span><span class="symbol">':</span> <span class="symbol">'Bill</span> Gates', <span class="symbol">'id</span><span class="symbol">':</span> <span class="symbol">'m.03_3d</span>', <span class="symbol">'type</span><span class="symbol">':</span> <span class="symbol">'None</span>'&#125;,</span><br><span class="line">        <span class="symbol">'tail</span><span class="symbol">':</span> &#123;<span class="symbol">'word</span><span class="symbol">':</span> <span class="symbol">'Microsoft</span>', <span class="symbol">'id</span><span class="symbol">':</span> <span class="symbol">'m.07dfk</span>', <span class="symbol">'type</span><span class="symbol">':</span> <span class="symbol">'None</span>'&#125;,</span><br><span class="line">        <span class="symbol">'relation</span><span class="symbol">':</span> <span class="symbol">'founder</span>'</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>名称为train.json 和 test.json。对于 Relation-ID 的映射文件，里面保存着用到的关系，其中需要注意的是NA的 value必须为0。得到的文件名为rel2id.json，其格式为：</p>
<figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">'NA'</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">'relation_1'</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">'relation_2'</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="params">...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="5-词向量的生成"><a href="#5-词向量的生成" class="headerlink" title="5. 词向量的生成"></a>5. 词向量的生成</h2><p>这里我用 word2vec来生成词向量，文本是用6w词条的，分词用jieba做。输出向量维度是50，包含1 552 081个词。为了在 OpenNRE 中使用，我们需要将其转化为如下格式：</p>
<figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;<span class="symbol">'word</span><span class="symbol">':</span> <span class="symbol">'the</span>', <span class="symbol">'vec</span><span class="symbol">':</span> [<span class="name">0.418</span>, <span class="number">0.24968</span>, ...]&#125;,</span><br><span class="line">    &#123;<span class="symbol">'word</span><span class="symbol">':</span> ',', <span class="symbol">'vec</span><span class="symbol">':</span> [<span class="name">0.013441</span>, <span class="number">0.23682</span>, ...]&#125;,</span><br><span class="line">    ...</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>关于词向量的生成由 word2vec.py 完成。这里需要注意的是，在生成词向量时， 我将Word2vec 包放在C:\my\word2vec文件夹下 ，由下述命令完成：</p>
<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.system("C:\my\word2vec\word2vec -train seg_6w_disambi_text.txt -output word_vec.txt -size<span class="number"> 50 </span>-window<span class="number"> 5 </span>-sample 1e-4 -negative<span class="number"> 5 </span>-hs<span class="number"> 0 </span>-binary<span class="number"> 0 </span>-cbow<span class="number"> 0 </span>-iter<span class="number"> 3 </span>-min-count<span class="number"> 1 </span>-hs 1")transfer_json("word_vec.txt", "word_vec.json")</span><br></pre></td></tr></table></figure>
<p>运行word2vec.py</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">C:\my\Python\python.exe C:/d/mmm/pycharm/re_cnn_att/word2vec.py</span><br><span class="line"></span><br><span class="line">0it [00:00, ?it/s]Building<span class="built_in"> prefix </span>dict <span class="keyword">from</span> the<span class="built_in"> default </span>dictionary <span class="built_in">..</span>.</span><br><span class="line">Loading model <span class="keyword">from</span> cache C:\Users\mmm\AppData\Local\Temp\jieba.cache</span><br><span class="line">Loading model cost 0.977 seconds.</span><br><span class="line">Prefix dict has been built succesfully.</span><br><span class="line">1it [00:06,  6.57s/it]</span><br><span class="line">Starting training using file seg_6w_disambi_text.txt</span><br><span class="line">Vocab size: 70593</span><br><span class="line">Words <span class="keyword">in</span> train file: 814504</span><br><span class="line">Alpha: 0.000098  Progress: 100.92%  Words/thread/sec: 1125.03k  Total word_num:  70593 </span><br><span class="line">  0%|          | 0/70593 [00:00&lt;?, ?it/s]Word dim:  50</span><br><span class="line">100%|██████████| 70593/70593 [00:06&lt;00:00, 10144.12it/s]</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>
<p>生成的word_vec.json结果格式：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="attr">"word"</span>: <span class="string">"&lt;/s&gt;"</span>, <span class="attr">"vec"</span>: [<span class="number">0.008005</span>, <span class="number">0.008839</span>, <span class="number">-0.007661</span>, <span class="number">-0.006556</span>, <span class="number">0.002733</span>, <span class="number">0.006042</span>, <span class="number">0.001882</span>, <span class="number">0.000423</span>, <span class="number">-0.007207</span>, <span class="number">0.004437</span>, <span class="number">-0.008713</span>, <span class="number">0.002499</span>, <span class="number">-0.001503</span>, <span class="number">-0.001914</span>, <span class="number">-0.006631</span>, <span class="number">-0.003764</span>, <span class="number">0.005159</span>, <span class="number">0.006051</span>, <span class="number">0.005938</span>, <span class="number">0.003195</span>, <span class="number">0.00309</span>, <span class="number">-0.007605</span>, <span class="number">-0.008192</span>, <span class="number">0.009939</span>, <span class="number">0.007603</span>, <span class="number">0.00618</span>, <span class="number">-0.001208</span>, <span class="number">0.008031</span>, <span class="number">-0.00099</span>, <span class="number">0.001469</span>, <span class="number">-0.000298</span>, <span class="number">-0.005966</span>, <span class="number">0.002625</span>, <span class="number">-0.002675</span>, <span class="number">-0.007651</span>, <span class="number">0.009508</span>, <span class="number">0.008759</span>, <span class="number">-0.00219</span>, <span class="number">-0.000452</span>, <span class="number">0.001018</span>, <span class="number">-0.007275</span>, <span class="number">-0.008014</span>, <span class="number">0.009109</span>, <span class="number">0.000126</span>, <span class="number">-0.005165</span>, <span class="number">-0.006084</span>, <span class="number">-0.006153</span>, <span class="number">0.003394</span>, <span class="number">0.000403</span>, <span class="number">0.002662</span>]&#125;, &#123;<span class="attr">"word"</span>: <span class="string">"\uff0c"</span>, <span class="attr">"vec"</span>: [<span class="number">-0.255787</span>, <span class="number">-0.137732</span>, <span class="number">0.144594</span>, <span class="number">0.138146</span>, <span class="number">-0.224961</span>, <span class="number">-0.198183</span>, <span class="number">0.168778</span>, <span class="number">-0.021675</span>, <span class="number">-0.293887</span>, <span class="number">-0.247066</span>, <span class="number">0.185316</span>, <span class="number">0.137508</span>, <span class="number">-0.401537</span>, <span class="number">-0.242721</span>, <span class="number">0.069197</span>, <span class="number">-0.161912</span>, <span class="number">-0.168342</span>, <span class="number">-0.15231</span>, <span class="number">0.313346</span>, <span class="number">0.136589</span>, <span class="number">-0.300042</span>, <span class="number">-0.082335</span>, <span class="number">0.705634</span>, <span class="number">-0.395934</span>, <span class="number">-0.18271</span>, <span class="number">-0.206994</span>, <span class="number">-0.316542</span>, <span class="number">-0.464895</span>, <span class="number">-0.208067</span>, <span class="number">0.031974</span>, <span class="number">-0.005736</span>, </span><br><span class="line"></span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<h1 id="四-运行-OpenNRE"><a href="#四-运行-OpenNRE" class="headerlink" title="四. 运行 OpenNRE"></a>四. 运行 OpenNRE</h1><p>我的train.json、test.json、rel2id.json、word2vec.json 四个文件放在百度云上，供大家使用，<a href="https://pan.baidu.com/s/17vk8fZrtHwHpGJzddHAvUw" target="_blank" rel="noopener">百度云下载链接</a>(提取码：0k5h)。</p>
<p>这部就比较简单了，前面我们已经得到运行该程序所需的文件，现在只需将上面得到的 train.json、test.json、rel2id.json、word2vec.json 四个文件打包放到data目录下，我的在C:\my\OpenNRE\data\baidu\。而后运行<code>python train_demo.py baidu cnn att</code>即可训练数据。</p>
<h2 id="1-运行"><a href="#1-运行" class="headerlink" title="1.  运行"></a>1.  运行</h2><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">C</span>:\my\OpenNRE&gt;python train_demo.py baidu cnn att</span><br><span class="line"></span><br><span class="line"><span class="number">2019</span>-<span class="number">11</span>-<span class="number">01</span> <span class="number">10</span>:<span class="number">39</span>:<span class="number">22.737101</span>: W tensorflow/stream_executor/platform/default/dso_loader.<span class="attribute">cc</span>:<span class="number">55</span>] Could not load dynamic library <span class="string">'cudart64_100.dll'</span>; <span class="attribute">dlerror</span>: cudart64_100.dll not found</span><br><span class="line"><span class="number">2019</span>-<span class="number">11</span>-<span class="number">01</span> <span class="number">10</span>:<span class="number">39</span>:<span class="number">22.743047</span>: I tensorflow/stream_executor/cuda/cudart_stub.<span class="attribute">cc</span>:<span class="number">29</span>] Ignore above cudart dlerror if you do not have a GPU set up on your machine.</span><br><span class="line"><span class="attribute">WARNING</span>:<span class="attribute">tensorflow</span>:From <span class="attribute">C</span>:\my\OpenNRE\nrekit\framework.<span class="attribute">py</span>:<span class="number">126</span>: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.</span><br><span class="line"></span><br><span class="line">Pre-processed files exist. Loading them...</span><br><span class="line">Finish loading</span><br><span class="line">Total relation <span class="attribute">fact</span>: <span class="number">6298</span></span><br><span class="line">Pre-processed files exist. Loading them...</span><br><span class="line">Finish loading</span><br><span class="line">Total relation <span class="attribute">fact</span>: <span class="number">1761</span></span><br><span class="line">Pre-processed files exist. Loading them...</span><br><span class="line">Finish loading</span><br><span class="line">Total relation <span class="attribute">fact</span>: <span class="number">1761</span></span><br><span class="line">Start training...</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="number">2019</span>-<span class="number">11</span>-<span class="number">01</span> <span class="number">10</span>:<span class="number">39</span>:<span class="number">54.093624</span>: W tensorflow/core/common_runtime/colocation_graph.<span class="attribute">cc</span>:<span class="number">983</span>] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [</span><br><span class="line">  /<span class="attribute">job</span>:localhost/<span class="attribute">replica</span>:<span class="number">0</span>/<span class="attribute">task</span>:<span class="number">0</span>/<span class="attribute">device</span>:<span class="attribute">CPU</span>:<span class="number">0</span>].</span><br><span class="line">See below for details of this colocation <span class="attribute">group</span>:</span><br><span class="line">Colocation Debug <span class="attribute">Info</span>:</span><br><span class="line">Colocation group had the following types and supported <span class="attribute">devices</span>:</span><br><span class="line">Root Member(assigned_device_name_index_=-<span class="number">1</span> requested_device_name_=<span class="string">'/device:GPU:0'</span> assigned_device_name_=<span class="string">''</span> resource_device_name_=<span class="string">'/device:GPU:0'</span> supported_device_types_=[CPU] possible_devices_=[]</span><br><span class="line"><span class="attribute">VariableV2</span>: CPU</span><br><span class="line"><span class="attribute">Const</span>: CPU</span><br><span class="line"><span class="attribute">Assign</span>: CPU</span><br><span class="line"><span class="attribute">Identity</span>: CPU</span><br><span class="line"><span class="attribute">GatherV2</span>: CPU</span><br><span class="line"></span><br><span class="line">Colocation members, user-requested devices, and framework assigned devices, if <span class="attribute">any</span>:</span><br><span class="line">  weights_table/weights_table (VariableV2) /<span class="attribute">device</span>:<span class="attribute">GPU</span>:<span class="number">0</span></span><br><span class="line">  weights_table/weights_table/Assign (Assign) /<span class="attribute">device</span>:<span class="attribute">GPU</span>:<span class="number">0</span></span><br><span class="line">  weights_table/weights_table/read (Identity) /<span class="attribute">device</span>:<span class="attribute">GPU</span>:<span class="number">0</span></span><br><span class="line">  gpu_0/loss/embedding_lookup/axis (Const) /<span class="attribute">device</span>:<span class="attribute">GPU</span>:<span class="number">0</span></span><br><span class="line">  gpu_0/loss/embedding_lookup (GatherV2) /<span class="attribute">device</span>:<span class="attribute">GPU</span>:<span class="number">0</span></span><br><span class="line">  save/Assign_6 (Assign) /<span class="attribute">device</span>:<span class="attribute">GPU</span>:<span class="number">0</span></span><br><span class="line"></span><br><span class="line">###### Epoch <span class="number">1</span> ######</span><br><span class="line">epoch <span class="number">1</span> step <span class="number">684</span> time <span class="number">0.43</span> | <span class="attribute">loss</span>: <span class="number">0.320573</span>, not NA <span class="attribute">accuracy</span>: <span class="number">0.122737</span>, <span class="attribute">accuracy</span>: <span class="number">0.943412</span></span><br><span class="line">Average iteration <span class="attribute">time</span>: <span class="number">0.545785</span></span><br><span class="line">Testing...</span><br><span class="line">[TEST] step <span class="number">184</span> | not NA <span class="attribute">accuracy</span>: <span class="number">0.119584</span>, <span class="attribute">accuracy</span>: <span class="number">0.946689</span></span><br><span class="line">[TEST] <span class="attribute">auc</span>: <span class="number">0.3006554130143355</span></span><br><span class="line">Finish testing</span><br><span class="line">Best model, storing...</span><br><span class="line">Finish storing</span><br><span class="line">###### Epoch <span class="number">2</span> ######</span><br><span class="line">epoch <span class="number">2</span> step <span class="number">684</span> time <span class="number">0.55</span> | <span class="attribute">loss</span>: <span class="number">0.015132</span>, not NA <span class="attribute">accuracy</span>: <span class="number">0.213719</span>, <span class="attribute">accuracy</span>: <span class="number">0.949443</span></span><br><span class="line">Average iteration <span class="attribute">time</span>: <span class="number">0.642220</span></span><br><span class="line">Testing...</span><br><span class="line">[TEST] step <span class="number">184</span> | not NA <span class="attribute">accuracy</span>: <span class="number">0.338533</span>, <span class="attribute">accuracy</span>: <span class="number">0.957770</span></span><br><span class="line">[TEST] <span class="attribute">auc</span>: <span class="number">0.5440238744502314</span></span><br><span class="line">Finish testing</span><br><span class="line">Best model, storing...</span><br><span class="line">Finish storing</span><br><span class="line">###### Epoch <span class="number">3</span> ######</span><br><span class="line">epoch <span class="number">3</span> step <span class="number">684</span> time <span class="number">0.47</span> | <span class="attribute">loss</span>: <span class="number">0.025789</span>, not NA <span class="attribute">accuracy</span>: <span class="number">0.336138</span>, <span class="attribute">accuracy</span>: <span class="number">0.956259</span></span><br><span class="line">Average iteration <span class="attribute">time</span>: <span class="number">0.615477</span></span><br><span class="line">Testing...</span><br><span class="line">[TEST] step <span class="number">184</span> | not NA <span class="attribute">accuracy</span>: <span class="number">0.392259</span>, <span class="attribute">accuracy</span>: <span class="number">0.961486</span></span><br><span class="line">[TEST] <span class="attribute">auc</span>: <span class="number">0.6110335239333476</span></span><br><span class="line">Finish testing</span><br><span class="line">Best model, storing...</span><br><span class="line">Finish storing</span><br><span class="line">###### Epoch <span class="number">4</span> ######</span><br><span class="line">epoch <span class="number">4</span> step <span class="number">684</span> time <span class="number">0.47</span> | <span class="attribute">loss</span>: <span class="number">0.131589</span>, not NA <span class="attribute">accuracy</span>: <span class="number">0.399333</span>, <span class="attribute">accuracy</span>: <span class="number">0.960073</span></span><br><span class="line">Average iteration <span class="attribute">time</span>: <span class="number">0.545155</span></span><br><span class="line">Testing...</span><br><span class="line">[TEST] step <span class="number">184</span> | not NA <span class="attribute">accuracy</span>: <span class="number">0.517620</span>, <span class="attribute">accuracy</span>: <span class="number">0.963953</span></span><br><span class="line">[TEST] <span class="attribute">auc</span>: <span class="number">0.6347928854797641</span></span><br><span class="line">Finish testing</span><br><span class="line">Best model, storing...</span><br><span class="line">Finish storing</span><br><span class="line">##### Epoch <span class="number">5</span> ######</span><br><span class="line">epoch <span class="number">5</span> step <span class="number">684</span> time <span class="number">0.68</span> | <span class="attribute">loss</span>: <span class="number">0.039580</span>, not NA <span class="attribute">accuracy</span>: <span class="number">0.425214</span>, <span class="attribute">accuracy</span>: <span class="number">0.961551</span></span><br><span class="line">Average iteration <span class="attribute">time</span>: <span class="number">0.641899</span></span><br><span class="line">Testing...</span><br><span class="line">[TEST] step <span class="number">184</span> | not NA <span class="attribute">accuracy</span>: <span class="number">0.489890</span>, <span class="attribute">accuracy</span>: <span class="number">0.965709</span></span><br><span class="line">[TEST] <span class="attribute">auc</span>: <span class="number">0.6604051878963836</span></span><br><span class="line">Finish testing</span><br><span class="line">Best model, storing...</span><br><span class="line">Finish storing</span><br><span class="line">###### Epoch <span class="number">6</span> ######</span><br><span class="line">epoch <span class="number">6</span> step <span class="number">684</span> time <span class="number">0.58</span> | <span class="attribute">loss</span>: <span class="number">0.096361</span>, not NA <span class="attribute">accuracy</span>: <span class="number">0.448396</span>, <span class="attribute">accuracy</span>: <span class="number">0.962464</span></span><br><span class="line">Average iteration <span class="attribute">time</span>: <span class="number">0.696763</span></span><br><span class="line">Testing...</span><br><span class="line">[TEST] step <span class="number">184</span> | not NA <span class="attribute">accuracy</span>: <span class="number">0.533218</span>, <span class="attribute">accuracy</span>: <span class="number">0.967399</span></span><br><span class="line">[TEST] <span class="attribute">auc</span>: <span class="number">0.6855477905925986</span></span><br><span class="line">Finish testing</span><br><span class="line">Best model, storing...</span><br><span class="line">Finish storing</span><br><span class="line">###### Epoch <span class="number">7</span> ######</span><br><span class="line">epoch <span class="number">7</span> step <span class="number">684</span> time <span class="number">0.63</span> | <span class="attribute">loss</span>: <span class="number">0.076175</span>, not NA <span class="attribute">accuracy</span>: <span class="number">0.469514</span>, <span class="attribute">accuracy</span>: <span class="number">0.963622</span></span><br><span class="line">Average iteration <span class="attribute">time</span>: <span class="number">0.691868</span></span><br><span class="line">Testing...</span><br><span class="line">[TEST] step <span class="number">184</span> | not NA <span class="attribute">accuracy</span>: <span class="number">0.514154</span>, <span class="attribute">accuracy</span>: <span class="number">0.967230</span></span><br><span class="line">[TEST] <span class="attribute">auc</span>: <span class="number">0.6920503761834449</span></span><br><span class="line">Finish testing</span><br><span class="line">Best model, storing...</span><br><span class="line">Finish storing</span><br><span class="line">###### Epoch <span class="number">8</span> ######</span><br><span class="line">epoch <span class="number">8</span> step <span class="number">684</span> time <span class="number">0.60</span> | <span class="attribute">loss</span>: <span class="number">0.033911</span>, not NA <span class="attribute">accuracy</span>: <span class="number">0.479994</span>, <span class="attribute">accuracy</span>: <span class="number">0.964151</span></span><br><span class="line">Average iteration <span class="attribute">time</span>: <span class="number">0.694419</span></span><br><span class="line">Testing...</span><br><span class="line">[TEST] step <span class="number">184</span> | not NA <span class="attribute">accuracy</span>: <span class="number">0.534373</span>, <span class="attribute">accuracy</span>: <span class="number">0.968007</span></span><br><span class="line">[TEST] <span class="attribute">auc</span>: <span class="number">0.7014862217419188</span></span><br><span class="line">Finish testing</span><br><span class="line">Best model, storing...</span><br><span class="line">Finish storing</span><br></pre></td></tr></table></figure>
<p>最终，当训练8个epoch时，在测试机上得到的准确率为70.15%，其中非NA准确率为53.44%。</p>
<h2 id="2-运行可能出现的问题及解决"><a href="#2-运行可能出现的问题及解决" class="headerlink" title="2.  运行可能出现的问题及解决"></a>2.  运行可能出现的问题及解决</h2><p>问题1：错误信息FileNotFoundError: [Errno 2] No such file or directory: ‘_processed_data/baidu\data\baidu\train_word.npy’。</p>
<p>解决：手工创建data\baidu\这两级目录。</p>
<p>问题2：错误信息AttributeError: module ‘nrekit’ has no attribute ‘embedding’。</p>
<p>解决：修改train_demo.py，把<code>nrekit.embedding</code>改成<code>nrekit.network.embedding</code> 。</p>
<p>问题3：错误信息NameError: name ‘encoder’ is not defined。</p>
<p>解决：修改train_demo.py，把<code>encoder + &#39;_&#39; + selector</code>改成<code>self.encoder + &#39;_&#39; + self.selector</code> 。</p>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="/" target="_blank">Ljjyy.com</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/archives/2019/10/100600.html" class="pre-post btn btn-default" title='从零开始学习知识图谱 之 十.百科知识图谱构建 4.结构化数据到RDF'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">从零开始学习知识图谱 之 十.百科知识图谱构建 4.结构化数据到RDF</span>
        </a>
    
    
        <a href="/archives/2019/10/100598.html" class="next-post btn btn-default" title='从零开始学习知识图谱 之 八.百科知识图谱构建 2.数据清洗及存入图数据库Neo4j'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">从零开始学习知识图谱 之 八.百科知识图谱构建 2.数据清洗及存入图数据库Neo4j</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: '5MzTXYXkt03k101j0PmSDN34-gzGzoHsz',
            appKey: 'iwjYgwno6qj3wtDVVSbe8nYQ',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一-简介"><span class="toc-text">一. 简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二-环境准备"><span class="toc-text">二. 环境准备</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-操作系统"><span class="toc-text">1. 操作系统</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-jdk"><span class="toc-text">2. jdk</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Python3"><span class="toc-text">3. Python3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Stanford-NLP"><span class="toc-text">4. Stanford NLP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#安装"><span class="toc-text">安装</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-word2vec"><span class="toc-text">5. word2vec</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-OpenNRE"><span class="toc-text">6. OpenNRE</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#三-远程监督数据集的获取"><span class="toc-text">三. 远程监督数据集的获取</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-加载字典"><span class="toc-text">1. 加载字典</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-从数据库导出数据并清洗"><span class="toc-text">2. 从数据库导出数据并清洗</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-生成数据"><span class="toc-text">3. 生成数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-数据集的格式"><span class="toc-text">4. 数据集的格式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-词向量的生成"><span class="toc-text">5. 词向量的生成</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#四-运行-OpenNRE"><span class="toc-text">四. 运行 OpenNRE</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-运行"><span class="toc-text">1.  运行</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-运行可能出现的问题及解决"><span class="toc-text">2.  运行可能出现的问题及解决</span></a></li></ol></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019-2023&emsp;<a href="/" class="copyright-links" target="_blank" rel="nofollow">Ljjyy.com</a>
                </span> |
                <span>
                    <a href="/about/" class="copyright-links" target="_blank" rel="nofollow">关于我们</a>
                </span> |                
                <span>
                    <a href="/sitemap.xml" class="copyright-links" target="_blank" rel="nofollow">网站地图</a>
                </span> |
                <span>
                    <a href="/archives/" class="copyright-links" target="_blank" rel="nofollow">时间轴</a>
                </span>              
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>
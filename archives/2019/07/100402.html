<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="https://www.ljjyy.com">
    <!--SEO-->

    <meta name="keywords" content="hadoop,spark,rdd">


    <meta name="description" content="一、RDD简介RDD全称为Resilient Distributed Datasets，是Spark最基本的数据抽象，它是只读的、分区记录的集合，支持并行操作，可以由外部数据集或其他RDD转换而...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>Spark弹性式数据集RDDs | 来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</title>


    <link rel="alternate" href="/atom.xml" title="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
        <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
        <script>LA.init({id: "JgbNOaw1xxsmUUsQ",ck: "JgbNOaw1xxsmUUsQ"})</script>
	</div>






    
    <meta name="baidu-site-verification" content="dTHILoORpx">


    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  >
    <div class="main-header-box">
        <!--a class="header-avatar" href="/" title='Ljjyy.com'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a-->
        <div class="branding">
            
                <h2> 多读书多实践，勤思考善领悟 </h2>
            
    	  </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">

        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="web-logo"  href="/" title='Ljjyy.com'></a>
                    <!--a class="navbar-brand" href="https://www.ljjyy.com">来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</a-->
                </div>
                <div class="collapse navbar-collapse" id="main-menu" style="">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/cloud/"><i class="fa "></i>云计算</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/front/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/back/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/devops/"><i class="fa "></i>运维</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/crack/"><i class="fa "></i>破解</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/penetration/"><i class="fa "></i>渗透</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tool/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/other/"><i class="fa "></i>其他</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="Spark弹性式数据集RDDs">
            
	            Spark弹性式数据集RDDs
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/cloud/">云计算</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/hadoop/">hadoop</a> <a class="tag-link" href="/tags/rdd/">rdd</a> <a class="tag-link" href="/tags/spark/">spark</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/07/10</span>
        </span>
        
    
</div>
            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>1440</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <h2 id="一、RDD简介"><a href="#一、RDD简介" class="headerlink" title="一、RDD简介"></a>一、RDD简介</h2><p><code>RDD</code>全称为Resilient Distributed Datasets，是Spark最基本的数据抽象，它是只读的、分区记录的集合，支持并行操作，可以由外部数据集或其他RDD转换而来，它具有以下特性：</p>
<ul>
<li>一个RDD由一个或者多个分区（Partitions）组成。对于RDD来说，每个分区会被一个计算任务所处理，用户可以在创建RDD时指定其分区个数，如果没有指定，则默认采用程序所分配到的CPU的核心数；</li>
<li>RDD拥有一个用于计算分区的函数compute；</li>
<li>RDD会保存彼此间的依赖关系，RDD的每次转换都会生成一个新的依赖关系，这种RDD之间的依赖关系就像流水线一样。在部分分区数据丢失后，可以通过这种依赖关系重新计算丢失的分区数据，而不是对RDD的所有分区进行重新计算；</li>
<li>Key-Value型的RDD还拥有Partitioner(分区器)，用于决定数据被存储在哪个分区中，目前Spark中支持HashPartitioner(按照哈希分区)和RangeParationer(按照范围进行分区)；</li>
<li>一个优先位置列表(可选)，用于存储每个分区的优先位置(prefered location)。对于一个HDFS文件来说，这个列表保存的就是每个分区所在的块的位置，按照“移动数据不如移动计算“的理念，Spark在进行任务调度的时候，会尽可能的将计算任务分配到其所要处理数据块的存储位置。</li>
</ul>
<p><code>RDD[T]</code>抽象类的部分相关代码如下：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 由子类实现以计算给定分区</span></span><br><span class="line"><span class="keyword">def</span> compute(<span class="string">split:</span> Partition, <span class="string">context:</span> TaskContext): Iterator[T]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取所有分区</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">def</span> <span class="string">getPartitions:</span> Array[Partition]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取所有依赖关系</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">def</span> <span class="string">getDependencies:</span> Seq[Dependency[_]] = deps</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取优先位置列表</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">def</span> getPreferredLocations(<span class="string">split:</span> Partition): Seq[String] = Nil</span><br><span class="line"></span><br><span class="line"><span class="comment">// 分区器 由子类重写以指定它们的分区方式</span></span><br><span class="line"><span class="meta">@transient</span> val <span class="string">partitioner:</span> Option[Partitioner] = None</span><br></pre></td></tr></table></figure>
<h2 id="二、创建RDD"><a href="#二、创建RDD" class="headerlink" title="二、创建RDD"></a>二、创建RDD</h2><p>RDD有两种创建方式，分别介绍如下：</p>
<h3 id="2-1-由现有集合创建"><a href="#2-1-由现有集合创建" class="headerlink" title="2.1 由现有集合创建"></a>2.1 由现有集合创建</h3><p>这里使用<code>spark-shell</code>进行测试，启动命令如下：</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --<span class="keyword">master</span> <span class="title">local</span>[<span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>启动<code>spark-shell</code>后，程序会自动创建应用上下文，相当于执行了下面的Scala语句：</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> SparkConf().setAppName(<span class="string">"Spark shell"</span>).setMaster(<span class="string">"local[4]"</span>)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> SparkContext(conf)</span><br></pre></td></tr></table></figure>
<p>由现有集合创建RDD，你可以在创建时指定其分区个数，如果没有指定，则采用程序所分配到的CPU的核心数：</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> <span class="keyword">data</span> = Array(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"><span class="comment">// 由现有集合创建RDD,默认分区数为程序所分配到的CPU的核心数</span></span><br><span class="line"><span class="keyword">val</span> dataRDD = sc.parallelize(<span class="keyword">data</span>) </span><br><span class="line"><span class="comment">// 查看分区数</span></span><br><span class="line">dataRDD.getNumPartitions</span><br><span class="line"><span class="comment">// 明确指定分区数</span></span><br><span class="line"><span class="keyword">val</span> dataRDD = sc.parallelize(<span class="keyword">data</span>,<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>执行结果如下：</p>
<div align="center"> <img src="/img/bigdata/scala-fqs.png"> </div>

<h3 id="2-2-引用外部存储系统中的数据集"><a href="#2-2-引用外部存储系统中的数据集" class="headerlink" title="2.2 引用外部存储系统中的数据集"></a>2.2 引用外部存储系统中的数据集</h3><p>引用外部存储系统中的数据集，例如本地文件系统，HDFS，HBase或支持Hadoop InputFormat的任何数据源。</p>
<figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> fileRDD = sc.textFile(<span class="string">"/usr/file/emp.txt"</span>)</span><br><span class="line"><span class="comment">// 获取第一行文本</span></span><br><span class="line">fileRDD.take(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>使用外部存储系统时需要注意以下两点：</p>
<ul>
<li>如果在集群环境下从本地文件系统读取数据，则要求该文件必须在集群中所有机器上都存在，且路径相同；</li>
<li>支持目录路径，支持压缩文件，支持使用通配符。</li>
</ul>
<h3 id="2-3-textFile-amp-wholeTextFiles"><a href="#2-3-textFile-amp-wholeTextFiles" class="headerlink" title="2.3 textFile &amp; wholeTextFiles"></a>2.3 textFile &amp; wholeTextFiles</h3><p>两者都可以用来读取外部文件，但是返回格式是不同的：</p>
<ul>
<li><strong>textFile</strong>：其返回格式是<code>RDD[String]</code> ，返回的是就是文件内容，RDD中每一个元素对应一行数据；</li>
<li><strong>wholeTextFiles</strong>：其返回格式是<code>RDD[(String, String)]</code>，元组中第一个参数是文件路径，第二个参数是文件内容；</li>
<li>两者都提供第二个参数来控制最小分区数；</li>
<li>从HDFS上读取文件时，Spark会为每个块创建一个分区。</li>
</ul>
<figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def textFile(path: <span class="type">String</span>,minPartitions: <span class="type">Int</span> = defaultMinPartitions): <span class="type">RDD</span>[<span class="type">String</span>] = withScope <span class="meta">&#123;...&#125;</span></span><br><span class="line">def wholeTextFiles(path: <span class="type">String</span>,minPartitions: <span class="type">Int</span> = defaultMinPartitions): <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>)]=<span class="meta">&#123;..&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="三、操作RDD"><a href="#三、操作RDD" class="headerlink" title="三、操作RDD"></a>三、操作RDD</h2><p>RDD支持两种类型的操作：<em>transformations</em>（转换，从现有数据集创建新数据集）和 <em>actions</em>（在数据集上运行计算后将值返回到驱动程序）。RDD中的所有转换操作都是惰性的，它们只是记住这些转换操作，但不会立即执行，只有遇到 <em>action</em> 操作后才会真正的进行计算，这类似于函数式编程中的惰性求值。</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val <span class="type">list</span> = List(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment">// map 是一个transformations操作，而foreach是一个actions操作</span></span><br><span class="line">sc.parallelize(<span class="type">list</span>).map(_ * <span class="number">10</span>).foreach(println)</span><br><span class="line"><span class="comment">// 输出： 10 20 30</span></span><br></pre></td></tr></table></figure>
<h2 id="四、缓存RDD"><a href="#四、缓存RDD" class="headerlink" title="四、缓存RDD"></a>四、缓存RDD</h2><h3 id="4-1-缓存级别"><a href="#4-1-缓存级别" class="headerlink" title="4.1 缓存级别"></a>4.1 缓存级别</h3><p>Spark速度非常快的一个原因是RDD支持缓存。成功缓存后，如果之后的操作使用到了该数据集，则直接从缓存中获取。虽然缓存也有丢失的风险，但是由于RDD之间的依赖关系，如果某个分区的缓存数据丢失，只需要重新计算该分区即可。</p>
<p>Spark支持多种缓存级别 ：</p>
<table>
<thead>
<tr>
<th>Storage Level<br>（存储级别）</th>
<th>Meaning（含义）</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>MEMORY_ONLY</code></td>
<td>默认的缓存级别，将 RDD以反序列化的Java对象的形式存储在 JVM 中。如果内存空间不够，则部分分区数据将不再缓存。</td>
</tr>
<tr>
<td><code>MEMORY_AND_DISK</code></td>
<td>将 RDD 以反序列化的Java对象的形式存储JVM中。如果内存空间不够，将未缓存的分区数据存储到磁盘，在需要使用这些分区时从磁盘读取。</td>
</tr>
<tr>
<td><code>MEMORY_ONLY_SER</code><br></td>
<td>将 RDD 以序列化的Java对象的形式进行存储（每个分区为一个 byte 数组）。这种方式比反序列化对象节省存储空间，但在读取时会增加CPU的计算负担。仅支持Java和Scala 。</td>
</tr>
<tr>
<td><code>MEMORY_AND_DISK_SER</code><br></td>
<td>类似于<code>MEMORY_ONLY_SER</code>，但是溢出的分区数据会存储到磁盘，而不是在用到它们时重新计算。仅支持Java和Scala。</td>
</tr>
<tr>
<td><code>DISK_ONLY</code></td>
<td>只在磁盘上缓存RDD</td>
</tr>
<tr>
<td><code>MEMORY_ONLY_2</code>, <br><code>MEMORY_AND_DISK_2</code>, etc</td>
<td>与上面的对应级别功能相同，但是会为每个分区在集群中的两个节点上建立副本。</td>
</tr>
<tr>
<td><code>OFF_HEAP</code></td>
<td>与<code>MEMORY_ONLY_SER</code>类似，但将数据存储在堆外内存中。这需要启用堆外内存。</td>
</tr>
</tbody>
</table>
<blockquote>
<p>启动堆外内存需要配置两个参数：</p>
<ul>
<li><strong>spark.memory.offHeap.enabled</strong> ：是否开启堆外内存，默认值为false，需要设置为true；</li>
<li><strong>spark.memory.offHeap.size</strong> : 堆外内存空间的大小，默认值为0，需要设置为正值。</li>
</ul>
</blockquote>
<h3 id="4-2-使用缓存"><a href="#4-2-使用缓存" class="headerlink" title="4.2 使用缓存"></a>4.2 使用缓存</h3><p>缓存数据的方法有两个：<code>persist</code>和<code>cache</code> 。<code>cache</code>内部调用的也是<code>persist</code>，它是<code>persist</code>的特殊化形式，等价于<code>persist(StorageLevel.MEMORY_ONLY)</code>。示例如下：</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 所有存储级别均定义在StorageLevel对象中</span></span><br><span class="line">fileRDD.persist<span class="comment">(StorageLevel.MEMORY_AND_DISK)</span></span><br><span class="line">fileRDD.cache<span class="comment">()</span></span><br></pre></td></tr></table></figure>
<h3 id="4-3-移除缓存"><a href="#4-3-移除缓存" class="headerlink" title="4.3 移除缓存"></a>4.3 移除缓存</h3><p>Spark会自动监视每个节点上的缓存使用情况，并按照最近最少使用（LRU）的规则删除旧数据分区。当然，你也可以使用<code>RDD.unpersist()</code>方法进行手动删除。</p>
<h2 id="五、理解shuffle"><a href="#五、理解shuffle" class="headerlink" title="五、理解shuffle"></a>五、理解shuffle</h2><h3 id="5-1-shuffle介绍"><a href="#5-1-shuffle介绍" class="headerlink" title="5.1 shuffle介绍"></a>5.1 shuffle介绍</h3><p>在Spark中，一个任务对应一个分区，通常不会跨分区操作数据。但如果遇到<code>reduceByKey</code>等操作，Spark必须从所有分区读取数据，并查找所有键的所有值，然后汇总在一起以计算每个键的最终结果 ，这称为<code>Shuffle</code>。</p>
<div align="center"> <img width="600px" src="/img/bigdata/spark-reducebykey.png"> </div>



<h3 id="5-2-Shuffle的影响"><a href="#5-2-Shuffle的影响" class="headerlink" title="5.2 Shuffle的影响"></a>5.2 Shuffle的影响</h3><p>Shuffle是一项昂贵的操作，因为它通常会跨节点操作数据，这会涉及磁盘I/O，网络I/O，和数据序列化。某些Shuffle操作还会消耗大量的堆内存，因为它们使用堆内存来临时存储需要网络传输的数据。Shuffle还会在磁盘上生成大量中间文件，从Spark 1.3开始，这些文件将被保留，直到相应的RDD不再使用并进行垃圾回收，这样做是为了避免在计算时重复创建Shuffle文件。如果应用程序长期保留对这些RDD的引用，则垃圾回收可能在很长一段时间后才会发生，这意味着长时间运行的Spark作业可能会占用大量磁盘空间，通常可以使用<code>spark.local.dir</code>参数来指定这些临时文件的存储目录。</p>
<h3 id="5-3-导致Shuffle的操作"><a href="#5-3-导致Shuffle的操作" class="headerlink" title="5.3 导致Shuffle的操作"></a>5.3 导致Shuffle的操作</h3><p>由于Shuffle操作对性能的影响比较大，所以需要特别注意使用，以下操作都会导致Shuffle：</p>
<ul>
<li><strong>涉及到重新分区操作</strong>： 如<code>repartition</code> 和 <code>coalesce</code>；</li>
<li><strong>所有涉及到ByKey的操作</strong>：如<code>groupByKey</code>和<code>reduceByKey</code>，但<code>countByKey</code>除外；</li>
<li><strong>联结操作</strong>：如<code>cogroup</code>和<code>join</code>。</li>
</ul>
<h2 id="五、宽依赖和窄依赖"><a href="#五、宽依赖和窄依赖" class="headerlink" title="五、宽依赖和窄依赖"></a>五、宽依赖和窄依赖</h2><p>RDD和它的父RDD(s)之间的依赖关系分为两种不同的类型：</p>
<ul>
<li><strong>窄依赖(narrow dependency)</strong>：父RDDs的一个分区最多被子RDDs一个分区所依赖；</li>
<li><strong>宽依赖(wide dependency)</strong>：父RDDs的一个分区可以被子RDDs的多个子分区所依赖。</li>
</ul>
<p>如下图，每一个方框表示一个RDD，带有颜色的矩形表示分区：</p>
<div align="center"> <img width="600px" src="/img/bigdata/spark-yl.png"> </div>



<p>区分这两种依赖是非常有用的：</p>
<ul>
<li>首先，窄依赖允许在一个集群节点上以流水线的方式（pipeline）对父分区数据进行计算，例如先执行map操作，然后执行filter操作。而宽依赖则需要计算好所有父分区的数据，然后再在节点之间进行Shuffle，这与MapReduce类似。</li>
<li>窄依赖能够更有效地进行数据恢复，因为只需重新对丢失分区的父分区进行计算，且不同节点之间可以并行计算；而对于宽依赖而言，如果数据丢失，则需要对所有父分区数据进行计算并再次Shuffle。</li>
</ul>
<h2 id="六、DAG的生成"><a href="#六、DAG的生成" class="headerlink" title="六、DAG的生成"></a>六、DAG的生成</h2><p>RDD(s)及其之间的依赖关系组成了DAG(有向无环图)，DAG定义了这些RDD(s)之间的Lineage(血统)关系，通过血统关系，如果一个RDD的部分或者全部计算结果丢失了，也可以重新进行计算。那么Spark是如何根据DAG来生成计算任务呢？主要是根据依赖关系的不同将DAG划分为不同的计算阶段(Stage)：</p>
<ul>
<li>对于窄依赖，由于分区的依赖关系是确定的，其转换操作可以在同一个线程执行，所以可以划分到同一个执行阶段；</li>
<li>对于宽依赖，由于Shuffle的存在，只能在父RDD(s)被Shuffle处理完成后，才能开始接下来的计算，因此遇到宽依赖就需要重新划分阶段。</li>
</ul>
<div align="center"> <img width="600px" height="600px" src="/img/bigdata/spark-DAG.png"> </div>





<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li>张安站 . Spark技术内幕：深入解析Spark内核架构设计与实现原理[M] . 机械工业出版社 . 2015-09-01</li>
<li><a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-programming-guide" target="_blank" rel="noopener">RDD Programming Guide</a></li>
<li><a href="http://shiyanjun.cn/archives/744.html" target="_blank" rel="noopener">RDD：基于内存的集群计算容错抽象</a></li>
</ol>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="/" target="_blank">Ljjyy.com</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/archives/2019/07/100403.html" class="pre-post btn btn-default" title='Spark Transformation 和 Action 常用算子'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">Spark Transformation 和 Action 常用算子</span>
        </a>
    
    
        <a href="/archives/2019/07/100401.html" class="next-post btn btn-default" title='Spark简介'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">Spark简介</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: '5MzTXYXkt03k101j0PmSDN34-gzGzoHsz',
            appKey: 'iwjYgwno6qj3wtDVVSbe8nYQ',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、RDD简介"><span class="toc-text">一、RDD简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、创建RDD"><span class="toc-text">二、创建RDD</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-由现有集合创建"><span class="toc-text">2.1 由现有集合创建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-引用外部存储系统中的数据集"><span class="toc-text">2.2 引用外部存储系统中的数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-textFile-amp-wholeTextFiles"><span class="toc-text">2.3 textFile &amp; wholeTextFiles</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、操作RDD"><span class="toc-text">三、操作RDD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#四、缓存RDD"><span class="toc-text">四、缓存RDD</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-缓存级别"><span class="toc-text">4.1 缓存级别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-使用缓存"><span class="toc-text">4.2 使用缓存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-移除缓存"><span class="toc-text">4.3 移除缓存</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#五、理解shuffle"><span class="toc-text">五、理解shuffle</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-shuffle介绍"><span class="toc-text">5.1 shuffle介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Shuffle的影响"><span class="toc-text">5.2 Shuffle的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-导致Shuffle的操作"><span class="toc-text">5.3 导致Shuffle的操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#五、宽依赖和窄依赖"><span class="toc-text">五、宽依赖和窄依赖</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#六、DAG的生成"><span class="toc-text">六、DAG的生成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考资料"><span class="toc-text">参考资料</span></a></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019-2023&emsp;<a href="/" class="copyright-links" target="_blank" rel="nofollow">Ljjyy.com</a>
                </span> |
                <span>
                    <a href="/about/" class="copyright-links" target="_blank" rel="nofollow">关于我们</a>
                </span> |                
                <span>
                    <a href="/sitemap.xml" class="copyright-links" target="_blank" rel="nofollow">网站地图</a>
                </span> |
                <span>
                    <a href="/archives/" class="copyright-links" target="_blank" rel="nofollow">时间轴</a>
                </span>              
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>
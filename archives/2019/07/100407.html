<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="https://www.ljjyy.com">
    <!--SEO-->

    <meta name="keywords" content="hadoop,api,spark">


    <meta name="description" content="一、创建DataFrame和Dataset1.1 创建DataFrameSpark中所有功能的入口点是SparkSession，可以使用SparkSession.builder()创建。创建后应...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>Spark Structured API基本使用 | 来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</title>


    <link rel="alternate" href="/atom.xml" title="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
        <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
        <script>LA.init({id: "JgbNOaw1xxsmUUsQ",ck: "JgbNOaw1xxsmUUsQ"})</script>
	</div>






    
    <meta name="baidu-site-verification" content="dTHILoORpx">


    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  >
    <div class="main-header-box">
        <!--a class="header-avatar" href="/" title='Ljjyy.com'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a-->
        <div class="branding">
            
                <h2> 多读书多实践，勤思考善领悟 </h2>
            
    	  </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">

        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="web-logo"  href="/" title='Ljjyy.com'></a>
                    <!--a class="navbar-brand" href="https://www.ljjyy.com">来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</a-->
                </div>
                <div class="collapse navbar-collapse" id="main-menu" style="">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/cloud/"><i class="fa "></i>云计算</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/front/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/back/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/devops/"><i class="fa "></i>运维</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/crack/"><i class="fa "></i>破解</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/penetration/"><i class="fa "></i>渗透</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tool/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/other/"><i class="fa "></i>其他</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="Spark Structured API基本使用">
            
	            Spark Structured API基本使用
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/cloud/">云计算</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/api/">api</a> <a class="tag-link" href="/tags/hadoop/">hadoop</a> <a class="tag-link" href="/tags/spark/">spark</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/07/10</span>
        </span>
        
    
</div>
            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>1376</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <h2 id="一、创建DataFrame和Dataset"><a href="#一、创建DataFrame和Dataset" class="headerlink" title="一、创建DataFrame和Dataset"></a>一、创建DataFrame和Dataset</h2><h3 id="1-1-创建DataFrame"><a href="#1-1-创建DataFrame" class="headerlink" title="1.1 创建DataFrame"></a>1.1 创建DataFrame</h3><p>Spark中所有功能的入口点是<code>SparkSession</code>，可以使用<code>SparkSession.builder()</code>创建。创建后应用程序就可以从现有RDD，Hive表或Spark数据源创建DataFrame。示例如下：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val spark = SparkSession.builder().appName(<span class="string">"Spark-SQL"</span>).master(<span class="string">"local[2]"</span>).getOrCreate()</span><br><span class="line">val df = spark<span class="selector-class">.read</span><span class="selector-class">.json</span>(<span class="string">"/usr/file/json/emp.json"</span>)</span><br><span class="line">df.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 建议在进行spark SQL编程前导入下面的隐式转换，因为DataFrames和dataSets中很多操作都依赖了隐式转换</span></span><br><span class="line">import spark<span class="selector-class">.implicits</span>._</span><br></pre></td></tr></table></figure>
<p>可以使用<code>spark-shell</code>进行测试，需要注意的是<code>spark-shell</code>启动后会自动创建一个名为<code>spark</code>的<code>SparkSession</code>，在命令行中可以直接引用即可：</p>
<div align="center"> <img src="/img/bigdata/spark-sql-shell.png"> </div>

<p><br></p>
<h3 id="1-2-创建Dataset"><a href="#1-2-创建Dataset" class="headerlink" title="1.2 创建Dataset"></a>1.2 创建Dataset</h3><p>Spark支持由内部数据集和外部数据集来创建DataSet，其创建方式分别如下：</p>
<h4 id="1-由外部数据集创建"><a href="#1-由外部数据集创建" class="headerlink" title="1. 由外部数据集创建"></a>1. 由外部数据集创建</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.需要导入隐式转换</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.创建case class,等价于Java Bean</span></span><br><span class="line">case <span class="class"><span class="keyword">class</span> <span class="title">Emp</span></span>(ename: String, comm: <span class="built_in">Double</span>, deptno: <span class="built_in">Long</span>, empno: <span class="built_in">Long</span>, </span><br><span class="line">               hiredate: String, job: String, mgr: <span class="built_in">Long</span>, sal: <span class="built_in">Double</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.由外部数据集创建Datasets</span></span><br><span class="line"><span class="keyword">val</span> ds = spark.read.json(<span class="string">"/usr/file/emp.json"</span>).<span class="keyword">as</span>[Emp]</span><br><span class="line">ds.show()</span><br></pre></td></tr></table></figure>
<h4 id="2-由内部数据集创建"><a href="#2-由内部数据集创建" class="headerlink" title="2. 由内部数据集创建"></a>2. 由内部数据集创建</h4><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.需要导入隐式转换</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.创建case class,等价于Java Bean</span></span><br><span class="line">case <span class="class"><span class="keyword">class</span> <span class="title">Emp</span></span>(ename: String, comm: <span class="built_in">Double</span>, deptno: <span class="built_in">Long</span>, empno: <span class="built_in">Long</span>, </span><br><span class="line">               hiredate: String, job: String, mgr: <span class="built_in">Long</span>, sal: <span class="built_in">Double</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.由内部数据集创建Datasets</span></span><br><span class="line"><span class="keyword">val</span> caseClassDS = Seq(Emp(<span class="string">"ALLEN"</span>, <span class="number">300.0</span>, <span class="number">30</span>, <span class="number">7499</span>, <span class="string">"1981-02-20 00:00:00"</span>, <span class="string">"SALESMAN"</span>, <span class="number">7698</span>, <span class="number">1600.0</span>),</span><br><span class="line">                      Emp(<span class="string">"JONES"</span>, <span class="number">300.0</span>, <span class="number">30</span>, <span class="number">7499</span>, <span class="string">"1981-02-20 00:00:00"</span>, <span class="string">"SALESMAN"</span>, <span class="number">7698</span>, <span class="number">1600.0</span>))</span><br><span class="line">                    .toDS()</span><br><span class="line">caseClassDS.show()</span><br></pre></td></tr></table></figure>
<p><br></p>
<h3 id="1-3-由RDD创建DataFrame"><a href="#1-3-由RDD创建DataFrame" class="headerlink" title="1.3 由RDD创建DataFrame"></a>1.3 由RDD创建DataFrame</h3><p>Spark支持两种方式把RDD转换为DataFrame，分别是使用反射推断和指定Schema转换：</p>
<h4 id="1-使用反射推断"><a href="#1-使用反射推断" class="headerlink" title="1. 使用反射推断"></a>1. 使用反射推断</h4><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.导入隐式转换</span></span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.创建部门类</span></span><br><span class="line"><span class="keyword">case</span> class Dept(deptno: Long, dname: <span class="keyword">String</span>, loc: <span class="keyword">String</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.创建RDD并转换为dataSet</span></span><br><span class="line">val rddToDS = spark.sparkContext</span><br><span class="line">  .textFile(<span class="string">"/usr/file/dept.txt"</span>)</span><br><span class="line">  .<span class="built_in">map</span>(_.<span class="built_in">split</span>(<span class="string">"\t"</span>))</span><br><span class="line">  .<span class="built_in">map</span>(<span class="built_in">line</span> =&gt; Dept(<span class="built_in">line</span>(<span class="number">0</span>).<span class="built_in">trim</span>.toLong, <span class="built_in">line</span>(<span class="number">1</span>), <span class="built_in">line</span>(<span class="number">2</span>)))</span><br><span class="line">  .toDS()  <span class="comment">// 如果调用toDF()则转换为dataFrame</span></span><br></pre></td></tr></table></figure>
<h4 id="2-以编程方式指定Schema"><a href="#2-以编程方式指定Schema" class="headerlink" title="2. 以编程方式指定Schema"></a>2. 以编程方式指定Schema</h4><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.sql</span><span class="selector-class">.Row</span></span><br><span class="line">import org<span class="selector-class">.apache</span><span class="selector-class">.spark</span><span class="selector-class">.sql</span><span class="selector-class">.types</span>._</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.定义每个列的列类型</span></span><br><span class="line">val fields = Array(StructField(<span class="string">"deptno"</span>, LongType, nullable = true),</span><br><span class="line">                   StructField(<span class="string">"dname"</span>, StringType, nullable = true),</span><br><span class="line">                   StructField(<span class="string">"loc"</span>, StringType, nullable = true))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.创建schema</span></span><br><span class="line">val schema = StructType(fields)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.创建RDD</span></span><br><span class="line">val deptRDD = spark<span class="selector-class">.sparkContext</span><span class="selector-class">.textFile</span>(<span class="string">"/usr/file/dept.txt"</span>)</span><br><span class="line">val rowRDD = deptRDD.map(_.split(<span class="string">"\t"</span>)).map(line =&gt; Row(line(<span class="number">0</span>)<span class="selector-class">.toLong</span>, line(<span class="number">1</span>), line(<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 4.将RDD转换为dataFrame</span></span><br><span class="line">val deptDF = spark.createDataFrame(rowRDD, schema)</span><br><span class="line">deptDF.show()</span><br></pre></td></tr></table></figure>
<p><br></p>
<h3 id="1-4-DataFrames与Datasets互相转换"><a href="#1-4-DataFrames与Datasets互相转换" class="headerlink" title="1.4  DataFrames与Datasets互相转换"></a>1.4  DataFrames与Datasets互相转换</h3><p>Spark提供了非常简单的转换方法用于DataFrame与Dataset间的互相转换，示例如下：</p>
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DataFrames转Datasets</span></span><br><span class="line"><span class="keyword">scala&gt; </span>df.as[Emp]</span><br><span class="line"><span class="symbol">res1:</span> <span class="keyword">org.apache.spark.sql.Dataset[Emp] </span>= [COMM: double, DEPTNO: <span class="keyword">bigint </span>... <span class="number">6</span> more fields]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Datasets转DataFrames</span></span><br><span class="line"><span class="keyword">scala&gt; </span>ds.toDF()</span><br><span class="line"><span class="symbol">res2:</span> <span class="keyword">org.apache.spark.sql.DataFrame </span>= [COMM: double, DEPTNO: <span class="keyword">bigint </span>... <span class="number">6</span> more fields]</span><br></pre></td></tr></table></figure>
<p><br></p>
<h2 id="二、Columns列操作"><a href="#二、Columns列操作" class="headerlink" title="二、Columns列操作"></a>二、Columns列操作</h2><h3 id="2-1-引用列"><a href="#2-1-引用列" class="headerlink" title="2.1 引用列"></a>2.1 引用列</h3><p>Spark支持多种方法来构造和引用列，最简单的是使用 <code>col()</code>或 <code>column()</code>函数。</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">col</span>(<span class="string">"colName"</span>)</span><br><span class="line"><span class="selector-tag">column</span>(<span class="string">"colName"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对于Scala语言而言，还可以使用$"myColumn"和'myColumn这两种语法糖进行引用。</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.select</span>($<span class="string">"ename"</span>, $<span class="string">"job"</span>)<span class="selector-class">.show</span>()</span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.select</span>(<span class="string">'ename, '</span>job)<span class="selector-class">.show</span>()</span><br></pre></td></tr></table></figure>
<h3 id="2-2-新增列"><a href="#2-2-新增列" class="headerlink" title="2.2 新增列"></a>2.2 新增列</h3><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 基于已有列值新增列</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.withColumn</span>(<span class="string">"upSal"</span>,$<span class="string">"sal"</span>+<span class="number">1000</span>)</span><br><span class="line"><span class="comment">// 基于固定值新增列</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.withColumn</span>(<span class="string">"intCol"</span>,lit(<span class="number">1000</span>))</span><br></pre></td></tr></table></figure>
<h3 id="2-3-删除列"><a href="#2-3-删除列" class="headerlink" title="2.3 删除列"></a>2.3 删除列</h3><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 支持删除多个列</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.drop</span>(<span class="string">"comm"</span>,<span class="string">"job"</span>)<span class="selector-class">.show</span>()</span><br></pre></td></tr></table></figure>
<h3 id="2-4-重命名列"><a href="#2-4-重命名列" class="headerlink" title="2.4 重命名列"></a>2.4 重命名列</h3><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">df</span><span class="selector-class">.withColumnRenamed</span>(<span class="string">"comm"</span>, <span class="string">"common"</span>)<span class="selector-class">.show</span>()</span><br></pre></td></tr></table></figure>
<p>需要说明的是新增，删除，重命名列都会产生新的DataFrame，原来的DataFrame不会被改变。</p>
<p><br></p>
<h2 id="三、使用Structured-API进行基本查询"><a href="#三、使用Structured-API进行基本查询" class="headerlink" title="三、使用Structured API进行基本查询"></a>三、使用Structured API进行基本查询</h2><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.查询员工姓名及工作</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.select</span>($<span class="string">"ename"</span>, $<span class="string">"job"</span>)<span class="selector-class">.show</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.filter 查询工资大于2000的员工信息</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.filter</span>($<span class="string">"sal"</span> &gt; <span class="number">2000</span>)<span class="selector-class">.show</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.orderBy 按照部门编号降序，工资升序进行查询</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.orderBy</span>(desc(<span class="string">"deptno"</span>), asc(<span class="string">"sal"</span>))<span class="selector-class">.show</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4.limit 查询工资最高的3名员工的信息</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.orderBy</span>(desc(<span class="string">"sal"</span>))<span class="selector-class">.limit</span>(<span class="number">3</span>)<span class="selector-class">.show</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5.distinct 查询所有部门编号</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.select</span>(<span class="string">"deptno"</span>)<span class="selector-class">.distinct</span>()<span class="selector-class">.show</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 6.groupBy 分组统计部门人数</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.groupBy</span>(<span class="string">"deptno"</span>)<span class="selector-class">.count</span>()<span class="selector-class">.show</span>()</span><br></pre></td></tr></table></figure>
<p><br></p>
<h2 id="四、使用Spark-SQL进行基本查询"><a href="#四、使用Spark-SQL进行基本查询" class="headerlink" title="四、使用Spark SQL进行基本查询"></a>四、使用Spark SQL进行基本查询</h2><h3 id="4-1-Spark-SQL基本使用"><a href="#4-1-Spark-SQL基本使用" class="headerlink" title="4.1 Spark  SQL基本使用"></a>4.1 Spark  SQL基本使用</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// 1.首先需要将DataFrame注册为临时视图</span><br><span class="line">df.createOrReplaceTempView("emp")</span><br><span class="line"></span><br><span class="line">// 2.查询员工姓名及工作</span><br><span class="line">spark.sql("<span class="keyword">SELECT</span> ename,job <span class="keyword">FROM</span> emp<span class="string">").show()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 3.查询工资大于2000的员工信息</span></span><br><span class="line"><span class="string">spark.sql("</span><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> emp <span class="keyword">where</span> sal &gt; <span class="number">2000</span><span class="string">").show()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 4.orderBy 按照部门编号降序，工资升序进行查询</span></span><br><span class="line"><span class="string">spark.sql("</span><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> emp <span class="keyword">ORDER</span> <span class="keyword">BY</span> deptno <span class="keyword">DESC</span>,sal <span class="keyword">ASC</span><span class="string">").show()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 5.limit  查询工资最高的3名员工的信息</span></span><br><span class="line"><span class="string">spark.sql("</span><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> emp <span class="keyword">ORDER</span> <span class="keyword">BY</span> sal <span class="keyword">DESC</span> <span class="keyword">LIMIT</span> <span class="number">3</span><span class="string">").show()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 6.distinct 查询所有部门编号</span></span><br><span class="line"><span class="string">spark.sql("</span><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span>(deptno) <span class="keyword">FROM</span> emp<span class="string">").show()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">// 7.分组统计部门人数</span></span><br><span class="line"><span class="string">spark.sql("</span><span class="keyword">SELECT</span> deptno,<span class="keyword">count</span>(ename) <span class="keyword">FROM</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno<span class="string">").show()</span></span><br></pre></td></tr></table></figure>
<h3 id="4-2-全局临时视图"><a href="#4-2-全局临时视图" class="headerlink" title="4.2 全局临时视图"></a>4.2 全局临时视图</h3><p>上面使用<code>createOrReplaceTempView</code>创建的是会话临时视图，它的生命周期仅限于会话范围，会随会话的结束而结束。</p>
<p>你也可以使用<code>createGlobalTempView</code>创建全局临时视图，全局临时视图可以在所有会话之间共享，并直到整个Spark应用程序终止后才会消失。全局临时视图被定义在内置的<code>global_temp</code>数据库下，需要使用限定名称进行引用，如<code>SELECT * FROM global_temp.view1</code>。</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注册为全局临时视图</span></span><br><span class="line"><span class="selector-tag">df</span><span class="selector-class">.createGlobalTempView</span>(<span class="string">"gemp"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用限定名称进行引用</span></span><br><span class="line"><span class="selector-tag">spark</span><span class="selector-class">.sql</span>(<span class="string">"SELECT ename,job FROM global_temp.gemp"</span>)<span class="selector-class">.show</span>()</span><br></pre></td></tr></table></figure>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://spark.apache.org/docs/latest/sql-getting-started.html" target="_blank" rel="noopener">Spark SQL, DataFrames and Datasets Guide &gt; Getting Started</a></p>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="/" target="_blank">Ljjyy.com</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/archives/2019/07/100408.html" class="pre-post btn btn-default" title='Spark SQL外部数据源'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">Spark SQL外部数据源</span>
        </a>
    
    
        <a href="/archives/2019/07/100406.html" class="next-post btn btn-default" title='Spark DataFrame和Dataset简介'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">Spark DataFrame和Dataset简介</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: '5MzTXYXkt03k101j0PmSDN34-gzGzoHsz',
            appKey: 'iwjYgwno6qj3wtDVVSbe8nYQ',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、创建DataFrame和Dataset"><span class="toc-text">一、创建DataFrame和Dataset</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-创建DataFrame"><span class="toc-text">1.1 创建DataFrame</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-创建Dataset"><span class="toc-text">1.2 创建Dataset</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-由外部数据集创建"><span class="toc-text">1. 由外部数据集创建</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-由内部数据集创建"><span class="toc-text">2. 由内部数据集创建</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-由RDD创建DataFrame"><span class="toc-text">1.3 由RDD创建DataFrame</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-使用反射推断"><span class="toc-text">1. 使用反射推断</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-以编程方式指定Schema"><span class="toc-text">2. 以编程方式指定Schema</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-DataFrames与Datasets互相转换"><span class="toc-text">1.4  DataFrames与Datasets互相转换</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、Columns列操作"><span class="toc-text">二、Columns列操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-引用列"><span class="toc-text">2.1 引用列</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-新增列"><span class="toc-text">2.2 新增列</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-删除列"><span class="toc-text">2.3 删除列</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-重命名列"><span class="toc-text">2.4 重命名列</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、使用Structured-API进行基本查询"><span class="toc-text">三、使用Structured API进行基本查询</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#四、使用Spark-SQL进行基本查询"><span class="toc-text">四、使用Spark SQL进行基本查询</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Spark-SQL基本使用"><span class="toc-text">4.1 Spark  SQL基本使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-全局临时视图"><span class="toc-text">4.2 全局临时视图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考资料"><span class="toc-text">参考资料</span></a></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019-2023&emsp;<a href="/" class="copyright-links" target="_blank" rel="nofollow">Ljjyy.com</a>
                </span> |
                <span>
                    <a href="/about/" class="copyright-links" target="_blank" rel="nofollow">关于我们</a>
                </span> |                
                <span>
                    <a href="/sitemap.xml" class="copyright-links" target="_blank" rel="nofollow">网站地图</a>
                </span> |
                <span>
                    <a href="/archives/" class="copyright-links" target="_blank" rel="nofollow">时间轴</a>
                </span>              
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>
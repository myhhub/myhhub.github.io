<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="https://www.ljjyy.com">
    <!--SEO-->

    <meta name="keywords" content="hadoop,hdfs,shell">


    <meta name="description" content="HDFS文件操作&#160; &#160; &#160; &#160;HDFS是一种文件系统,专为MapReduce这类框架下的大规模分布式数据处理而设计,你可以把一个大数据集(比如说100TB...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>hadoop HDFS常用Shell命令 | 来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</title>


    <link rel="alternate" href="/atom.xml" title="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
        <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
        <script>LA.init({id: "JgbNOaw1xxsmUUsQ",ck: "JgbNOaw1xxsmUUsQ"})</script>
	</div>






    
    <meta name="baidu-site-verification" content="dTHILoORpx">


    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  >
    <div class="main-header-box">
        <!--a class="header-avatar" href="/" title='Ljjyy.com'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a-->
        <div class="branding">
            
                <h2> 多读书多实践，勤思考善领悟 </h2>
            
    	  </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">

        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="web-logo"  href="/" title='Ljjyy.com'></a>
                    <!--a class="navbar-brand" href="https://www.ljjyy.com">来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</a-->
                </div>
                <div class="collapse navbar-collapse" id="main-menu" style="">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/cloud/"><i class="fa "></i>云计算</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/front/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/back/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/devops/"><i class="fa "></i>运维</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/crack/"><i class="fa "></i>破解</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/penetration/"><i class="fa "></i>渗透</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tool/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/other/"><i class="fa "></i>其他</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="hadoop HDFS常用Shell命令">
            
	            hadoop HDFS常用Shell命令
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/cloud/">云计算</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/hadoop/">hadoop</a> <a class="tag-link" href="/tags/hdfs/">hdfs</a> <a class="tag-link" href="/tags/shell/">shell</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/07/09</span>
        </span>
        
    
</div>
            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>1533</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <h2 id="HDFS文件操作"><a href="#HDFS文件操作" class="headerlink" title="HDFS文件操作"></a>HDFS文件操作</h2><p>&#160; &#160; &#160; &#160;HDFS是一种文件系统,专为MapReduce这类框架下的大规模分布式数据处理而设计,你可以把一个大数据集(比如说100TB)在HDFS中存储为单个文件,而大多数其他的文件系统无力实现这一点.<br>&#160; &#160; &#160; &#160;HDFS并不是一个天生的UNIX文件系统,不支持像ls和cp这种标准的UNIX文件命令,也不支持如fopen()和fread()这样的标准文件读写操作.另一方面,Hadoop确也提供了一套与Linux文件命令类似的命令行工具.</p>
<h3 id="基本文件fs命令"><a href="#基本文件fs命令" class="headerlink" title="基本文件fs命令"></a>基本文件fs命令</h3><p>Hadoop的文件命令采取的形式为</p>
<p><code>hadoop fs -cmd &lt;args&gt;</code>  </p>
<p>基中cmd是具体的文件命令,而<code>&lt;args&gt;</code>是一组数据可变的参数.<code>cmd</code>的命名通常与unix对应的命令名相同.例如,文件形表命令为  </p>
<figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hadoop <span class="built_in">fs</span> -ls  </span><br><span class="line"></span><br><span class="line">hadoop <span class="built_in">fs</span> -<span class="built_in">mkdir</span> /user/chuck</span><br><span class="line">hadoop <span class="built_in">fs</span> -ls /</span><br><span class="line">hadoop <span class="built_in">fs</span> -put example.txt /user/chuck</span><br><span class="line">hadoop <span class="built_in">fs</span> -ls</span><br><span class="line">hadoop <span class="built_in">fs</span> -get example.txt .</span><br><span class="line">hadoop <span class="built_in">fs</span> -cat example.txt</span><br><span class="line">hadoop <span class="built_in">fs</span> -rm  example.txt</span><br></pre></td></tr></table></figure>
<h4 id="1-显示当前目录结构"><a href="#1-显示当前目录结构" class="headerlink" title="1. 显示当前目录结构"></a><strong>1. 显示当前目录结构</strong></h4><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 显示当前目录结构</span></span><br><span class="line">hadoop fs -ls  &lt;path&gt;</span><br><span class="line"><span class="meta"># 递归显示当前目录结构</span></span><br><span class="line">hadoop fs -ls  -R  &lt;path&gt;</span><br><span class="line"><span class="meta"># 显示根目录下内容</span></span><br><span class="line">hadoop fs -ls  /</span><br></pre></td></tr></table></figure>
<h4 id="2-创建目录"><a href="#2-创建目录" class="headerlink" title="2. 创建目录"></a><strong>2. 创建目录</strong></h4><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 创建目录</span><br><span class="line">hadoop <span class="built_in">fs</span> -<span class="built_in">mkdir</span>  &lt;<span class="built_in">path</span>&gt; </span><br><span class="line"># 递归创建目录</span><br><span class="line">hadoop <span class="built_in">fs</span> -<span class="built_in">mkdir</span> -p  &lt;<span class="built_in">path</span>&gt;</span><br></pre></td></tr></table></figure>
<p><strong>3. 删除操作</strong></p>
<figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 删除文件</span><br><span class="line">hadoop <span class="built_in">fs</span> -rm  &lt;<span class="built_in">path</span>&gt;</span><br><span class="line"># 递归删除目录和文件</span><br><span class="line">hadoop <span class="built_in">fs</span> -rm -R  &lt;<span class="built_in">path</span>&gt;</span><br></pre></td></tr></table></figure>
<h4 id="4-从本地加载文件到HDFS"><a href="#4-从本地加载文件到HDFS" class="headerlink" title="4. 从本地加载文件到HDFS"></a><strong>4. 从本地加载文件到HDFS</strong></h4><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 二选一执行即可</span><br><span class="line">hadoop fs -put  <span class="string">[localsrc]</span> <span class="string">[dst]</span> </span><br><span class="line">hadoop fs - copyFromLocal <span class="string">[localsrc]</span> <span class="string">[dst]</span></span><br></pre></td></tr></table></figure>
<h4 id="5-从HDFS导出文件到本地"><a href="#5-从HDFS导出文件到本地" class="headerlink" title="5. 从HDFS导出文件到本地"></a><strong>5. 从HDFS导出文件到本地</strong></h4><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 二选一执行即可</span><br><span class="line">hadoop fs -get  <span class="string">[dst]</span> <span class="string">[localsrc]</span> </span><br><span class="line">hadoop fs -copyToLocal <span class="string">[dst]</span> <span class="string">[localsrc]</span></span><br></pre></td></tr></table></figure>
<p><strong>6. 查看文件内容</strong></p>
<figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 二选一执行即可</span><br><span class="line">hadoop <span class="built_in">fs</span> -text  &lt;<span class="built_in">path</span>&gt; </span><br><span class="line">hadoop <span class="built_in">fs</span> -cat  &lt;<span class="built_in">path</span>&gt;</span><br></pre></td></tr></table></figure>
<h4 id="7-显示文件的最后一千字节"><a href="#7-显示文件的最后一千字节" class="headerlink" title="7. 显示文件的最后一千字节"></a><strong>7. 显示文件的最后一千字节</strong></h4><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop <span class="built_in">fs</span> -tail  &lt;<span class="built_in">path</span>&gt; </span><br><span class="line"># 和Linux下一样，会持续监听文件内容变化 并显示文件的最后一千字节</span><br><span class="line">hadoop <span class="built_in">fs</span> -tail -f  &lt;<span class="built_in">path</span>&gt;</span><br></pre></td></tr></table></figure>
<h4 id="8-拷贝文件"><a href="#8-拷贝文件" class="headerlink" title="8. 拷贝文件"></a><strong>8. 拷贝文件</strong></h4><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp <span class="string">[src]</span> <span class="string">[dst]</span></span><br></pre></td></tr></table></figure>
<h4 id="9-移动文件"><a href="#9-移动文件" class="headerlink" title="9. 移动文件"></a><strong>9. 移动文件</strong></h4><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv <span class="string">[src]</span> <span class="string">[dst]</span></span><br></pre></td></tr></table></figure>
<h4 id="10-统计当前目录下各文件大小"><a href="#10-统计当前目录下各文件大小" class="headerlink" title="10. 统计当前目录下各文件大小"></a><strong>10. 统计当前目录下各文件大小</strong></h4><ul>
<li>默认单位字节</li>
<li>-s : 显示所有文件大小总和，</li>
<li>-h : 将以更友好的方式显示文件大小（例如64.0m而不是67108864）</li>
</ul>
<figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop <span class="built_in">fs</span> -du  &lt;<span class="built_in">path</span>&gt;</span><br></pre></td></tr></table></figure>
<h4 id="11-合并下载多个文件"><a href="#11-合并下载多个文件" class="headerlink" title="11. 合并下载多个文件"></a><strong>11. 合并下载多个文件</strong></h4><ul>
<li>-nl 在每个文件的末尾添加换行符（LF）</li>
<li>-skip-empty-file 跳过空文件</li>
</ul>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -getmerge</span><br><span class="line"><span class="comment"># 示例 将HDFS上的hbase-policy.xml和hbase-site.xml文件合并后下载到本地的/usr/test.xml</span></span><br><span class="line">hadoop fs -getmerge -nl  /test/hbase-policy.<span class="keyword">xml</span> <span class="title">/test</span>/hbase-site.<span class="keyword">xml</span> <span class="title">/usr</span>/test.xml</span><br></pre></td></tr></table></figure>
<h4 id="12-统计文件系统的可用空间信息"><a href="#12-统计文件系统的可用空间信息" class="headerlink" title="12. 统计文件系统的可用空间信息"></a><strong>12. 统计文件系统的可用空间信息</strong></h4><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop <span class="built_in">fs</span> -df -h /</span><br></pre></td></tr></table></figure>
<h4 id="13-更改文件复制因子"><a href="#13-更改文件复制因子" class="headerlink" title="13. 更改文件复制因子"></a><strong>13. 更改文件复制因子</strong></h4><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep <span class="string">[-R]</span> <span class="string">[-w]</span> &lt;numReplicas&gt; &lt;path&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>更改文件的复制因子。如果path是目录，则更改其下所有文件的复制因子</li>
<li>-w : 请求命令是否等待复制完成</li>
</ul>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例</span></span><br><span class="line">hadoop fs -setrep -w <span class="number">3</span> <span class="regexp">/user/</span>hadoop<span class="regexp">/dir1</span></span><br></pre></td></tr></table></figure>
<h4 id="14-权限控制"><a href="#14-权限控制" class="headerlink" title="14. 权限控制"></a><strong>14. 权限控制</strong></h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># 权限控制和Linux上使用方式一致</span></span><br><span class="line"><span class="section"># 变更文件或目录的所属群组。 用户必须是文件的所有者或超级用户。</span></span><br><span class="line">hadoop fs -chgrp [-R] GROUP URI [URI ...]</span><br><span class="line"><span class="section"># 修改文件或目录的访问权限  用户必须是文件的所有者或超级用户。</span></span><br><span class="line">hadoop fs -chmod [-R] <span class="xml"><span class="tag">&lt;<span class="name">MODE[,MODE]...</span> | <span class="attr">OCTALMODE</span>&gt;</span></span> URI [URI ...]</span><br><span class="line"><span class="section"># 修改文件的拥有者  用户必须是超级用户。</span></span><br><span class="line">hadoop fs -chown [<span class="string">-R</span>] [<span class="string">OWNER</span>][<span class="symbol">:[GROUP</span>]] URI [URI ]</span><br></pre></td></tr></table></figure>
<h4 id="15-文件检测"><a href="#15-文件检测" class="headerlink" title="15. 文件检测"></a><strong>15. 文件检测</strong></h4><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop <span class="built_in">fs</span> -<span class="keyword">test</span> - [defsz]  URI</span><br></pre></td></tr></table></figure>
<p>可选选项：</p>
<ul>
<li>-d：如果路径是目录，返回0。</li>
<li>-e：如果路径存在，则返回0。</li>
<li>-f：如果路径是文件，则返回0。</li>
<li>-s：如果路径不为空，则返回0。</li>
<li>-r：如果路径存在且授予读权限，则返回0。</li>
<li>-w：如果路径存在且授予写入权限，则返回0。</li>
<li>-z：如果文件长度为零，则返回0。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例</span></span><br><span class="line">hadoop fs -<span class="built_in">test</span> -e filename</span><br></pre></td></tr></table></figure>
<h3 id="cat命令"><a href="#cat命令" class="headerlink" title="cat命令"></a>cat命令</h3><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">将路径指定文件的内容输出到stdout</span><br><span class="line">hadoop<span class="variable">@Master</span><span class="symbol">:~</span><span class="variable">$ </span>hadoop dfs -cat input/core-site.xml</span><br></pre></td></tr></table></figure>
<h3 id="chgrp命令"><a href="#chgrp命令" class="headerlink" title="chgrp命令"></a>chgrp命令</h3><figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">改变文件所属组.使用-R将使改变在目录结构下递归进行.命令的使用者必须是文件的所有者或者超级用户.</span><br></pre></td></tr></table></figure>
<h3 id="chmod命令"><a href="#chmod命令" class="headerlink" title="chmod命令"></a>chmod命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修改文件权限</span><br></pre></td></tr></table></figure>
<h3 id="chown命令"><a href="#chown命令" class="headerlink" title="chown命令"></a>chown命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">改变文件的拥有者</span><br></pre></td></tr></table></figure>
<h3 id="cp命令"><a href="#cp命令" class="headerlink" title="cp命令"></a>cp命令</h3><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">将文件从源路径复制到目标路径,这个命令允许有多个源路径,此时目标路径必须是一个目录</span><br><span class="line">hadoop@<span class="literal">Master</span>:/usr/local/hadoop/etc/hadoop$ hdfs dfs -cp input/* output/</span><br><span class="line">hadoop@<span class="literal">Master</span>:/usr/local/hadoop/etc/hadoop$ hdfs dfs -ls output</span><br><span class="line">Found <span class="number">11</span> items</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup          <span class="number">0</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">25</span> <span class="number">22</span>:<span class="number">14</span> output/_SUCCESS</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup       <span class="number">4436</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/capacity-scheduler.xml</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup       <span class="number">1072</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/core-site.xml</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup       <span class="number">9683</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/hadoop-policy.xml</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup       <span class="number">1257</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/hdfs-site.xml</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup        <span class="number">620</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/httpfs-site.xml</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup       <span class="number">3523</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/kms-acls.xml</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup       <span class="number">5511</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/kms-site.xml</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup       <span class="number">1103</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/mapred-site.xml</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup        <span class="number">107</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">25</span> <span class="number">22</span>:<span class="number">14</span> output/part-r-<span class="number">00000</span></span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup        <span class="number">924</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/yarn-site.xml</span><br></pre></td></tr></table></figure>
<h3 id="du命令"><a href="#du命令" class="headerlink" title="du命令"></a>du命令</h3><p>显示目录中所有文件的大小,或者当只指定一个文件时,显示此文件的大小.<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop<span class="variable">@Master</span><span class="symbol">:/usr/local/hadoop/etc/hadoop</span><span class="variable">$ </span>hadoop fs -du input/core-site.xml</span><br></pre></td></tr></table></figure></p>
<h3 id="expunge命令"><a href="#expunge命令" class="headerlink" title="expunge命令"></a>expunge命令</h3><p>清空回收站<br>除了文件权限之外,还有一个保护机制可以防止在HDFS上意外删除文件,这就是回收站,默认情况下该功能是被禁用.当它启用后,用于删除的命令行不会立即删除文件.<br>相反它们会暂时的把文件移动到用户工作目录下的.Trash文件夹下.若要启用回收站功能并设置清空回收站的时间延迟,可能通过设置core-site.xml的fs.trash.interval属性(以分钟为单位).<br>例如如果你希望用户有24个小时的时间来还原已删除的文件,就应该在core-site.xml中设置.<br>如果将该值设置为0,则将禁用回收站的功能</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="get命令"><a href="#get命令" class="headerlink" title="get命令"></a>get命令</h3><p>复制文件到本地文件系统.<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get input/hadoop<span class="selector-class">.tar</span><span class="selector-class">.gz</span> ~/</span><br></pre></td></tr></table></figure></p>
<h3 id="lsr命令"><a href="#lsr命令" class="headerlink" title="lsr命令"></a>lsr命令</h3><p>ls命令的递归版本,类似于Unix中的ls -R</p>
<p>###mkdir命令</p>
<p>接受路径指定的uri作为参数,创建这些目录,其行为类似于Unix的mkdir -p,它会创建路径中的各级父目录.<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir <span class="regexp">/user/</span>hadoop<span class="regexp">/dir1 /u</span>ser<span class="regexp">/hadoop/</span>dir2</span><br></pre></td></tr></table></figure></p>
<h3 id="mv命令"><a href="#mv命令" class="headerlink" title="mv命令"></a>mv命令</h3><p>将文件从源路径移动到目标路径<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv <span class="regexp">/user/</span>hadoop<span class="regexp">/file1 /u</span>ser<span class="regexp">/hadoop/</span>file2</span><br></pre></td></tr></table></figure></p>
<h3 id="put命令"><a href="#put命令" class="headerlink" title="put命令"></a>put命令</h3><p>从本地文件系统中复制单个或者多个源路径到目标文件系统.也支持从标准输入中读取输入写入目标文件系统.<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put /tmp/*.<span class="keyword">xml</span> <span class="title">/user</span>/hadoop/</span><br></pre></td></tr></table></figure></p>
<h3 id="rmr命令"><a href="#rmr命令" class="headerlink" title="rmr命令"></a>rmr命令</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rmr <span class="regexp">/user/</span>hadoop<span class="regexp">/chu888chu888</span></span><br></pre></td></tr></table></figure>
<h3 id="job命令"><a href="#job命令" class="headerlink" title="job命令"></a>job命令</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">* Job操作</span><br><span class="line">* 提交MapReduce Job, Hadoop所有的MapReduce Job都是一个jar包</span><br><span class="line">* $ hadoop jar &lt;local-jar-file&gt; &lt;java-<span class="class"><span class="keyword">class</span>&gt; &lt;hdfs-<span class="title">input</span>-<span class="title">file</span>&gt; &lt;hdfs-<span class="title">output</span>-<span class="title">dir</span>&gt;</span></span><br><span class="line">* $ hadoop jar sandbox-mapred-<span class="number">0</span>.<span class="number">0</span>.<span class="number">20</span>.jar sandbox.mapred.WordCountJob /user/cl/input.dat /user/cl/outputdir</span><br><span class="line">*</span><br><span class="line">* 杀死某个正在运行的Job</span><br><span class="line">* 假设Job_Id为：job_201207121738_0001</span><br><span class="line">* $ hadoop job -kill job_201207121738_0001</span><br></pre></td></tr></table></figure>
<h3 id="系统体检"><a href="#系统体检" class="headerlink" title="系统体检"></a>系统体检</h3><p>Hadoop提供的文件系统检查工具叫做fsck,如参数为文件路径时,它会递归检查该路径下所有文件的健康状态,如果参数为/,它就会检查整个文件系统,如下输出一个例子.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">hadoop@Master:~$ hadoop fsck /</span><br><span class="line">DEPRECATED: <span class="keyword">Use</span> <span class="keyword">of</span> this script <span class="keyword">to</span> <span class="keyword">execute</span> hdfs command <span class="keyword">is</span> deprecated.</span><br><span class="line">Instead <span class="keyword">use</span> the hdfs command <span class="keyword">for</span> it.</span><br><span class="line"></span><br><span class="line"><span class="number">16</span>/<span class="number">01</span>/<span class="number">27</span> <span class="number">22</span>:<span class="number">55</span>:<span class="number">14</span> WARN util.NativeCodeLoader: Unable <span class="keyword">to</span> <span class="keyword">load</span> <span class="keyword">native</span>-hadoop <span class="keyword">library</span> <span class="keyword">for</span> your platform... <span class="keyword">using</span> builtin-<span class="keyword">java</span> classes <span class="keyword">where</span> applicable</span><br><span class="line">Connecting <span class="keyword">to</span> namenode via <span class="keyword">http</span>://<span class="keyword">Master</span>:<span class="number">50070</span></span><br><span class="line">FSCK started <span class="keyword">by</span> hadoop (auth:SIMPLE) <span class="keyword">from</span> /<span class="number">192.168</span><span class="number">.1</span><span class="number">.80</span> <span class="keyword">for</span> <span class="keyword">path</span> / <span class="keyword">at</span> Wed Jan <span class="number">27</span> <span class="number">22</span>:<span class="number">55</span>:<span class="number">15</span> CST <span class="number">2016</span></span><br><span class="line">.....................Status: HEALTHY</span><br><span class="line"> Total <span class="keyword">size</span>:	<span class="number">878899</span> B</span><br><span class="line"> Total dirs:	<span class="number">21</span></span><br><span class="line"> Total files:	<span class="number">21</span></span><br><span class="line"> Total symlinks:		<span class="number">0</span></span><br><span class="line"> Total blocks (validated):	<span class="number">20</span> (avg. <span class="keyword">block</span> <span class="keyword">size</span> <span class="number">43944</span> B)</span><br><span class="line"> Minimally replicated blocks:	<span class="number">20</span> (<span class="number">100.0</span> %)</span><br><span class="line"> <span class="keyword">Over</span>-replicated blocks:	<span class="number">0</span> (<span class="number">0.0</span> %)</span><br><span class="line"> <span class="keyword">Under</span>-replicated blocks:	<span class="number">0</span> (<span class="number">0.0</span> %)</span><br><span class="line"> Mis-replicated blocks:		<span class="number">0</span> (<span class="number">0.0</span> %)</span><br><span class="line"> <span class="keyword">Default</span> <span class="keyword">replication</span> factor:	<span class="number">1</span></span><br><span class="line"> Average <span class="keyword">block</span> <span class="keyword">replication</span>:	<span class="number">1.0</span></span><br><span class="line"> Corrupt blocks:		<span class="number">0</span></span><br><span class="line"> <span class="keyword">Missing</span> replicas:		<span class="number">0</span> (<span class="number">0.0</span> %)</span><br><span class="line"> <span class="built_in">Number</span> <span class="keyword">of</span> <span class="keyword">data</span>-nodes:		<span class="number">2</span></span><br><span class="line"> <span class="built_in">Number</span> <span class="keyword">of</span> racks:		<span class="number">1</span></span><br><span class="line">FSCK ended <span class="keyword">at</span> Wed Jan <span class="number">27</span> <span class="number">22</span>:<span class="number">55</span>:<span class="number">15</span> CST <span class="number">2016</span> <span class="keyword">in</span> <span class="number">32</span> milliseconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">The filesystem <span class="keyword">under</span> <span class="keyword">path</span> <span class="string">'/'</span> <span class="keyword">is</span> HEALTHY</span><br></pre></td></tr></table></figure>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="/" target="_blank">Ljjyy.com</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/archives/2019/07/100461.html" class="pre-post btn btn-default" title='hadoop HDFS Java API的使用'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">hadoop HDFS Java API的使用</span>
        </a>
    
    
        <a href="/archives/2019/07/100393.html" class="next-post btn btn-default" title='hadoop集群资源管理器——YARN'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">hadoop集群资源管理器——YARN</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: '5MzTXYXkt03k101j0PmSDN34-gzGzoHsz',
            appKey: 'iwjYgwno6qj3wtDVVSbe8nYQ',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS文件操作"><span class="toc-text">HDFS文件操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#基本文件fs命令"><span class="toc-text">基本文件fs命令</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-显示当前目录结构"><span class="toc-text">1. 显示当前目录结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-创建目录"><span class="toc-text">2. 创建目录</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-从本地加载文件到HDFS"><span class="toc-text">4. 从本地加载文件到HDFS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-从HDFS导出文件到本地"><span class="toc-text">5. 从HDFS导出文件到本地</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-显示文件的最后一千字节"><span class="toc-text">7. 显示文件的最后一千字节</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-拷贝文件"><span class="toc-text">8. 拷贝文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-移动文件"><span class="toc-text">9. 移动文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-统计当前目录下各文件大小"><span class="toc-text">10. 统计当前目录下各文件大小</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-合并下载多个文件"><span class="toc-text">11. 合并下载多个文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-统计文件系统的可用空间信息"><span class="toc-text">12. 统计文件系统的可用空间信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-更改文件复制因子"><span class="toc-text">13. 更改文件复制因子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-权限控制"><span class="toc-text">14. 权限控制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-文件检测"><span class="toc-text">15. 文件检测</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cat命令"><span class="toc-text">cat命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#chgrp命令"><span class="toc-text">chgrp命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#chmod命令"><span class="toc-text">chmod命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#chown命令"><span class="toc-text">chown命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cp命令"><span class="toc-text">cp命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#du命令"><span class="toc-text">du命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#expunge命令"><span class="toc-text">expunge命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#get命令"><span class="toc-text">get命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lsr命令"><span class="toc-text">lsr命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mv命令"><span class="toc-text">mv命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#put命令"><span class="toc-text">put命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rmr命令"><span class="toc-text">rmr命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#job命令"><span class="toc-text">job命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#系统体检"><span class="toc-text">系统体检</span></a></li></ol></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019-2023&emsp;<a href="/" class="copyright-links" target="_blank" rel="nofollow">Ljjyy.com</a>
                </span> |
                <span>
                    <a href="/about/" class="copyright-links" target="_blank" rel="nofollow">关于我们</a>
                </span> |                
                <span>
                    <a href="/sitemap.xml" class="copyright-links" target="_blank" rel="nofollow">网站地图</a>
                </span> |
                <span>
                    <a href="/archives/" class="copyright-links" target="_blank" rel="nofollow">时间轴</a>
                </span>              
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>
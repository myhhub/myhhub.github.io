<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="https://www.ljjyy.com">
    <!--SEO-->

    <meta name="keywords" content="hadoop">


    <meta name="description" content="1. 网络拓扑
192.168.1.80 Master
192.168.1.82 Slave1
192.168.1.84 Slave2

2. 安装JDK所有实验主机都需要正确的安装JDK,具体...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>大数据hadoop之 十.Hadoop的完全分布式搭建 | 来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</title>


    <link rel="alternate" href="/atom.xml" title="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
        <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
        <script>LA.init({id: "JgbNOaw1xxsmUUsQ",ck: "JgbNOaw1xxsmUUsQ"})</script>
	</div>






    
    <meta name="baidu-site-verification" content="dTHILoORpx">


    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  >
    <div class="main-header-box">
        <!--a class="header-avatar" href="/" title='Ljjyy.com'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a-->
        <div class="branding">
            
                <h2> 多读书多实践，勤思考善领悟 </h2>
            
    	  </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">

        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="web-logo"  href="/" title='Ljjyy.com'></a>
                    <!--a class="navbar-brand" href="https://www.ljjyy.com">来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</a-->
                </div>
                <div class="collapse navbar-collapse" id="main-menu" style="">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/cloud/"><i class="fa "></i>云计算</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/front/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/back/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/devops/"><i class="fa "></i>运维</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/crack/"><i class="fa "></i>破解</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/penetration/"><i class="fa "></i>渗透</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tool/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/other/"><i class="fa "></i>其他</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="大数据hadoop之 十.Hadoop的完全分布式搭建">
            
	            大数据hadoop之 十.Hadoop的完全分布式搭建
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/cloud/">云计算</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/hadoop/">hadoop</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/06/09</span>
        </span>
        
    
</div>
            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>1488</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <h2 id="1-网络拓扑"><a href="#1-网络拓扑" class="headerlink" title="1. 网络拓扑"></a>1. 网络拓扑</h2><ul>
<li>192.168.1.80 Master</li>
<li>192.168.1.82 Slave1</li>
<li>192.168.1.84 Slave2</li>
</ul>
<h2 id="2-安装JDK"><a href="#2-安装JDK" class="headerlink" title="2. 安装JDK"></a>2. 安装JDK</h2><p>所有实验主机都需要正确的安装JDK,具体操作方法  </p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">chu888chu888@<span class="symbol">ubuntu1:</span>~$ tar xvfz jdk-<span class="number">8</span>u65-linux-x64.gz</span><br><span class="line">chu888chu888@<span class="symbol">ubuntu1:</span>~$ sudo cp -r jdk1.<span class="number">8.0_65</span>/ <span class="regexp">/usr/lib</span><span class="regexp">/jvm/</span></span><br><span class="line">chu888chu888@<span class="symbol">ubuntu1:</span>/usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>$ <span class="title">sudo</span> <span class="title">nano</span> /<span class="title">etc</span>/<span class="title">profile</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">#修改内容如下,注意大小写</span></span><br><span class="line"><span class="comment">#在环境变量中的配置中,有一点需要指出就是如果只是编辑~/.profile的话这个变量的生效只是针对当前用户的.</span></span><br><span class="line"><span class="comment">#如果想要其在全局生效的话,建议更新/etc/profile,这是一个全局的.</span></span><br><span class="line"></span><br><span class="line">export JAVA_HOME=<span class="regexp">/usr/lib</span><span class="regexp">/jvm/</span></span><br><span class="line">export JRE_HOME=$&#123;JAVA_HOME&#125;/jre</span><br><span class="line">export CLASSPATH=.:$&#123;JAVA_HOME&#125;/<span class="class"><span class="keyword">lib</span>:$&#123;<span class="title">JRE_HOME</span>&#125;/<span class="title">lib</span></span></span><br><span class="line">export PATH=$&#123;JAVA_HOME&#125;/<span class="symbol">bin:</span>$PATH</span><br><span class="line"></span><br><span class="line">chu888chu888@<span class="symbol">ubuntu1:</span>/usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>$ <span class="title">source</span> /<span class="title">etc</span>/<span class="title">profile</span> </span></span><br><span class="line">chu888chu888@<span class="symbol">ubuntu1:</span>/usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>$ <span class="title">env</span></span></span><br><span class="line">chu888chu888@<span class="symbol">ubuntu1:</span>/usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>$ <span class="title">java</span> -<span class="title">version</span></span></span><br><span class="line">java version <span class="string">"1.8.0_65"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build <span class="number">1.8</span>.<span class="number">0</span>_65-b17)</span><br><span class="line">Java HotSpot(TM) <span class="number">64</span>-Bit Server VM (build <span class="number">25.65</span>-b01, mixed mode)</span><br><span class="line"></span><br><span class="line"><span class="comment">#有一种极端情况就是,如果在本机已经安装了OpenJavaSDK,怎么办?</span></span><br><span class="line">sudo update-alternatives --install /usr/bin/java java /usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>/<span class="title">java</span>/<span class="title">bin</span>/<span class="title">java</span> 300  </span></span><br><span class="line">sudo update-alternatives --install /usr/bin/javac javac /usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>/<span class="title">java</span>/<span class="title">bin</span>/<span class="title">javac</span> 300  </span></span><br><span class="line">sudo update-alternatives --install /usr/bin/jar jar /usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>/<span class="title">java</span>/<span class="title">bin</span>/<span class="title">jar</span> 300   </span></span><br><span class="line">sudo update-alternatives --install /usr/bin/javah javah /usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>/<span class="title">java</span>/<span class="title">bin</span>/<span class="title">javah</span> 300   </span></span><br><span class="line">sudo update-alternatives --install /usr/bin/javap javap /usr/<span class="class"><span class="keyword">lib</span>/<span class="title">jvm</span>/<span class="title">java</span>/<span class="title">bin</span>/<span class="title">javap</span> 300</span></span><br><span class="line">sudo update-alternatives --config java</span><br><span class="line">sudo update-alternatives --config javac</span><br></pre></td></tr></table></figure>
<p>这里面我简单补充一下,其他相关知识,因为涉及到主机之间的安装文件传递,我们可以使用sftp命令进行.</p>
<figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">chu<span class="number">888</span>chu<span class="number">888</span><span class="title">@ubuntu-hadoop</span>:~$ sftp chu<span class="number">888</span>chu<span class="number">888</span><span class="title">@192</span>.<span class="number">168.1</span>.<span class="number">84</span></span><br><span class="line">The authenticity of host '<span class="number">192.168</span>.<span class="number">1.84</span> (<span class="number">192.168</span>.<span class="number">1.84</span>)' can't be established.</span><br><span class="line">ECDSA key fingerprint is <span class="number">6</span><span class="keyword">c</span>:<span class="number">00</span>:fb:<span class="number">9</span>b:<span class="number">43</span>:<span class="number">6</span><span class="keyword">c</span>:<span class="number">3</span>b:<span class="number">29</span>:<span class="number">96</span>:<span class="number">98</span>:a<span class="number">8</span>:<span class="number">28</span>:d<span class="number">1</span>:<span class="number">23</span>:<span class="number">11</span>:<span class="number">13</span>.</span><br><span class="line">Are you sure you want <span class="keyword">to</span> continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added '<span class="number">192.168</span>.<span class="number">1.84</span>' (ECDSA) <span class="keyword">to</span> the list of known hosts.</span><br><span class="line">chu<span class="number">888</span>chu<span class="number">888</span><span class="title">@192</span>.<span class="number">168.1</span>.<span class="number">84</span>'s password: </span><br><span class="line">Connected <span class="keyword">to</span> <span class="number">192.168</span>.<span class="number">1.84</span>.</span><br><span class="line">sftp&gt; put jdk<span class="number">-8</span>u<span class="number">65</span>-linux-<span class="keyword">x</span><span class="number">64</span>.gz </span><br><span class="line">Uploading jdk<span class="number">-8</span>u<span class="number">65</span>-linux-<span class="keyword">x</span><span class="number">64</span>.gz <span class="keyword">to</span> /home/chu<span class="number">888</span>chu<span class="number">888</span>/jdk<span class="number">-8</span>u<span class="number">65</span>-linux-<span class="keyword">x</span><span class="number">64</span>.gz</span><br><span class="line">jdk<span class="number">-8</span>u<span class="number">65</span>-linux-<span class="keyword">x</span><span class="number">64</span>.gz                                                                                 <span class="number">100</span>%  <span class="number">173</span>MB  <span class="number">28.8</span>MB/s   <span class="number">00</span>:<span class="number">06</span>    </span><br><span class="line">sftp&gt;</span><br></pre></td></tr></table></figure>
<h2 id="3-Hadoop用户的创建"><a href="#3-Hadoop用户的创建" class="headerlink" title="3. Hadoop用户的创建"></a>3. Hadoop用户的创建</h2><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">创建hadoop用户组</span><br><span class="line">创建hadoop用户</span><br><span class="line">给hadoop用户添加权限,打开/etc/sudoers文件</span><br><span class="line">chu888chu888@ubuntu1:/<span class="symbol">$</span> sudo addgroup hadoop</span><br><span class="line">chu888chu888@ubuntu1:/<span class="symbol">$</span> sudo adduser -ingroup hadoop hadoop chu888chu888@ubuntu1:/<span class="symbol">$</span> sudo nano /etc/sudoers</span><br><span class="line"># User privilege specification</span><br><span class="line">root    <span class="keyword">ALL</span>=(<span class="keyword">ALL</span>:<span class="keyword">ALL</span>) <span class="keyword">ALL</span></span><br><span class="line">hadoop  <span class="keyword">ALL</span>=(<span class="keyword">ALL</span>:<span class="keyword">ALL</span>) <span class="keyword">ALL</span></span><br></pre></td></tr></table></figure>
<h2 id="4-hosts文件修改"><a href="#4-hosts文件修改" class="headerlink" title="4. hosts文件修改"></a>4. hosts文件修改</h2><p><strong>所有的主机的hosts都需要修改,在这里我吃了一个大亏,如果在etc配置文件中直接用Ip的话,可能会出现Datanode链接不上Namenode的现象.</strong></p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hadoop<span class="variable">@ubuntu</span>-<span class="symbol">hadoop:</span>/usr/local/hadoop/etc/hadoop<span class="variable">$ </span>more /etc/hosts</span><br><span class="line"><span class="number">127.0</span>.<span class="number">0</span>.<span class="number">1</span>	localhost</span><br><span class="line"><span class="number">192.168</span>.<span class="number">1.80</span>    Master</span><br><span class="line"><span class="number">192.168</span>.<span class="number">1.82</span>    Slave1</span><br><span class="line"></span><br><span class="line"><span class="comment"># The following lines are desirable for IPv6 capable hosts</span></span><br><span class="line">::<span class="number">1</span>     localhost ip6-localhost ip6-loopback</span><br><span class="line">ff02::<span class="number">1</span> ip6-allnodes</span><br><span class="line">ff02::<span class="number">2</span> ip6-allrouters</span><br><span class="line">hadoop<span class="variable">@ubuntu</span>-<span class="symbol">hadoop:</span>/usr/local/hadoop/etc/hadoop$</span><br></pre></td></tr></table></figure>
<h2 id="5-SSH无密码登录"><a href="#5-SSH无密码登录" class="headerlink" title="5. SSH无密码登录"></a>5. SSH无密码登录</h2><p>所有的主机都要进行操作</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">这个操作是要让<span class="literal">Master</span>节点可以在无密码的状态下SSH登录到各个<span class="literal">Slave</span>节点上</span><br><span class="line">首先生成<span class="literal">Master</span>节点的公钥,在<span class="literal">Master</span>节点的终端中执行</span><br><span class="line"></span><br><span class="line"><span class="comment">#如果没有该目录,先执行一次ssh localhost</span></span><br><span class="line">$ cd ~/.ssh</span><br><span class="line"><span class="comment">#删除之前生成的公钥</span></span><br><span class="line">$ rm ./id_rsa*</span><br><span class="line"><span class="comment">#一直按回车就可以了</span></span><br><span class="line">$ ssh-keygen -t rsa</span><br><span class="line"></span><br><span class="line">让<span class="literal">Master</span>节点需能无密码的SSH本机,在<span class="literal">Master</span>节点上执行</span><br><span class="line">$cat ./id_rsa.pub&gt;&gt;./authorized_keys</span><br><span class="line">完成后可执行ssh <span class="literal">Master</span>验证一下,接着需要把<span class="literal">Master</span>节点的公钥上传输到Slave1节点上</span><br><span class="line">$sftp hadoop@Slave1</span><br><span class="line"></span><br><span class="line">接着在Slave1节点上,将ssh公钥加入授权</span><br><span class="line">$mkdir ~/.ssh</span><br><span class="line">$cat ~/id_rsa.pub&gt;&gt;~/.ssh/authorized_keys</span><br><span class="line">$rm ~/id_rsa.pub</span><br><span class="line">如果有其他的<span class="literal">Slave</span>节点,也要执行将<span class="literal">Master</span>公钥传输到<span class="literal">Slave</span>节点,在<span class="literal">Slave</span>节点加入授权这两步.</span><br><span class="line">这样,在<span class="literal">Master</span>节点就可以无密码SSH到各个<span class="literal">Slave</span>节点了.</span><br></pre></td></tr></table></figure>
<h2 id="6-Hadoop的安装"><a href="#6-Hadoop的安装" class="headerlink" title="6. Hadoop的安装"></a>6. Hadoop的安装</h2><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:~</span><span class="variable">$ </span>sudo tar xvfz hadoop-<span class="number">2.6</span>.<span class="number">0</span>.tar.gz </span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:~</span><span class="variable">$ </span>sudo cp -r hadoop-<span class="number">2.6</span>.<span class="number">0</span> /usr/local/hadoop</span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:~</span><span class="variable">$ </span>sudo chmod -R <span class="number">775</span> /usr/local/hadoop/</span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:~</span><span class="variable">$ </span>sudo chown -R <span class="symbol">hadoop:</span>hadoop /usr/local/hadoop</span><br></pre></td></tr></table></figure>
<p>这里面有一个小的体验技巧,我建议将所有需要的环境变量配置加入到/etc/profile中,这是全局变量.</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/lib/jvm/</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JRE_HOME</span>=<span class="variable">$&#123;JAVA_HOME&#125;</span>/jre</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=.:$&#123;JAVA_HOME&#125;/lib:<span class="variable">$&#123;JRE_HOME&#125;</span>/lib</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:$PATH</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP VARIABLES START</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/lib/jvm/</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_INSTALL</span>=/usr/local/hadoop</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_INSTALL/bin</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$JAVA_HOME/bin</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_INSTALL/sbin</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_MAPRED_HOME</span>=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_COMMON_HOME</span>=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HDFS_HOME</span>=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">YARN_HOME</span>=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_COMMON_LIB_NATIVE_DIR</span>=<span class="variable">$HADOOP_INSTALL</span>/lib/native</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_OPTS</span>=<span class="string">"-Djava.library.path=<span class="variable">$HADOOP_INSTALL</span>/lib"</span></span><br><span class="line"><span class="comment">#HADOOP VARIABLES END</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">还有一个问题就是,在启动hadoop的时候经常会出现,找不到JAVA_HOME的问题,这个问题可以通过修改hadoop环境变量来解决,直接写死变量就可以了.</span><br><span class="line"></span><br><span class="line">$ more hadoop-env.sh</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/lib/jvm/</span><br></pre></td></tr></table></figure>
<h2 id="7-配置集群环境192-168-1-80-NameNode"><a href="#7-配置集群环境192-168-1-80-NameNode" class="headerlink" title="7. 配置集群环境192.168.1.80 NameNode"></a>7. 配置集群环境192.168.1.80 NameNode</h2><p>集群/分布式模式需要修改 /usr/local/hadoop/etc/hadoop 中的5个配置文件，更多设置项可点击查看官方说明，这里仅设置了正常启动所必须的设置项： slaves、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml 。</p>
<h2 id="8-文件slaves"><a href="#8-文件slaves" class="headerlink" title="8. 文件slaves"></a>8. 文件slaves</h2><p>文件 slaves，将作为 DataNode 的主机名写入该文件，每行一个，默认为 localhost，所以在伪分布式配置时，节点即作为 NameNode 也作为 DataNode。分布式配置可以保留 localhost，也可以删掉，让 Master 节点仅作为 NameNode 使用。<br>本教程让 Master 节点仅作为 NameNode 使用，因此将文件中原来的 localhost 删除，只添加一行内容：Slave1。</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hadoop<span class="meta">@ubuntu</span>-<span class="string">hadoop:</span>~$ cd <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span></span><br><span class="line">hadoop<span class="meta">@ubuntu</span>-<span class="string">hadoop:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop$ sudo nano slaves </span><br><span class="line">[sudo] password <span class="keyword">for</span> <span class="string">hadoop:</span> </span><br><span class="line">hadoop<span class="meta">@ubuntu</span>-<span class="string">hadoop:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop$ more slaves </span><br><span class="line">Slave1</span><br><span class="line"></span><br><span class="line">hadoop<span class="meta">@ubuntu</span>-<span class="string">hadoop:</span><span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc/hadoop$</span><br></pre></td></tr></table></figure>
<h2 id="9-文件-core-site-xml-改为下面的配置："><a href="#9-文件-core-site-xml-改为下面的配置：" class="headerlink" title="9. 文件 core-site.xml 改为下面的配置："></a>9. 文件 core-site.xml 改为下面的配置：</h2><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;configuration&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>fs.defaultFS<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>hdfs:<span class="comment">//Master:9000&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>hadoop.tmp.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>file:<span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/hadoop/</span>tmp<span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>Abase for other temporary directories.<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="10-文件-hdfs-site-xml，dfs-replication-一般设为-3，但我们只有一个-Slave-节点，所以-dfs-replication-的值还是设为-1："><a href="#10-文件-hdfs-site-xml，dfs-replication-一般设为-3，但我们只有一个-Slave-节点，所以-dfs-replication-的值还是设为-1：" class="headerlink" title="10. 文件 hdfs-site.xml，dfs.replication 一般设为 3，但我们只有一个 Slave 节点，所以 dfs.replication 的值还是设为 1："></a>10. 文件 hdfs-site.xml，dfs.replication 一般设为 3，但我们只有一个 Slave 节点，所以 dfs.replication 的值还是设为 1：</h2><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;configuration&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.namenode.secondary.http-address<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>Master:<span class="number">50090</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.replication<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">1</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.namenode.name.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>file:<span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/hadoop/</span>tmp<span class="meta-keyword">/dfs/</span>name<span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.datanode.data.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>file:<span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/hadoop/</span>tmp<span class="meta-keyword">/dfs/</span>data<span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="11-文件-mapred-site-xml-（可能需要先重命名，默认文件名为-mapred-site-xml-template），然后配置修改如下："><a href="#11-文件-mapred-site-xml-（可能需要先重命名，默认文件名为-mapred-site-xml-template），然后配置修改如下：" class="headerlink" title="11. 文件 mapred-site.xml （可能需要先重命名，默认文件名为 mapred-site.xml.template），然后配置修改如下："></a>11. 文件 mapred-site.xml （可能需要先重命名，默认文件名为 mapred-site.xml.template），然后配置修改如下：</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="12-文件-yarn-site-xml："><a href="#12-文件-yarn-site-xml：" class="headerlink" title="12. 文件 yarn-site.xml："></a>12. 文件 yarn-site.xml：</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="13-在其他Slave节点需要做的"><a href="#13-在其他Slave节点需要做的" class="headerlink" title="13. 在其他Slave节点需要做的"></a>13. 在其他Slave节点需要做的</h2><p>首先通过sftp把Master配置好的hadoop打包,之后转输到Slave节点上,配置好环境变量JDK PATH SSH 基本上与Master是一样的.<br>配置好后，将 Master 上的 /usr/local/Hadoop 文件夹复制到各个节点上。因为之前有跑过伪分布式模式，建议在切换到集群模式前先删除之前的临时文件。<br>在 Master 节点上执行：  </p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> <span class="string">/usr/local</span></span><br><span class="line"><span class="comment"># 删除 Hadoop 临时文件</span></span><br><span class="line">sudo rm -r <span class="string">./hadoop/tmp</span></span><br><span class="line"><span class="comment"># 删除日志文件</span></span><br><span class="line">sudo rm -r <span class="string">./hadoop/logs/</span>*  </span><br><span class="line"><span class="comment"># 先压缩再复制</span></span><br><span class="line">tar -cvfz ~<span class="string">/hadoop.master.tar.gz</span> <span class="string">./hadoop</span></span><br></pre></td></tr></table></figure>
<p>在Slave节点上执行:</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -r <span class="string">/usr/local/hadoop</span>    <span class="comment"># 删掉旧的（如果存在）</span></span><br><span class="line">sudo tar -xvfz ~<span class="string">/hadoop.master.tar.gz</span> -C <span class="string">/usr/local</span></span><br><span class="line">sudo chown -R hadoop<span class="function">:hadoop</span> <span class="string">/usr/local/hadoop</span></span><br></pre></td></tr></table></figure>
<h2 id="14-开始启动集群"><a href="#14-开始启动集群" class="headerlink" title="14. 开始启动集群"></a>14. 开始启动集群</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format       # 首次运行需要执行初始化，之后不需要</span><br><span class="line">在Master上执行:</span><br><span class="line"><span class="variable">$start</span>-dfs.sh</span><br><span class="line"><span class="variable">$start</span>-yarn.sh</span><br><span class="line"><span class="variable">$mr</span>-jobhistory-daemon.sh start historyserver</span><br><span class="line"></span><br><span class="line">Centos6.X需要关闭防火墙</span><br><span class="line">sudo<span class="built_in"> service </span>iptables stop   # 关闭防火墙服务</span><br><span class="line">sudo chkconfig iptables off  # 禁止防火墙开机自启，就不用手动关闭了</span><br><span class="line">Cent7</span><br><span class="line">systemctl stop firewalld.service    # 关闭firewall</span><br><span class="line">systemctl <span class="builtin-name">disable</span> firewalld.service # 禁止firewall开机启动</span><br></pre></td></tr></table></figure>
<p>之后分别在Master与Slave上执行jps,会看到不同的结果.缺少任一进程都表示出错。另外还需要在 Master 节点上通过命令 hdfs dfsadmin -report 查看 DataNode 是否正常启动，如果 Live datanodes 不为 0 ，则说明集群启动成功。例如我这边一共有 1 个 Datanodes：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"><span class="meta-keyword">$jps</span></span></span><br><span class="line"><span class="meta"><span class="meta-keyword">$hdfs</span> dfsadmin -report</span></span><br><span class="line"></span><br><span class="line">可以访问http:<span class="comment">//192.168.1.80:50070/ 查看结果</span></span><br></pre></td></tr></table></figure>
<p><img src="/img/hadoop/4/4/jps1.png" alt><br><img src="/img/hadoop/4/jps2.png" alt></p>
<h2 id="15-执行分布式的实验-分布式存储"><a href="#15-执行分布式的实验-分布式存储" class="headerlink" title="15. 执行分布式的实验-分布式存储"></a>15. 执行分布式的实验-分布式存储</h2><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">执行分布式实例过程与伪分布式模式一样，首先创建 HDFS 上的用户目录：</span><br><span class="line">$ hdfs dfs -mkdir -p <span class="meta-keyword">/user/</span>hadoop</span><br><span class="line">将 <span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/hadoop/</span>etc/hadoop 中的配置文件作为输入文件复制到分布式文件系统中：</span><br><span class="line">$ hdfs dfs -mkdir input</span><br><span class="line">$ hdfs dfs -put <span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/hadoop/</span>etc<span class="meta-keyword">/hadoop/</span>*.xml input</span><br></pre></td></tr></table></figure>
<p>通过查看 DataNode 的状态（占用大小有改变），输入文件确实复制到了 DataNode 中，如下图所示：<br><img src="/img/hadoop/4/hdfssave.png" alt></p>
<h2 id="16-执行分布式的实验-MapReduce"><a href="#16-执行分布式的实验-MapReduce" class="headerlink" title="16. 执行分布式的实验-MapReduce"></a>16. 执行分布式的实验-MapReduce</h2><p>执行MapReduce作业</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/</span>mapreduce<span class="regexp">/hadoop-mapreduce-examples-*.jar grep /</span>user<span class="regexp">/hadoop/</span>input <span class="regexp">/user/</span>hadoop/output <span class="string">'dfs[a-z.]+'</span></span><br><span class="line">查看<span class="string">http:</span><span class="comment">//192.168.1.80:8088/cluster看结果</span></span><br></pre></td></tr></table></figure>
<p>运行时的输出信息与伪分布式类似，会显示 Job 的进度。</p>
<p>可能会有点慢，但如果迟迟没有进度，比如 5 分钟都没看到进度，那不妨重启 Hadoop 再试试。若重启还不行，则很有可能是内存不足引起，建议增大虚拟机的内存，或者通过更改 YARN 的内存配置解决。<br>同样可以通过 Web 界面查看任务进度 <a href="http://master:8088/cluster，在" target="_blank" rel="noopener">http://master:8088/cluster，在</a> Web 界面点击 “Tracking UI” 这一列的 History 连接，可以看到任务的运行信息，如下图所示：</p>
<p><img src="/img/hadoop/4/yarnfinish.png" alt></p>
<h2 id="17-关闭集群"><a href="#17-关闭集群" class="headerlink" title="17. 关闭集群"></a>17. 关闭集群</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stop-yarn.sh</span><br><span class="line">stop-dfs.sh</span><br><span class="line">mr-jobhistory-daemon<span class="selector-class">.sh</span> stop historyserver</span><br></pre></td></tr></table></figure>
    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="/" target="_blank">Ljjyy.com</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/archives/2019/06/100317.html" class="pre-post btn btn-default" title='大数据hadoop之 十一.组件HDFS'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">大数据hadoop之 十一.组件HDFS</span>
        </a>
    
    
        <a href="/archives/2019/06/100315.html" class="next-post btn btn-default" title='大数据hadoop之 九.Hadoop的伪分布式搭建'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">大数据hadoop之 九.Hadoop的伪分布式搭建</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: '5MzTXYXkt03k101j0PmSDN34-gzGzoHsz',
            appKey: 'iwjYgwno6qj3wtDVVSbe8nYQ',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-网络拓扑"><span class="toc-text">1. 网络拓扑</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-安装JDK"><span class="toc-text">2. 安装JDK</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Hadoop用户的创建"><span class="toc-text">3. Hadoop用户的创建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-hosts文件修改"><span class="toc-text">4. hosts文件修改</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-SSH无密码登录"><span class="toc-text">5. SSH无密码登录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Hadoop的安装"><span class="toc-text">6. Hadoop的安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-配置集群环境192-168-1-80-NameNode"><span class="toc-text">7. 配置集群环境192.168.1.80 NameNode</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-文件slaves"><span class="toc-text">8. 文件slaves</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-文件-core-site-xml-改为下面的配置："><span class="toc-text">9. 文件 core-site.xml 改为下面的配置：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-文件-hdfs-site-xml，dfs-replication-一般设为-3，但我们只有一个-Slave-节点，所以-dfs-replication-的值还是设为-1："><span class="toc-text">10. 文件 hdfs-site.xml，dfs.replication 一般设为 3，但我们只有一个 Slave 节点，所以 dfs.replication 的值还是设为 1：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-文件-mapred-site-xml-（可能需要先重命名，默认文件名为-mapred-site-xml-template），然后配置修改如下："><span class="toc-text">11. 文件 mapred-site.xml （可能需要先重命名，默认文件名为 mapred-site.xml.template），然后配置修改如下：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-文件-yarn-site-xml："><span class="toc-text">12. 文件 yarn-site.xml：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-在其他Slave节点需要做的"><span class="toc-text">13. 在其他Slave节点需要做的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-开始启动集群"><span class="toc-text">14. 开始启动集群</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-执行分布式的实验-分布式存储"><span class="toc-text">15. 执行分布式的实验-分布式存储</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16-执行分布式的实验-MapReduce"><span class="toc-text">16. 执行分布式的实验-MapReduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-关闭集群"><span class="toc-text">17. 关闭集群</span></a></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019-2023&emsp;<a href="/" class="copyright-links" target="_blank" rel="nofollow">Ljjyy.com</a>
                </span> |
                <span>
                    <a href="/about/" class="copyright-links" target="_blank" rel="nofollow">关于我们</a>
                </span> |                
                <span>
                    <a href="/sitemap.xml" class="copyright-links" target="_blank" rel="nofollow">网站地图</a>
                </span> |
                <span>
                    <a href="/archives/" class="copyright-links" target="_blank" rel="nofollow">时间轴</a>
                </span>              
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>
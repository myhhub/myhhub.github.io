<!DOCTYPE HTML>
<html lang="zh-CN">
<head>
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="https://www.ljjyy.com">
    <!--SEO-->

    <meta name="keywords" content="hadoop" />


    <meta name="description" content="1. 网络拓扑
192.168.1.80 Master
192.168.1.82 Slave1
192.168.1.84 Slave2

2. 安装JDK所有实验主机都需要正确的安装JDK,具体..." />



<meta name="robots" content="all" />
<meta name="google" content="all" />
<meta name="googlebot" content="all" />
<meta name="verify" content="all" />

    <!--Title-->


<title>大数据hadoop之 十.Hadoop的完全分布式搭建 | 来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</title>


    <link rel="alternate" href="/atom.xml" title="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    




<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7.css">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0.css">
<link rel="stylesheet" href="/css/style.css?rev=@@hash.css">





    
	<div class="hide">
        <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
        <script>LA.init({id: "JgbNOaw1xxsmUUsQ",ck: "JgbNOaw1xxsmUUsQ"})</script>
	</div>






    
    <meta name="baidu-site-verification" content="dTHILoORpx" />


    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

<meta name="generator" content="Hexo 7.3.0"></head>


<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  >
    <div class="main-header-box">
        <!--a class="header-avatar" href="/" title='Ljjyy.com'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a-->
        <div class="branding">
            
                <h2> 多读书多实践，勤思考善领悟 </h2>
            
    	  </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">

        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="web-logo"  href="/" title='Ljjyy.com'></a>
                    <!--a class="navbar-brand" href="https://www.ljjyy.com">来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</a-->
                </div>
                <div class="collapse navbar-collapse" id="main-menu" style="">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/cloud/"><i class="fa "></i>云计算</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/front/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/back/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/devops/"><i class="fa "></i>运维</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/crack/"><i class="fa "></i>破解</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/penetration/"><i class="fa "></i>渗透</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tool/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/other/"><i class="fa "></i>其他</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="大数据hadoop之 十.Hadoop的完全分布式搭建">
            
	            大数据hadoop之 十.Hadoop的完全分布式搭建
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/cloud/">云计算</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-none-link" href="/tags/hadoop/" rel="tag">hadoop</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/06/09</span>
        </span>
        
    
</div>
            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>2109</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <h2 id="1-网络拓扑"><a href="#1-网络拓扑" class="headerlink" title="1. 网络拓扑"></a>1. 网络拓扑</h2><ul>
<li>192.168.1.80 Master</li>
<li>192.168.1.82 Slave1</li>
<li>192.168.1.84 Slave2</li>
</ul>
<h2 id="2-安装JDK"><a href="#2-安装JDK" class="headerlink" title="2. 安装JDK"></a>2. 安装JDK</h2><p>所有实验主机都需要正确的安装JDK,具体操作方法  </p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:~</span><span class="variable">$ </span>tar xvfz jdk-8u65-linux-x64.gz</span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:~</span><span class="variable">$ </span>sudo cp -r jdk1.<span class="number">8.0_65</span>/ <span class="regexp">/usr/lib</span><span class="regexp">/jvm/</span></span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:/usr/lib/jvm</span><span class="variable">$ </span>sudo nano /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改内容如下,注意大小写</span></span><br><span class="line"><span class="comment">#在环境变量中的配置中,有一点需要指出就是如果只是编辑~/.profile的话这个变量的生效只是针对当前用户的.</span></span><br><span class="line"><span class="comment">#如果想要其在全局生效的话,建议更新/etc/profile,这是一个全局的.</span></span><br><span class="line"></span><br><span class="line">export <span class="variable constant_">JAVA_HOME</span>=<span class="regexp">/usr/lib</span><span class="regexp">/jvm/</span></span><br><span class="line">export <span class="variable constant_">JRE_HOME</span>=<span class="variable">$&#123;</span><span class="variable constant_">JAVA_HOME</span>&#125;/jre</span><br><span class="line">export <span class="variable constant_">CLASSPATH</span>=.<span class="symbol">:</span><span class="variable">$&#123;</span><span class="variable constant_">JAVA_HOME</span>&#125;/<span class="symbol">lib:</span><span class="variable">$&#123;</span><span class="variable constant_">JRE_HOME</span>&#125;/lib</span><br><span class="line">export <span class="variable constant_">PATH</span>=<span class="variable">$&#123;</span><span class="variable constant_">JAVA_HOME</span>&#125;/<span class="symbol">bin:</span><span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:/usr/lib/jvm</span><span class="variable">$ </span>source /etc/profile </span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:/usr/lib/jvm</span><span class="variable">$ </span>env</span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:/usr/lib/jvm</span><span class="variable">$ </span>java -version</span><br><span class="line">java version <span class="string">&quot;1.8.0_65&quot;</span></span><br><span class="line"><span class="title class_">Java</span>(<span class="variable constant_">TM</span>) <span class="variable constant_">SE</span> <span class="title class_">Runtime</span> <span class="title class_">Environment</span> (build <span class="number">1.8</span>.<span class="number">0_65</span>-b17)</span><br><span class="line"><span class="title class_">Java</span> <span class="title class_">HotSpot</span>(<span class="variable constant_">TM</span>) <span class="number">64</span>-<span class="title class_">Bit</span> <span class="title class_">Server</span> <span class="variable constant_">VM</span> (build <span class="number">25.65</span>-b01, mixed mode)</span><br><span class="line"></span><br><span class="line"><span class="comment">#有一种极端情况就是,如果在本机已经安装了OpenJavaSDK,怎么办?</span></span><br><span class="line">sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/java/bin/java <span class="number">300</span>  </span><br><span class="line">sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java/bin/javac <span class="number">300</span>  </span><br><span class="line">sudo update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/java/bin/jar <span class="number">300</span>   </span><br><span class="line">sudo update-alternatives --install /usr/bin/javah javah /usr/lib/jvm/java/bin/javah <span class="number">300</span>   </span><br><span class="line">sudo update-alternatives --install /usr/bin/javap javap /usr/lib/jvm/java/bin/javap <span class="number">300</span></span><br><span class="line">sudo update-alternatives --config java</span><br><span class="line">sudo update-alternatives --config javac</span><br></pre></td></tr></table></figure>

<p>这里面我简单补充一下,其他相关知识,因为涉及到主机之间的安装文件传递,我们可以使用sftp命令进行.</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">chu888chu888</span>@ubuntu-hadoop:~$ sftp chu888chu888@<span class="number">192.168.1.84</span></span><br><span class="line"><span class="attribute">The</span> authenticity of host &#x27;<span class="number">192.168.1.84</span> (<span class="number">192.168.1.84</span>)&#x27; can&#x27;t be established.</span><br><span class="line"><span class="attribute">ECDSA</span> key fingerprint is <span class="number">6</span>c:<span class="number">00</span>:fb:<span class="number">9</span>b:<span class="number">43</span>:<span class="number">6</span>c:<span class="number">3</span>b:<span class="number">29</span>:<span class="number">96</span>:<span class="number">98</span>:a8:<span class="number">28</span>:d1:<span class="number">23</span>:<span class="number">11</span>:<span class="number">13</span>.</span><br><span class="line"><span class="attribute">Are</span> you sure you want to continue connecting (yes/no)? yes</span><br><span class="line"><span class="attribute">Warning</span>: Permanently added &#x27;<span class="number">192.168.1.84</span>&#x27; (ECDSA) to the list of known hosts.</span><br><span class="line"><span class="attribute">chu888chu888</span>@<span class="number">192.168.1.84</span>&#x27;s password: </span><br><span class="line"><span class="attribute">Connected</span> to <span class="number">192.168.1.84</span>.</span><br><span class="line"><span class="attribute">sftp</span>&gt; put jdk-<span class="number">8</span>u65-linux-x64.gz </span><br><span class="line"><span class="attribute">Uploading</span> jdk-<span class="number">8</span>u65-linux-x64.gz to /home/chu888chu888/jdk-<span class="number">8</span>u65-linux-x64.gz</span><br><span class="line"><span class="attribute">jdk</span>-<span class="number">8</span>u65-linux-x64.gz                                                                                 <span class="number">100</span>%  <span class="number">173</span>MB  <span class="number">28</span>.<span class="number">8</span>MB/s   <span class="number">00</span>:<span class="number">06</span>    </span><br><span class="line"><span class="attribute">sftp</span>&gt; </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="3-Hadoop用户的创建"><a href="#3-Hadoop用户的创建" class="headerlink" title="3. Hadoop用户的创建"></a>3. Hadoop用户的创建</h2><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">创建hadoop用户组</span><br><span class="line">创建hadoop用户</span><br><span class="line">给hadoop用户添加权限,打开/etc/sudoers文件</span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:/</span><span class="variable">$ </span>sudo addgroup hadoop</span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:/</span><span class="variable">$ </span>sudo adduser -ingroup hadoop hadoop chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:/</span><span class="variable">$ </span>sudo nano /etc/sudoers</span><br><span class="line"><span class="comment"># User privilege specification</span></span><br><span class="line">root    <span class="variable constant_">ALL</span>=(<span class="variable constant_">ALL</span><span class="symbol">:ALL</span>) <span class="variable constant_">ALL</span></span><br><span class="line">hadoop  <span class="variable constant_">ALL</span>=(<span class="variable constant_">ALL</span><span class="symbol">:ALL</span>) <span class="variable constant_">ALL</span></span><br></pre></td></tr></table></figure>
<h2 id="4-hosts文件修改"><a href="#4-hosts文件修改" class="headerlink" title="4. hosts文件修改"></a>4. hosts文件修改</h2><p><strong>所有的主机的hosts都需要修改,在这里我吃了一个大亏,如果在etc配置文件中直接用Ip的话,可能会出现Datanode链接不上Namenode的现象.</strong></p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hadoop@ubuntu-hadoop:/usr/local/hadoop/etc/hadoop$ more /etc/hosts</span><br><span class="line"><span class="number">127.0.0.1</span>	localhost</span><br><span class="line"><span class="number">192.168.1.80</span>    Master</span><br><span class="line"><span class="number">192.168.1.82</span>    Slave1</span><br><span class="line"></span><br><span class="line"># The following lines are desirable for IPv6 capable hosts</span><br><span class="line">::<span class="number">1</span>     localhost ip6-localhost ip6-loopback</span><br><span class="line">ff02::<span class="number">1</span> ip6-allnodes</span><br><span class="line">ff02::<span class="number">2</span> ip6-allrouters</span><br><span class="line">hadoop@ubuntu-hadoop:/usr/local/hadoop/etc/hadoop$ </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="5-SSH无密码登录"><a href="#5-SSH无密码登录" class="headerlink" title="5. SSH无密码登录"></a>5. SSH无密码登录</h2><p>所有的主机都要进行操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">这个操作是要让Master节点可以在无密码的状态下SSH登录到各个Slave节点上</span><br><span class="line">首先生成Master节点的公钥,在Master节点的终端中执行</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果没有该目录,先执行一次ssh localhost</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> ~/.ssh</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">删除之前生成的公钥</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">rm</span> ./id_rsa*</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">一直按回车就可以了</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ssh-keygen -t rsa</span></span><br><span class="line"></span><br><span class="line">让Master节点需能无密码的SSH本机,在Master节点上执行</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash"><span class="built_in">cat</span> ./id_rsa.pub&gt;&gt;./authorized_keys</span></span><br><span class="line">完成后可执行ssh Master验证一下,接着需要把Master节点的公钥上传输到Slave1节点上</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">sftp hadoop@Slave1</span></span><br><span class="line"></span><br><span class="line">接着在Slave1节点上,将ssh公钥加入授权</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash"><span class="built_in">mkdir</span> ~/.ssh</span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash"><span class="built_in">cat</span> ~/id_rsa.pub&gt;&gt;~/.ssh/authorized_keys</span></span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash"><span class="built_in">rm</span> ~/id_rsa.pub</span></span><br><span class="line">如果有其他的Slave节点,也要执行将Master公钥传输到Slave节点,在Slave节点加入授权这两步.</span><br><span class="line">这样,在Master节点就可以无密码SSH到各个Slave节点了.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="6-Hadoop的安装"><a href="#6-Hadoop的安装" class="headerlink" title="6. Hadoop的安装"></a>6. Hadoop的安装</h2><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:~</span><span class="variable">$ </span>sudo tar xvfz hadoop<span class="number">-2.6</span>.<span class="number">0</span>.tar.gz </span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:~</span><span class="variable">$ </span>sudo cp -r hadoop<span class="number">-2.6</span>.<span class="number">0</span> /usr/local/hadoop</span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:~</span><span class="variable">$ </span>sudo chmod -R <span class="number">775</span> /usr/local/hadoop/</span><br><span class="line">chu888chu888<span class="variable">@ubuntu1</span><span class="symbol">:~</span><span class="variable">$ </span>sudo chown -R <span class="symbol">hadoop:</span>hadoop /usr/local/hadoop</span><br></pre></td></tr></table></figure>
<p>这里面有一个小的体验技巧,我建议将所有需要的环境变量配置加入到&#x2F;etc&#x2F;profile中,这是全局变量.</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> <span class="attribute">JAVA_HOME</span>=/usr/lib/jvm/</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">JRE_HOME</span>=<span class="variable">$&#123;JAVA_HOME&#125;</span>/jre</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">CLASSPATH</span>=.:$&#123;JAVA_HOME&#125;/lib:<span class="variable">$&#123;JRE_HOME&#125;</span>/lib</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">PATH</span>=<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:$PATH</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP VARIABLES START</span></span><br><span class="line"><span class="built_in">export</span> <span class="attribute">JAVA_HOME</span>=/usr/lib/jvm/</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">HADOOP_INSTALL</span>=/usr/local/hadoop</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_INSTALL/bin</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$JAVA_HOME/bin</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_INSTALL/sbin</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">HADOOP_MAPRED_HOME</span>=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> <span class="attribute">HADOOP_COMMON_HOME</span>=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> <span class="attribute">HADOOP_HDFS_HOME</span>=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> <span class="attribute">YARN_HOME</span>=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> <span class="attribute">HADOOP_COMMON_LIB_NATIVE_DIR</span>=<span class="variable">$HADOOP_INSTALL</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">HADOOP_OPTS</span>=<span class="string">&quot;-Djava.library.path=<span class="variable">$HADOOP_INSTALL</span>/lib&quot;</span></span><br><span class="line"><span class="comment">#HADOOP VARIABLES END</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">还有一个问题就是,在启动hadoop的时候经常会出现,找不到JAVA_HOME的问题,这个问题可以通过修改hadoop环境变量来解决,直接写死变量就可以了.</span><br><span class="line"></span><br><span class="line">$ more hadoop-env.sh</span><br><span class="line"><span class="built_in">export</span> <span class="attribute">JAVA_HOME</span>=/usr/lib/jvm/</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="7-配置集群环境192-168-1-80-NameNode"><a href="#7-配置集群环境192-168-1-80-NameNode" class="headerlink" title="7. 配置集群环境192.168.1.80 NameNode"></a>7. 配置集群环境192.168.1.80 NameNode</h2><p>集群&#x2F;分布式模式需要修改 &#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;etc&#x2F;hadoop 中的5个配置文件，更多设置项可点击查看官方说明，这里仅设置了正常启动所必须的设置项： slaves、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml 。</p>
<h2 id="8-文件slaves"><a href="#8-文件slaves" class="headerlink" title="8. 文件slaves"></a>8. 文件slaves</h2><p>文件 slaves，将作为 DataNode 的主机名写入该文件，每行一个，默认为 localhost，所以在伪分布式配置时，节点即作为 NameNode 也作为 DataNode。分布式配置可以保留 localhost，也可以删掉，让 Master 节点仅作为 NameNode 使用。<br>本教程让 Master 节点仅作为 NameNode 使用，因此将文件中原来的 localhost 删除，只添加一行内容：Slave1。</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hadoop<span class="meta">@ubuntu</span><span class="operator">-</span>hadoop:<span class="operator">~</span>$ cd <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span></span><br><span class="line">hadoop<span class="meta">@ubuntu</span><span class="operator">-</span>hadoop:<span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="operator">/</span>hadoop$ sudo nano slaves </span><br><span class="line">[sudo] password <span class="keyword">for</span> hadoop: </span><br><span class="line">hadoop<span class="meta">@ubuntu</span><span class="operator">-</span>hadoop:<span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="operator">/</span>hadoop$ more slaves </span><br><span class="line"><span class="type">Slave1</span></span><br><span class="line"></span><br><span class="line">hadoop<span class="meta">@ubuntu</span><span class="operator">-</span>hadoop:<span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="operator">/</span>hadoop$ </span><br></pre></td></tr></table></figure>
<h2 id="9-文件-core-site-xml-改为下面的配置："><a href="#9-文件-core-site-xml-改为下面的配置：" class="headerlink" title="9. 文件 core-site.xml 改为下面的配置："></a>9. 文件 core-site.xml 改为下面的配置：</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://Master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="10-文件-hdfs-site-xml，dfs-replication-一般设为-3，但我们只有一个-Slave-节点，所以-dfs-replication-的值还是设为-1："><a href="#10-文件-hdfs-site-xml，dfs-replication-一般设为-3，但我们只有一个-Slave-节点，所以-dfs-replication-的值还是设为-1：" class="headerlink" title="10. 文件 hdfs-site.xml，dfs.replication 一般设为 3，但我们只有一个 Slave 节点，所以 dfs.replication 的值还是设为 1："></a>10. 文件 hdfs-site.xml，dfs.replication 一般设为 3，但我们只有一个 Slave 节点，所以 dfs.replication 的值还是设为 1：</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="11-文件-mapred-site-xml-（可能需要先重命名，默认文件名为-mapred-site-xml-template），然后配置修改如下："><a href="#11-文件-mapred-site-xml-（可能需要先重命名，默认文件名为-mapred-site-xml-template），然后配置修改如下：" class="headerlink" title="11. 文件 mapred-site.xml （可能需要先重命名，默认文件名为 mapred-site.xml.template），然后配置修改如下："></a>11. 文件 mapred-site.xml （可能需要先重命名，默认文件名为 mapred-site.xml.template），然后配置修改如下：</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="12-文件-yarn-site-xml："><a href="#12-文件-yarn-site-xml：" class="headerlink" title="12. 文件 yarn-site.xml："></a>12. 文件 yarn-site.xml：</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="13-在其他Slave节点需要做的"><a href="#13-在其他Slave节点需要做的" class="headerlink" title="13. 在其他Slave节点需要做的"></a>13. 在其他Slave节点需要做的</h2><p>首先通过sftp把Master配置好的hadoop打包,之后转输到Slave节点上,配置好环境变量JDK PATH SSH 基本上与Master是一样的.<br>配置好后，将 Master 上的 &#x2F;usr&#x2F;local&#x2F;Hadoop 文件夹复制到各个节点上。因为之前有跑过伪分布式模式，建议在切换到集群模式前先删除之前的临时文件。<br>在 Master 节点上执行：  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local</span><br><span class="line"><span class="comment"># 删除 Hadoop 临时文件</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -r ./hadoop/tmp</span><br><span class="line"><span class="comment"># 删除日志文件</span></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -r ./hadoop/logs/*  </span><br><span class="line"><span class="comment"># 先压缩再复制</span></span><br><span class="line">tar -cvfz ~/hadoop.master.tar.gz ./hadoop   </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在Slave节点上执行:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">rm</span> -r /usr/local/hadoop    <span class="comment"># 删掉旧的（如果存在）</span></span><br><span class="line"><span class="built_in">sudo</span> tar -xvfz ~/hadoop.master.tar.gz -C /usr/local</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chown</span> -R hadoop:hadoop /usr/local/hadoop</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="14-开始启动集群"><a href="#14-开始启动集群" class="headerlink" title="14. 开始启动集群"></a>14. 开始启动集群</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format       <span class="comment"># 首次运行需要执行初始化，之后不需要</span></span><br><span class="line">在Master上执行:</span><br><span class="line"><span class="variable">$start</span>-dfs.sh</span><br><span class="line"><span class="variable">$start</span>-yarn.sh</span><br><span class="line"><span class="variable">$mr</span>-jobhistory-daemon.sh start historyserver</span><br><span class="line"></span><br><span class="line">Centos6.X需要关闭防火墙</span><br><span class="line"><span class="built_in">sudo</span> service iptables stop   <span class="comment"># 关闭防火墙服务</span></span><br><span class="line"><span class="built_in">sudo</span> chkconfig iptables off  <span class="comment"># 禁止防火墙开机自启，就不用手动关闭了</span></span><br><span class="line">Cent7</span><br><span class="line">systemctl stop firewalld.service    <span class="comment"># 关闭firewall</span></span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld.service <span class="comment"># 禁止firewall开机启动</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>之后分别在Master与Slave上执行jps,会看到不同的结果.缺少任一进程都表示出错。另外还需要在 Master 节点上通过命令 hdfs dfsadmin -report 查看 DataNode 是否正常启动，如果 Live datanodes 不为 0 ，则说明集群启动成功。例如我这边一共有 1 个 Datanodes：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"><span class="keyword">$jps</span></span></span><br><span class="line"><span class="meta"><span class="keyword">$hdfs</span> dfsadmin -report</span></span><br><span class="line"></span><br><span class="line">可以访问http:<span class="comment">//192.168.1.80:50070/ 查看结果</span></span><br></pre></td></tr></table></figure>

<p><img src="/img/hadoop/4/4/jps1.png"><br><img src="/img/hadoop/4/jps2.png"></p>
<h2 id="15-执行分布式的实验-分布式存储"><a href="#15-执行分布式的实验-分布式存储" class="headerlink" title="15. 执行分布式的实验-分布式存储"></a>15. 执行分布式的实验-分布式存储</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">执行分布式实例过程与伪分布式模式一样，首先创建 HDFS 上的用户目录：</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -<span class="built_in">mkdir</span> -p /user/hadoop</span></span><br><span class="line">将 /usr/local/hadoop/etc/hadoop 中的配置文件作为输入文件复制到分布式文件系统中：</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -<span class="built_in">mkdir</span> input</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">hdfs dfs -put /usr/local/hadoop/etc/hadoop/*.xml input</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>通过查看 DataNode 的状态（占用大小有改变），输入文件确实复制到了 DataNode 中，如下图所示：<br><img src="/img/hadoop/4/hdfssave.png"></p>
<h2 id="16-执行分布式的实验-MapReduce"><a href="#16-执行分布式的实验-MapReduce" class="headerlink" title="16. 执行分布式的实验-MapReduce"></a>16. 执行分布式的实验-MapReduce</h2><p>执行MapReduce作业</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>share<span class="regexp">/hadoop/m</span>apreduce<span class="regexp">/hadoop-mapreduce-examples-*.jar grep /u</span>ser<span class="regexp">/hadoop/i</span>nput <span class="regexp">/user/</span>hadoop/output <span class="string">&#x27;dfs[a-z.]+&#x27;</span></span><br><span class="line">查看http:<span class="regexp">//</span><span class="number">192.168</span>.<span class="number">1.80</span>:<span class="number">8088</span>/cluster看结果</span><br></pre></td></tr></table></figure>
<p>运行时的输出信息与伪分布式类似，会显示 Job 的进度。</p>
<p>可能会有点慢，但如果迟迟没有进度，比如 5 分钟都没看到进度，那不妨重启 Hadoop 再试试。若重启还不行，则很有可能是内存不足引起，建议增大虚拟机的内存，或者通过更改 YARN 的内存配置解决。<br>同样可以通过 Web 界面查看任务进度 <a href="http://master:8088/cluster%EF%BC%8C%E5%9C%A8">http://master:8088/cluster，在</a> Web 界面点击 “Tracking UI” 这一列的 History 连接，可以看到任务的运行信息，如下图所示：</p>
<p><img src="/img/hadoop/4/yarnfinish.png"></p>
<h2 id="17-关闭集群"><a href="#17-关闭集群" class="headerlink" title="17. 关闭集群"></a>17. 关闭集群</h2><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">stop</span>-yarn.<span class="keyword">sh</span></span><br><span class="line"><span class="keyword">stop</span>-dfs.<span class="keyword">sh</span></span><br><span class="line">mr-jobhistory-daemon.<span class="keyword">sh</span> <span class="keyword">stop</span> historyserver</span><br></pre></td></tr></table></figure>
    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="/" target="_blank">Ljjyy.com</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/archives/2019/06/100317.html" class="pre-post btn btn-default" title='大数据hadoop之 十一.组件HDFS'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">大数据hadoop之 十一.组件HDFS</span>
        </a>
    
    
        <a href="/archives/2019/06/100315.html" class="next-post btn btn-default" title='大数据hadoop之 九.Hadoop的伪分布式搭建'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">大数据hadoop之 九.Hadoop的伪分布式搭建</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>


    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: '5MzTXYXkt03k101j0PmSDN34-gzGzoHsz',
            appKey: 'iwjYgwno6qj3wtDVVSbe8nYQ',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91"><span class="toc-text">1. 网络拓扑</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AE%89%E8%A3%85JDK"><span class="toc-text">2. 安装JDK</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Hadoop%E7%94%A8%E6%88%B7%E7%9A%84%E5%88%9B%E5%BB%BA"><span class="toc-text">3. Hadoop用户的创建</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-hosts%E6%96%87%E4%BB%B6%E4%BF%AE%E6%94%B9"><span class="toc-text">4. hosts文件修改</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-SSH%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95"><span class="toc-text">5. SSH无密码登录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Hadoop%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-text">6. Hadoop的安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83192-168-1-80-NameNode"><span class="toc-text">7. 配置集群环境192.168.1.80 NameNode</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E6%96%87%E4%BB%B6slaves"><span class="toc-text">8. 文件slaves</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E6%96%87%E4%BB%B6-core-site-xml-%E6%94%B9%E4%B8%BA%E4%B8%8B%E9%9D%A2%E7%9A%84%E9%85%8D%E7%BD%AE%EF%BC%9A"><span class="toc-text">9. 文件 core-site.xml 改为下面的配置：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E6%96%87%E4%BB%B6-hdfs-site-xml%EF%BC%8Cdfs-replication-%E4%B8%80%E8%88%AC%E8%AE%BE%E4%B8%BA-3%EF%BC%8C%E4%BD%86%E6%88%91%E4%BB%AC%E5%8F%AA%E6%9C%89%E4%B8%80%E4%B8%AA-Slave-%E8%8A%82%E7%82%B9%EF%BC%8C%E6%89%80%E4%BB%A5-dfs-replication-%E7%9A%84%E5%80%BC%E8%BF%98%E6%98%AF%E8%AE%BE%E4%B8%BA-1%EF%BC%9A"><span class="toc-text">10. 文件 hdfs-site.xml，dfs.replication 一般设为 3，但我们只有一个 Slave 节点，所以 dfs.replication 的值还是设为 1：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E6%96%87%E4%BB%B6-mapred-site-xml-%EF%BC%88%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E5%85%88%E9%87%8D%E5%91%BD%E5%90%8D%EF%BC%8C%E9%BB%98%E8%AE%A4%E6%96%87%E4%BB%B6%E5%90%8D%E4%B8%BA-mapred-site-xml-template%EF%BC%89%EF%BC%8C%E7%84%B6%E5%90%8E%E9%85%8D%E7%BD%AE%E4%BF%AE%E6%94%B9%E5%A6%82%E4%B8%8B%EF%BC%9A"><span class="toc-text">11. 文件 mapred-site.xml （可能需要先重命名，默认文件名为 mapred-site.xml.template），然后配置修改如下：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-%E6%96%87%E4%BB%B6-yarn-site-xml%EF%BC%9A"><span class="toc-text">12. 文件 yarn-site.xml：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-%E5%9C%A8%E5%85%B6%E4%BB%96Slave%E8%8A%82%E7%82%B9%E9%9C%80%E8%A6%81%E5%81%9A%E7%9A%84"><span class="toc-text">13. 在其他Slave节点需要做的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-%E5%BC%80%E5%A7%8B%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-text">14. 开始启动集群</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-%E6%89%A7%E8%A1%8C%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%AE%9E%E9%AA%8C-%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8"><span class="toc-text">15. 执行分布式的实验-分布式存储</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16-%E6%89%A7%E8%A1%8C%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%AE%9E%E9%AA%8C-MapReduce"><span class="toc-text">16. 执行分布式的实验-MapReduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-%E5%85%B3%E9%97%AD%E9%9B%86%E7%BE%A4"><span class="toc-text">17. 关闭集群</span></a></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019-2025&emsp;<a href="/" class="copyright-links" target="_blank" rel="nofollow">Ljjyy.com</a>
                </span> |
                <span>
                    <a href="/about/" class="copyright-links" target="_blank" rel="nofollow">关于我们</a>
                </span> |                
                <span>
                    <a href="/sitemap.xml" class="copyright-links" target="_blank" rel="nofollow">网站地图</a>
                </span> |
                <span>
                    <a href="/archives/" class="copyright-links" target="_blank" rel="nofollow">时间轴</a>
                </span>              
            </div>
        </div>
    </div>
</div>








<script src="/js/app.js?rev=@@hash.js"></script>


</body>
</html>
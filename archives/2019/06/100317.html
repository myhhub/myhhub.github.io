<!DOCTYPE HTML>
<html lang="zh-CN">
<head>
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="https://www.ljjyy.com">
    <!--SEO-->

    <meta name="keywords" content="hadoop,hdfs" />


    <meta name="description" content="HDFS常用Shell命令HDFS文件操作&#160; &#160; &#160; &#160;HDFS是一种文件系统,专为MapReduce这类框架下的大规模分布式数据处理而设计,你可以把一个..." />



<meta name="robots" content="all" />
<meta name="google" content="all" />
<meta name="googlebot" content="all" />
<meta name="verify" content="all" />

    <!--Title-->


<title>大数据hadoop之 十一.组件HDFS | 来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</title>


    <link rel="alternate" href="/atom.xml" title="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    




<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7.css">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0.css">
<link rel="stylesheet" href="/css/style.css?rev=@@hash.css">





    
	<div class="hide">
        <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
        <script>LA.init({id: "JgbNOaw1xxsmUUsQ",ck: "JgbNOaw1xxsmUUsQ"})</script>
	</div>






    
    <meta name="baidu-site-verification" content="dTHILoORpx" />


    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

<meta name="generator" content="Hexo 7.3.0"></head>


<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  >
    <div class="main-header-box">
        <!--a class="header-avatar" href="/" title='Ljjyy.com'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a-->
        <div class="branding">
            
                <h2> 多读书多实践，勤思考善领悟 </h2>
            
    	  </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">

        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="web-logo"  href="/" title='Ljjyy.com'></a>
                    <!--a class="navbar-brand" href="https://www.ljjyy.com">来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</a-->
                </div>
                <div class="collapse navbar-collapse" id="main-menu" style="">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/cloud/"><i class="fa "></i>云计算</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/front/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/back/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/devops/"><i class="fa "></i>运维</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/crack/"><i class="fa "></i>破解</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/penetration/"><i class="fa "></i>渗透</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tool/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/other/"><i class="fa "></i>其他</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="大数据hadoop之 十一.组件HDFS">
            
	            大数据hadoop之 十一.组件HDFS
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/cloud/">云计算</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-none-link" href="/tags/hadoop/" rel="tag">hadoop</a> <a class="tag-none-link" href="/tags/hdfs/" rel="tag">hdfs</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/06/10</span>
        </span>
        
    
</div>
            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>2108</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <h1 id="HDFS常用Shell命令"><a href="#HDFS常用Shell命令" class="headerlink" title="HDFS常用Shell命令"></a>HDFS常用Shell命令</h1><h2 id="HDFS文件操作"><a href="#HDFS文件操作" class="headerlink" title="HDFS文件操作"></a>HDFS文件操作</h2><p>&#160; &#160; &#160; &#160;HDFS是一种文件系统,专为MapReduce这类框架下的大规模分布式数据处理而设计,你可以把一个大数据集(比如说100TB)在HDFS中存储为单个文件,而大多数其他的文件系统无力实现这一点.<br>&#160; &#160; &#160; &#160;HDFS并不是一个天生的UNIX文件系统,不支持像ls和cp这种标准的UNIX文件命令,也不支持如fopen()和fread()这样的标准文件读写操作.另一方面,Hadoop确也提供了一套与Linux文件命令类似的命令行工具.</p>
<h3 id="基本文件fs命令"><a href="#基本文件fs命令" class="headerlink" title="基本文件fs命令"></a>基本文件fs命令</h3><p>Hadoop的文件命令采取的形式为</p>
<p><code>hadoop fs -cmd &lt;args&gt;</code>  </p>
<p>基中cmd是具体的文件命令,而<code>&lt;args&gt;</code>是一组数据可变的参数.<code>cmd</code>的命名通常与unix对应的命令名相同.例如,文件形表命令为  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">ls</span>  </span><br><span class="line"></span><br><span class="line">hadoop fs -<span class="built_in">mkdir</span> /user/chuck</span><br><span class="line">hadoop fs -<span class="built_in">ls</span> /</span><br><span class="line">hadoop fs -put example.txt /user/chuck</span><br><span class="line">hadoop fs -<span class="built_in">ls</span></span><br><span class="line">hadoop fs -get example.txt .</span><br><span class="line">hadoop fs -<span class="built_in">cat</span> example.txt</span><br><span class="line">hadoop fs -<span class="built_in">rm</span>  example.txt</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="1-显示当前目录结构"><a href="#1-显示当前目录结构" class="headerlink" title="1. 显示当前目录结构"></a><strong>1. 显示当前目录结构</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示当前目录结构</span></span><br><span class="line">hadoop fs -<span class="built_in">ls</span>  &lt;path&gt;</span><br><span class="line"><span class="comment"># 递归显示当前目录结构</span></span><br><span class="line">hadoop fs -<span class="built_in">ls</span>  -R  &lt;path&gt;</span><br><span class="line"><span class="comment"># 显示根目录下内容</span></span><br><span class="line">hadoop fs -<span class="built_in">ls</span>  /</span><br></pre></td></tr></table></figure>

<h4 id="2-创建目录"><a href="#2-创建目录" class="headerlink" title="2. 创建目录"></a><strong>2. 创建目录</strong></h4><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 创建目录</span><br><span class="line">hadoop <span class="built_in">fs</span> -<span class="built_in">mkdir</span>  &lt;<span class="built_in">path</span>&gt; </span><br><span class="line"># 递归创建目录</span><br><span class="line">hadoop <span class="built_in">fs</span> -<span class="built_in">mkdir</span> -p  &lt;<span class="built_in">path</span>&gt;  </span><br></pre></td></tr></table></figure>

<p><strong>3. 删除操作</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除文件</span></span><br><span class="line">hadoop fs -<span class="built_in">rm</span>  &lt;path&gt;</span><br><span class="line"><span class="comment"># 递归删除目录和文件</span></span><br><span class="line">hadoop fs -<span class="built_in">rm</span> -R  &lt;path&gt; </span><br></pre></td></tr></table></figure>

<h4 id="4-从本地加载文件到HDFS"><a href="#4-从本地加载文件到HDFS" class="headerlink" title="4. 从本地加载文件到HDFS"></a><strong>4. 从本地加载文件到HDFS</strong></h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 二选一执行即可</span><br><span class="line">hadoop fs -put  <span class="selector-attr">[localsrc]</span> <span class="selector-attr">[dst]</span> </span><br><span class="line">hadoop fs - copyFromLocal <span class="selector-attr">[localsrc]</span> <span class="selector-attr">[dst]</span> </span><br></pre></td></tr></table></figure>

<h4 id="5-从HDFS导出文件到本地"><a href="#5-从HDFS导出文件到本地" class="headerlink" title="5. 从HDFS导出文件到本地"></a><strong>5. 从HDFS导出文件到本地</strong></h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 二选一执行即可</span><br><span class="line">hadoop fs -get  <span class="selector-attr">[dst]</span> <span class="selector-attr">[localsrc]</span> </span><br><span class="line">hadoop fs -copyToLocal <span class="selector-attr">[dst]</span> <span class="selector-attr">[localsrc]</span> </span><br></pre></td></tr></table></figure>

<p><strong>6. 查看文件内容</strong></p>
<figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 二选一执行即可</span><br><span class="line">hadoop <span class="built_in">fs</span> -text  &lt;<span class="built_in">path</span>&gt; </span><br><span class="line">hadoop <span class="built_in">fs</span> -cat  &lt;<span class="built_in">path</span>&gt;  </span><br></pre></td></tr></table></figure>

<h4 id="7-显示文件的最后一千字节"><a href="#7-显示文件的最后一千字节" class="headerlink" title="7. 显示文件的最后一千字节"></a><strong>7. 显示文件的最后一千字节</strong></h4><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop <span class="built_in">fs</span> -tail  &lt;<span class="built_in">path</span>&gt; </span><br><span class="line"># 和Linux下一样，会持续监听文件内容变化 并显示文件的最后一千字节</span><br><span class="line">hadoop <span class="built_in">fs</span> -tail -f  &lt;<span class="built_in">path</span>&gt; </span><br></pre></td></tr></table></figure>

<h4 id="8-拷贝文件"><a href="#8-拷贝文件" class="headerlink" title="8. 拷贝文件"></a><strong>8. 拷贝文件</strong></h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp <span class="selector-attr">[src]</span> <span class="selector-attr">[dst]</span></span><br></pre></td></tr></table></figure>

<h4 id="9-移动文件"><a href="#9-移动文件" class="headerlink" title="9. 移动文件"></a><strong>9. 移动文件</strong></h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv <span class="selector-attr">[src]</span> <span class="selector-attr">[dst]</span> </span><br></pre></td></tr></table></figure>

<h4 id="10-统计当前目录下各文件大小"><a href="#10-统计当前目录下各文件大小" class="headerlink" title="10. 统计当前目录下各文件大小"></a><strong>10. 统计当前目录下各文件大小</strong></h4><ul>
<li>默认单位字节</li>
<li>-s : 显示所有文件大小总和，</li>
<li>-h : 将以更友好的方式显示文件大小（例如64.0m而不是67108864）</li>
</ul>
<figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop <span class="built_in">fs</span> -du  &lt;<span class="built_in">path</span>&gt;  </span><br></pre></td></tr></table></figure>

<h4 id="11-合并下载多个文件"><a href="#11-合并下载多个文件" class="headerlink" title="11. 合并下载多个文件"></a><strong>11. 合并下载多个文件</strong></h4><ul>
<li>-nl 在每个文件的末尾添加换行符（LF）</li>
<li>-skip-empty-file 跳过空文件</li>
</ul>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -getmerge</span><br><span class="line"># 示例 将HDFS上的hbase-<span class="keyword">policy</span>.xml和hbase-site.xml文件合并后下载到本地的/usr/test.xml</span><br><span class="line">hadoop fs -getmerge -nl  /test/hbase-<span class="keyword">policy</span>.xml /test/hbase-site.xml /usr/test.xml</span><br></pre></td></tr></table></figure>

<h4 id="12-统计文件系统的可用空间信息"><a href="#12-统计文件系统的可用空间信息" class="headerlink" title="12. 统计文件系统的可用空间信息"></a><strong>12. 统计文件系统的可用空间信息</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">df</span> -h /</span><br></pre></td></tr></table></figure>

<h4 id="13-更改文件复制因子"><a href="#13-更改文件复制因子" class="headerlink" title="13. 更改文件复制因子"></a><strong>13. 更改文件复制因子</strong></h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep <span class="selector-attr">[-R]</span> <span class="selector-attr">[-w]</span> &lt;numReplicas&gt; &lt;<span class="selector-tag">path</span>&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>更改文件的复制因子。如果path是目录，则更改其下所有文件的复制因子</li>
<li>-w : 请求命令是否等待复制完成</li>
</ul>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例</span></span><br><span class="line"><span class="attribute">hadoop</span> fs -setrep -w <span class="number">3</span> /user/hadoop/dir1</span><br></pre></td></tr></table></figure>

<h4 id="14-权限控制"><a href="#14-权限控制" class="headerlink" title="14. 权限控制"></a><strong>14. 权限控制</strong></h4><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 权限控制和Linux上使用方式一致</span><br><span class="line"># 变更文件或目录的所属群组。 用户必须是文件的所有者或超级用户。</span><br><span class="line">hadoop fs -chgrp <span class="comment">[-R]</span> GROUP URI <span class="comment">[URI ...]</span></span><br><span class="line"># 修改文件或目录的访问权限  用户必须是文件的所有者或超级用户。</span><br><span class="line">hadoop fs -chmod <span class="comment">[-R]</span> &lt;MODE<span class="comment">[,MODE]</span>... | OCTALMODE&gt; URI <span class="comment">[URI ...]</span></span><br><span class="line"># 修改文件的拥有者  用户必须是超级用户。</span><br><span class="line">hadoop fs -chown <span class="comment">[-R]</span> <span class="comment">[OWNER]</span><span class="comment">[:<span class="comment">[GROUP]</span>]</span> URI <span class="comment">[URI ]</span></span><br></pre></td></tr></table></figure>

<h4 id="15-文件检测"><a href="#15-文件检测" class="headerlink" title="15. 文件检测"></a><strong>15. 文件检测</strong></h4><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop <span class="built_in">fs</span> -<span class="keyword">test</span> - [defsz]  URI</span><br></pre></td></tr></table></figure>

<p>可选选项：</p>
<ul>
<li>-d：如果路径是目录，返回0。</li>
<li>-e：如果路径存在，则返回0。</li>
<li>-f：如果路径是文件，则返回0。</li>
<li>-s：如果路径不为空，则返回0。</li>
<li>-r：如果路径存在且授予读权限，则返回0。</li>
<li>-w：如果路径存在且授予写入权限，则返回0。</li>
<li>-z：如果文件长度为零，则返回0。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例</span></span><br><span class="line">hadoop fs -<span class="built_in">test</span> -e filename</span><br></pre></td></tr></table></figure>

<h3 id="cat命令"><a href="#cat命令" class="headerlink" title="cat命令"></a>cat命令</h3><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">将路径指定文件的内容输出到stdout</span><br><span class="line">hadoop<span class="variable">@Master</span><span class="symbol">:~</span><span class="variable">$ </span>hadoop dfs -cat input/core-site.xml</span><br></pre></td></tr></table></figure>
<h3 id="chgrp命令"><a href="#chgrp命令" class="headerlink" title="chgrp命令"></a>chgrp命令</h3><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">改变文件所属组.使用-<span class="attribute">R</span>将使改变在目录结构下递归进行.命令的使用者必须是文件的所有者或者超级用户.</span><br></pre></td></tr></table></figure>
<h3 id="chmod命令"><a href="#chmod命令" class="headerlink" title="chmod命令"></a>chmod命令</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">修改文件权限</span><br></pre></td></tr></table></figure>
<h3 id="chown命令"><a href="#chown命令" class="headerlink" title="chown命令"></a>chown命令</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">改变文件的拥有者</span><br></pre></td></tr></table></figure>
<h3 id="cp命令"><a href="#cp命令" class="headerlink" title="cp命令"></a>cp命令</h3><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">将文件从源路径复制到目标路径,这个命令允许有多个源路径,此时目标路径必须是一个目录</span><br><span class="line">hadoop@<span class="literal">Master</span>:/usr/local/hadoop/etc/hadoop$ hdfs dfs -cp input/* output/</span><br><span class="line">hadoop@<span class="literal">Master</span>:/usr/local/hadoop/etc/hadoop$ hdfs dfs -ls output</span><br><span class="line">Found <span class="number">11</span> items</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup          <span class="number">0</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">25</span> <span class="number">22</span>:<span class="number">14</span> output/_SUCCESS</span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup       <span class="number">4436</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/capacity-scheduler.<span class="keyword">xml</span></span><br><span class="line"><span class="title">-rw-r--r--</span>   <span class="number">1</span> hadoop supergroup       <span class="number">1072</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/core-site.<span class="keyword">xml</span></span><br><span class="line"><span class="title">-rw-r--r--</span>   <span class="number">1</span> hadoop supergroup       <span class="number">9683</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/hadoop-policy.<span class="keyword">xml</span></span><br><span class="line"><span class="title">-rw-r--r--</span>   <span class="number">1</span> hadoop supergroup       <span class="number">1257</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/hdfs-site.<span class="keyword">xml</span></span><br><span class="line"><span class="title">-rw-r--r--</span>   <span class="number">1</span> hadoop supergroup        <span class="number">620</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/httpfs-site.<span class="keyword">xml</span></span><br><span class="line"><span class="title">-rw-r--r--</span>   <span class="number">1</span> hadoop supergroup       <span class="number">3523</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/kms-acls.<span class="keyword">xml</span></span><br><span class="line"><span class="title">-rw-r--r--</span>   <span class="number">1</span> hadoop supergroup       <span class="number">5511</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/kms-site.<span class="keyword">xml</span></span><br><span class="line"><span class="title">-rw-r--r--</span>   <span class="number">1</span> hadoop supergroup       <span class="number">1103</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/mapred-site.<span class="keyword">xml</span></span><br><span class="line"><span class="title">-rw-r--r--</span>   <span class="number">1</span> hadoop supergroup        <span class="number">107</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">25</span> <span class="number">22</span>:<span class="number">14</span> output/part-r-<span class="number">00000</span></span><br><span class="line">-rw-r--r--   <span class="number">1</span> hadoop supergroup        <span class="number">924</span> <span class="number">2016</span>-<span class="number">01</span>-<span class="number">27</span> <span class="number">19</span>:<span class="number">16</span> output/yarn-site.<span class="keyword">xml</span></span><br><span class="line"><span class="title"></span></span><br></pre></td></tr></table></figure>
<h3 id="du命令"><a href="#du命令" class="headerlink" title="du命令"></a>du命令</h3><p>显示目录中所有文件的大小,或者当只指定一个文件时,显示此文件的大小.</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop<span class="variable">@Master</span><span class="symbol">:/usr/local/hadoop/etc/hadoop</span><span class="variable">$ </span>hadoop fs -du input/core-site.xml</span><br></pre></td></tr></table></figure>
<h3 id="expunge命令"><a href="#expunge命令" class="headerlink" title="expunge命令"></a>expunge命令</h3><p>清空回收站<br>除了文件权限之外,还有一个保护机制可以防止在HDFS上意外删除文件,这就是回收站,默认情况下该功能是被禁用.当它启用后,用于删除的命令行不会立即删除文件.<br>相反它们会暂时的把文件移动到用户工作目录下的.Trash文件夹下.若要启用回收站功能并设置清空回收站的时间延迟,可能通过设置core-site.xml的fs.trash.interval属性(以分钟为单位).<br>例如如果你希望用户有24个小时的时间来还原已删除的文件,就应该在core-site.xml中设置.<br>如果将该值设置为0,则将禁用回收站的功能</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>


<h3 id="get命令"><a href="#get命令" class="headerlink" title="get命令"></a>get命令</h3><p>复制文件到本地文件系统.</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="keyword">get</span> <span class="keyword">input</span>/hadoop.tar.gz ~/</span><br></pre></td></tr></table></figure>

<h3 id="lsr命令"><a href="#lsr命令" class="headerlink" title="lsr命令"></a>lsr命令</h3><p>ls命令的递归版本,类似于Unix中的ls -R<br>###mkdir命令</p>
<p>接受路径指定的uri作为参数,创建这些目录,其行为类似于Unix的mkdir -p,它会创建路径中的各级父目录.</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir <span class="regexp">/user/</span>hadoop<span class="regexp">/dir1 /u</span>ser<span class="regexp">/hadoop/</span>dir2</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="mv命令"><a href="#mv命令" class="headerlink" title="mv命令"></a>mv命令</h3><p>将文件从源路径移动到目标路径</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mv <span class="regexp">/user/</span>hadoop<span class="regexp">/file1 /u</span>ser<span class="regexp">/hadoop/</span>file2</span><br></pre></td></tr></table></figure>
<h3 id="put命令"><a href="#put命令" class="headerlink" title="put命令"></a>put命令</h3><p>从本地文件系统中复制单个或者多个源路径到目标文件系统.也支持从标准输入中读取输入写入目标文件系统.</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put /tmp/*.<span class="keyword">xml</span> <span class="title">/user</span>/hadoop/</span><br></pre></td></tr></table></figure>

<h3 id="rmr命令"><a href="#rmr命令" class="headerlink" title="rmr命令"></a>rmr命令</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rmr <span class="regexp">/user/</span>hadoop/chu888chu888</span><br></pre></td></tr></table></figure>
<h3 id="job命令"><a href="#job命令" class="headerlink" title="job命令"></a>job命令</h3><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">* Job操作</span><br><span class="line">* 提交MapReduce Job, Hadoop所有的MapReduce Job都是一个jar包</span><br><span class="line">* $ hadoop jar <span class="symbol">&lt;local-jar-file&gt;</span> <span class="symbol">&lt;java-class&gt;</span> <span class="symbol">&lt;hdfs-input-file&gt;</span> <span class="symbol">&lt;hdfs-output-dir&gt;</span></span><br><span class="line">* $ hadoop jar <span class="keyword">sandbox</span>-mapred-<span class="number">0.0</span>.<span class="number">20</span>.jar <span class="keyword">sandbox</span>.mapred.WordCountJob /user/<span class="keyword">cl</span>/<span class="built_in">input</span>.dat /user/<span class="keyword">cl</span>/outputdir</span><br><span class="line">*</span><br><span class="line">* 杀死某个正在运行的Job</span><br><span class="line">* 假设Job_Id为：job_201207121738_0001</span><br><span class="line">* $ hadoop job -kill job_201207121738_0001</span><br></pre></td></tr></table></figure>

<h3 id="系统体检"><a href="#系统体检" class="headerlink" title="系统体检"></a>系统体检</h3><p>Hadoop提供的文件系统检查工具叫做fsck,如参数为文件路径时,它会递归检查该路径下所有文件的健康状态,如果参数为&#x2F;,它就会检查整个文件系统,如下输出一个例子.</p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">hadoop<span class="keyword">@Master</span>:~$ hadoop fsck /</span><br><span class="line"><span class="attribute">DEPRECATED</span>: Use of this script to execute hdfs command is deprecated.</span><br><span class="line">Instead use the hdfs command for it.</span><br><span class="line"></span><br><span class="line"><span class="number">16</span>/<span class="number">01</span>/<span class="number">27</span> <span class="number">22</span>:<span class="number">55</span>:<span class="number">14</span> WARN util.<span class="attribute">NativeCodeLoader</span>: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Connecting to namenode via <span class="attribute">http</span>://<span class="attribute">Master</span>:<span class="number">50070</span></span><br><span class="line">FSCK started by hadoop (<span class="attribute">auth</span>:SIMPLE) from /<span class="number">192.168</span>.<span class="number">1.80</span> for path / at Wed Jan <span class="number">27</span> <span class="number">22</span>:<span class="number">55</span>:<span class="number">15</span> CST <span class="number">2016</span></span><br><span class="line">.....................<span class="attribute">Status</span>: HEALTHY</span><br><span class="line"> Total <span class="attribute">size</span>:	<span class="number">878899</span> B</span><br><span class="line"> Total <span class="attribute">dirs</span>:	<span class="number">21</span></span><br><span class="line"> Total <span class="attribute">files</span>:	<span class="number">21</span></span><br><span class="line"> Total <span class="attribute">symlinks</span>:		<span class="number">0</span></span><br><span class="line"> Total blocks (validated):	<span class="number">20</span> (avg. block size <span class="number">43944</span> B)</span><br><span class="line"> Minimally replicated <span class="attribute">blocks</span>:	<span class="number">20</span> (<span class="number">100.0</span> %)</span><br><span class="line"> Over-replicated <span class="attribute">blocks</span>:	<span class="number">0</span> (<span class="number">0.0</span> %)</span><br><span class="line"> Under-replicated <span class="attribute">blocks</span>:	<span class="number">0</span> (<span class="number">0.0</span> %)</span><br><span class="line"> Mis-replicated <span class="attribute">blocks</span>:		<span class="number">0</span> (<span class="number">0.0</span> %)</span><br><span class="line"> Default replication <span class="attribute">factor</span>:	<span class="number">1</span></span><br><span class="line"> Average block <span class="attribute">replication</span>:	<span class="number">1.0</span></span><br><span class="line"> Corrupt <span class="attribute">blocks</span>:		<span class="number">0</span></span><br><span class="line"> Missing <span class="attribute">replicas</span>:		<span class="number">0</span> (<span class="number">0.0</span> %)</span><br><span class="line"> Number of <span class="attribute">data-nodes</span>:		<span class="number">2</span></span><br><span class="line"> Number of <span class="attribute">racks</span>:		<span class="number">1</span></span><br><span class="line">FSCK ended at Wed Jan <span class="number">27</span> <span class="number">22</span>:<span class="number">55</span>:<span class="number">15</span> CST <span class="number">2016</span> in <span class="number">32</span> milliseconds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">The filesystem under path <span class="string">&#x27;/&#x27;</span> is HEALTHY</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="HDFS-Java-API的使用"><a href="#HDFS-Java-API的使用" class="headerlink" title="HDFS Java API的使用"></a>HDFS Java API的使用</h1><h2 id="一、-简介"><a href="#一、-简介" class="headerlink" title="一、 简介"></a>一、 简介</h2><p>想要使用HDFS API，需要导入依赖<code>hadoop-client</code>。如果是CDH版本的Hadoop，还需要额外指明其仓库地址：</p>
<figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 </span></span></span></span><br><span class="line"><span class="string"><span class="tag"><span class="language-xml">         http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.heibaiying<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hdfs-java-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>2.6.0-cdh5.15.2<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    <span class="comment">&lt;!---配置CDH仓库地址--&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>cloudera<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="comment">&lt;!--Hadoop-client--&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$</span><span class="template-variable">&#123;hadoop.version&#125;</span><span class="language-xml"><span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>4.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span></span><br></pre></td></tr></table></figure>

<h2 id="二、API的使用"><a href="#二、API的使用" class="headerlink" title="二、API的使用"></a>二、API的使用</h2><h3 id="2-1-FileSystem"><a href="#2-1-FileSystem" class="headerlink" title="2.1 FileSystem"></a>2.1 FileSystem</h3><p>FileSystem是所有HDFS操作的主入口。由于之后的每个单元测试都需要用到它，这里使用<code>@Before</code>注解进行标注。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">HDFS_PATH</span> <span class="operator">=</span> <span class="string">&quot;hdfs://192.168.0.106:8020&quot;</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">HDFS_USER</span> <span class="operator">=</span> <span class="string">&quot;root&quot;</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> FileSystem fileSystem;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Before</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">prepare</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 这里我启动的是单节点的Hadoop,所以副本系数设置为1,默认值为3</span></span><br><span class="line">        configuration.set(<span class="string">&quot;dfs.replication&quot;</span>, <span class="string">&quot;1&quot;</span>);</span><br><span class="line">        fileSystem = FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(HDFS_PATH), configuration, HDFS_USER);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (URISyntaxException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@After</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">destroy</span><span class="params">()</span> &#123;</span><br><span class="line">    fileSystem = <span class="literal">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-2-创建目录"><a href="#2-2-创建目录" class="headerlink" title="2.2 创建目录"></a>2.2 创建目录</h3><p>支持递归创建目录：</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">mkDir</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    fileSystem.mkdirs(<span class="keyword">new</span> Path(<span class="string">&quot;/hdfs-api/test0/&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-创建指定权限的目录"><a href="#2-3-创建指定权限的目录" class="headerlink" title="2.3 创建指定权限的目录"></a>2.3 创建指定权限的目录</h3><p><code>FsPermission(FsAction u, FsAction g, FsAction o)</code> 的三个参数分别对应：创建者权限，同组其他用户权限，其他用户权限，权限值定义在<code>FsAction</code>枚举类中。</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line"><span class="built_in">public</span> <span class="type">void</span> mkDirWithPermission() throws <span class="keyword">Exception</span> &#123;</span><br><span class="line">    fileSystem.mkdirs(<span class="built_in">new</span> Path(&quot;/hdfs-api/test1/&quot;),</span><br><span class="line">            <span class="built_in">new</span> FsPermission(FsAction.READ_WRITE, FsAction.<span class="keyword">READ</span>, FsAction.<span class="keyword">READ</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-4-创建文件，并写入内容"><a href="#2-4-创建文件，并写入内容" class="headerlink" title="2.4 创建文件，并写入内容"></a>2.4 创建文件，并写入内容</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line"><span class="built_in">public</span> <span class="type">void</span> <span class="keyword">create</span>() throws <span class="keyword">Exception</span> &#123;</span><br><span class="line">    // 如果文件存在，默认会覆盖, 可以通过第二个参数进行控制。第三个参数可以控制使用缓冲区的大小</span><br><span class="line">    FSDataOutputStream <span class="keyword">out</span> = fileSystem.<span class="keyword">create</span>(<span class="built_in">new</span> Path(&quot;/hdfs-api/test/a.txt&quot;),</span><br><span class="line">                                               <span class="keyword">true</span>, <span class="number">4096</span>);</span><br><span class="line">    <span class="keyword">out</span>.<span class="keyword">write</span>(&quot;hello hadoop!&quot;.getBytes());</span><br><span class="line">    <span class="keyword">out</span>.<span class="keyword">write</span>(&quot;hello spark!&quot;.getBytes());</span><br><span class="line">    <span class="keyword">out</span>.<span class="keyword">write</span>(&quot;hello flink!&quot;.getBytes());</span><br><span class="line">    // 强制将缓冲区中内容刷出</span><br><span class="line">    <span class="keyword">out</span>.flush();</span><br><span class="line">    <span class="keyword">out</span>.<span class="keyword">close</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-5-判断文件是否存在"><a href="#2-5-判断文件是否存在" class="headerlink" title="2.5 判断文件是否存在"></a>2.5 判断文件是否存在</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line"><span class="built_in">public</span> <span class="type">void</span> exist() throws <span class="keyword">Exception</span> &#123;</span><br><span class="line">    <span class="type">boolean</span> <span class="keyword">exists</span> = fileSystem.<span class="keyword">exists</span>(<span class="built_in">new</span> Path(&quot;/hdfs-api/test/a.txt&quot;));</span><br><span class="line">    <span class="keyword">System</span>.<span class="keyword">out</span>.println(<span class="keyword">exists</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-6-查看文件内容"><a href="#2-6-查看文件内容" class="headerlink" title="2.6 查看文件内容"></a>2.6 查看文件内容</h3><p>查看小文本文件的内容，直接转换成字符串后输出：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readToString</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">FSDataInputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> fileSystem.open(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfs-api/test/a.txt&quot;</span>));</span><br><span class="line">    <span class="type">String</span> <span class="variable">context</span> <span class="operator">=</span> inputStreamToString(inputStream, <span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">    System.out.println(context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>inputStreamToString</code>是一个自定义方法，代码如下：</p>
<figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 把输入流转换为指定编码的字符</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param inputStream 输入流</span></span><br><span class="line"><span class="comment"> * @param encode      指定编码类型</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="built_in">String</span> <span class="title function_">inputStreamToString</span>(InputStream inputStream, <span class="built_in">String</span> encode) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (encode == <span class="literal">null</span> || (<span class="string">&quot;&quot;</span>.<span class="property">equals</span>(encode))) &#123;</span><br><span class="line">            encode = <span class="string">&quot;utf-8&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">BufferedReader</span> reader = <span class="keyword">new </span><span class="class title_">BufferedReader</span>(<span class="keyword">new </span><span class="class title_">InputStreamReader</span>(inputStream, encode));</span><br><span class="line">        StringBuilder builder = <span class="keyword">new </span><span class="class title_">StringBuilder</span>();</span><br><span class="line">        <span class="built_in">String</span> <span class="built_in">str</span> = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">while</span> ((<span class="built_in">str</span> = reader.<span class="property">readLine</span>()) != <span class="literal">null</span>) &#123;</span><br><span class="line">            builder.<span class="property">append</span>(<span class="built_in">str</span>).<span class="property">append</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> builder.<span class="property">toString</span>();</span><br><span class="line">    &#125; <span class="title function_">catch</span> (IOException e) &#123;</span><br><span class="line">        e.<span class="property">printStackTrace</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-7-文件重命名"><a href="#2-7-文件重命名" class="headerlink" title="2.7 文件重命名"></a>2.7 文件重命名</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line"><span class="built_in">public</span> <span class="type">void</span> <span class="keyword">rename</span>() throws <span class="keyword">Exception</span> &#123;</span><br><span class="line">    <span class="type">Path</span> oldPath = <span class="built_in">new</span> Path(&quot;/hdfs-api/test/a.txt&quot;);</span><br><span class="line">    <span class="type">Path</span> newPath = <span class="built_in">new</span> Path(&quot;/hdfs-api/test/b.txt&quot;);</span><br><span class="line">    <span class="type">boolean</span> result = fileSystem.<span class="keyword">rename</span>(oldPath, newPath);</span><br><span class="line">    <span class="keyword">System</span>.<span class="keyword">out</span>.println(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-8-删除目录或文件"><a href="#2-8-删除目录或文件" class="headerlink" title="2.8 删除目录或文件"></a>2.8 删除目录或文件</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">public</span> <span class="type">void</span> <span class="keyword">delete</span>() throws <span class="keyword">Exception</span> &#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     *  第二个参数代表是否递归删除</span></span><br><span class="line"><span class="comment">     *    +  如果path是一个目录且递归删除为true, 则删除该目录及其中所有文件;</span></span><br><span class="line"><span class="comment">     *    +  如果path是一个目录但递归删除为false,则会则抛出异常。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="type">boolean</span> result = fileSystem.<span class="keyword">delete</span>(<span class="built_in">new</span> Path(&quot;/hdfs-api/test/b.txt&quot;), <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">System</span>.<span class="keyword">out</span>.println(result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-9-上传文件到HDFS"><a href="#2-9-上传文件到HDFS" class="headerlink" title="2.9 上传文件到HDFS"></a>2.9 上传文件到HDFS</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">copyFromLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="comment">// 如果指定的是目录，则会把目录及其中的文件都复制到指定目录下</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\BigData-Notes\\notes\\installation&quot;</span>);</span><br><span class="line">    <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfs-api/test/&quot;</span>);</span><br><span class="line">    fileSystem.copyFromLocalFile(src, dst);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-10-上传大文件并显示上传进度"><a href="#2-10-上传大文件并显示上传进度" class="headerlink" title="2.10 上传大文件并显示上传进度"></a>2.10 上传大文件并显示上传进度</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">copyFromLocalBigFile</span>() throws Exception</span> &#123;</span><br><span class="line"></span><br><span class="line">        File <span class="keyword">file</span> = <span class="keyword">new</span> File(<span class="string">&quot;D:\\kafka.tgz&quot;</span>);</span><br><span class="line">        final <span class="built_in">float</span> fileSize = <span class="keyword">file</span>.length();</span><br><span class="line">        InputStream <span class="keyword">in</span> = <span class="keyword">new</span> BufferedInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">file</span>));</span><br><span class="line"></span><br><span class="line">        FSDataOutputStream <span class="keyword">out</span> = fileSystem.create(<span class="keyword">new</span> Path(<span class="string">&quot;/hdfs-api/test/kafka5.tgz&quot;</span>),</span><br><span class="line">                <span class="keyword">new</span> Progressable() &#123;</span><br><span class="line">                  <span class="built_in">long</span> fileCount = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">                  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">progress</span>()</span> &#123;</span><br><span class="line">                     fileCount++;</span><br><span class="line">                     <span class="comment">// progress方法每上传大约64KB的数据后就会被调用一次</span></span><br><span class="line">                     System.<span class="keyword">out</span>.println(<span class="string">&quot;上传进度：&quot;</span> + (fileCount * <span class="number">64</span> * <span class="number">1024</span> / fileSize) * <span class="number">100</span> + <span class="string">&quot; %&quot;</span>);</span><br><span class="line">                   &#125;</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line">        IOUtils.copyBytes(<span class="keyword">in</span>, <span class="keyword">out</span>, <span class="number">4096</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-11-从HDFS上下载文件"><a href="#2-11-从HDFS上下载文件" class="headerlink" title="2.11 从HDFS上下载文件"></a>2.11 从HDFS上下载文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">copyToLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfs-api/test/kafka.tgz&quot;</span>);</span><br><span class="line">    <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:\\app\\&quot;</span>);</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 第一个参数控制下载完成后是否删除源文件,默认是true,即删除;</span></span><br><span class="line"><span class="comment">     * 最后一个参数表示是否将RawLocalFileSystem用作本地文件系统;</span></span><br><span class="line"><span class="comment">     * RawLocalFileSystem默认为false,通常情况下可以不设置,</span></span><br><span class="line"><span class="comment">     * 但如果你在执行时候抛出NullPointerException异常,则代表你的文件系统与程序可能存在不兼容的情况(window下常见),</span></span><br><span class="line"><span class="comment">     * 此时可以将RawLocalFileSystem设置为true</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    fileSystem.copyToLocalFile(<span class="literal">false</span>, src, dst, <span class="literal">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-12-查看指定目录下所有文件的信息"><a href="#2-12-查看指定目录下所有文件的信息" class="headerlink" title="2.12 查看指定目录下所有文件的信息"></a>2.12 查看指定目录下所有文件的信息</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listFiles</span>() throws Exception</span> &#123;</span><br><span class="line">    FileStatus[] statuses = fileSystem.listStatus(<span class="keyword">new</span> Path(<span class="string">&quot;/hdfs-api&quot;</span>));</span><br><span class="line">    <span class="keyword">for</span> (FileStatus fileStatus : statuses) &#123;</span><br><span class="line">        <span class="comment">//fileStatus的toString方法被重写过，直接打印可以看到所有信息</span></span><br><span class="line">        System.<span class="keyword">out</span>.println(fileStatus.toString());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>FileStatus</code>中包含了文件的基本信息，比如文件路径，是否是文件夹，修改时间，访问时间，所有者，所属组，文件权限，是否是符号链接等，输出内容示例如下：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FileStatus&#123;</span><br><span class="line"><span class="attribute">path</span>=hdfs://192.168.0.106:8020/hdfs-api/test; </span><br><span class="line"><span class="attribute">isDirectory</span>=<span class="literal">true</span>; </span><br><span class="line"><span class="attribute">modification_time</span>=1556680796191; </span><br><span class="line"><span class="attribute">access_time</span>=0; </span><br><span class="line"><span class="attribute">owner</span>=root; </span><br><span class="line"><span class="attribute">group</span>=supergroup; </span><br><span class="line"><span class="attribute">permission</span>=rwxr-xr-x; </span><br><span class="line"><span class="attribute">isSymlink</span>=<span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-13-递归查看指定目录下所有文件的信息"><a href="#2-13-递归查看指定目录下所有文件的信息" class="headerlink" title="2.13 递归查看指定目录下所有文件的信息"></a>2.13 递归查看指定目录下所有文件的信息</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line"><span class="built_in">public</span> <span class="type">void</span> listFilesRecursive() throws <span class="keyword">Exception</span> &#123;</span><br><span class="line">    RemoteIterator&lt;LocatedFileStatus&gt; files = fileSystem.listFiles(<span class="built_in">new</span> Path(&quot;/hbase&quot;), <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">while</span> (files.hasNext()) &#123;</span><br><span class="line">        <span class="keyword">System</span>.<span class="keyword">out</span>.println(files.next());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>和上面输出类似，只是多了文本大小，副本系数，块大小信息。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">LocatedFileStatus&#123;</span><br><span class="line"><span class="attribute">path</span>=hdfs://192.168.0.106:8020/hbase/hbase.version; </span><br><span class="line"><span class="attribute">isDirectory</span>=<span class="literal">false</span>; </span><br><span class="line"><span class="attribute">length</span>=7; </span><br><span class="line"><span class="attribute">replication</span>=1; </span><br><span class="line"><span class="attribute">blocksize</span>=134217728; </span><br><span class="line"><span class="attribute">modification_time</span>=1554129052916; </span><br><span class="line"><span class="attribute">access_time</span>=1554902661455; </span><br><span class="line"><span class="attribute">owner</span>=root; <span class="attribute">group</span>=supergroup;</span><br><span class="line"><span class="attribute">permission</span>=rw-r--r--; </span><br><span class="line"><span class="attribute">isSymlink</span>=<span class="literal">false</span>&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-14-查看文件的块信息"><a href="#2-14-查看文件的块信息" class="headerlink" title="2.14 查看文件的块信息"></a>2.14 查看文件的块信息</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getFileBlockLocations</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">FileStatus</span> <span class="variable">fileStatus</span> <span class="operator">=</span> fileSystem.getFileStatus(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfs-api/test/kafka.tgz&quot;</span>));</span><br><span class="line">    BlockLocation[] blocks = fileSystem.getFileBlockLocations(fileStatus, <span class="number">0</span>, fileStatus.getLen());</span><br><span class="line">    <span class="keyword">for</span> (BlockLocation block : blocks) &#123;</span><br><span class="line">        System.out.println(block);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>块输出信息有三个值，分别是文件的起始偏移量(offset)，文件大小(length)，块所在的主机名(hosts)。</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">0</span>,<span class="number">57028557</span>,hadoop001</span><br></pre></td></tr></table></figure>

<p><strong>以上所有测试用例下载地址</strong>：<a href="https://github.com/myhhub/BigData-Notes/tree/master/code/Hadoop/hdfs-java-api">HDFS Java API</a></p>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="/" target="_blank">Ljjyy.com</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/archives/2019/06/100318.html" class="pre-post btn btn-default" title='大数据hadoop之 十二.SSH免密钥登录'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">大数据hadoop之 十二.SSH免密钥登录</span>
        </a>
    
    
        <a href="/archives/2019/06/100316.html" class="next-post btn btn-default" title='大数据hadoop之 十.Hadoop的完全分布式搭建'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">大数据hadoop之 十.Hadoop的完全分布式搭建</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>


    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: '5MzTXYXkt03k101j0PmSDN34-gzGzoHsz',
            appKey: 'iwjYgwno6qj3wtDVVSbe8nYQ',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#HDFS%E5%B8%B8%E7%94%A8Shell%E5%91%BD%E4%BB%A4"><span class="toc-text">HDFS常用Shell命令</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C"><span class="toc-text">HDFS文件操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%96%87%E4%BB%B6fs%E5%91%BD%E4%BB%A4"><span class="toc-text">基本文件fs命令</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%98%BE%E7%A4%BA%E5%BD%93%E5%89%8D%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="toc-text">1. 显示当前目录结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95"><span class="toc-text">2. 创建目录</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E4%BB%8E%E6%9C%AC%E5%9C%B0%E5%8A%A0%E8%BD%BD%E6%96%87%E4%BB%B6%E5%88%B0HDFS"><span class="toc-text">4. 从本地加载文件到HDFS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E4%BB%8EHDFS%E5%AF%BC%E5%87%BA%E6%96%87%E4%BB%B6%E5%88%B0%E6%9C%AC%E5%9C%B0"><span class="toc-text">5. 从HDFS导出文件到本地</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-%E6%98%BE%E7%A4%BA%E6%96%87%E4%BB%B6%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%8D%83%E5%AD%97%E8%8A%82"><span class="toc-text">7. 显示文件的最后一千字节</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-%E6%8B%B7%E8%B4%9D%E6%96%87%E4%BB%B6"><span class="toc-text">8. 拷贝文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-%E7%A7%BB%E5%8A%A8%E6%96%87%E4%BB%B6"><span class="toc-text">9. 移动文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-%E7%BB%9F%E8%AE%A1%E5%BD%93%E5%89%8D%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%90%84%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F"><span class="toc-text">10. 统计当前目录下各文件大小</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-%E5%90%88%E5%B9%B6%E4%B8%8B%E8%BD%BD%E5%A4%9A%E4%B8%AA%E6%96%87%E4%BB%B6"><span class="toc-text">11. 合并下载多个文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-%E7%BB%9F%E8%AE%A1%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%AF%E7%94%A8%E7%A9%BA%E9%97%B4%E4%BF%A1%E6%81%AF"><span class="toc-text">12. 统计文件系统的可用空间信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-%E6%9B%B4%E6%94%B9%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6%E5%9B%A0%E5%AD%90"><span class="toc-text">13. 更改文件复制因子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#14-%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6"><span class="toc-text">14. 权限控制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-%E6%96%87%E4%BB%B6%E6%A3%80%E6%B5%8B"><span class="toc-text">15. 文件检测</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cat%E5%91%BD%E4%BB%A4"><span class="toc-text">cat命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#chgrp%E5%91%BD%E4%BB%A4"><span class="toc-text">chgrp命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#chmod%E5%91%BD%E4%BB%A4"><span class="toc-text">chmod命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#chown%E5%91%BD%E4%BB%A4"><span class="toc-text">chown命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cp%E5%91%BD%E4%BB%A4"><span class="toc-text">cp命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#du%E5%91%BD%E4%BB%A4"><span class="toc-text">du命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#expunge%E5%91%BD%E4%BB%A4"><span class="toc-text">expunge命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#get%E5%91%BD%E4%BB%A4"><span class="toc-text">get命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lsr%E5%91%BD%E4%BB%A4"><span class="toc-text">lsr命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mv%E5%91%BD%E4%BB%A4"><span class="toc-text">mv命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#put%E5%91%BD%E4%BB%A4"><span class="toc-text">put命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rmr%E5%91%BD%E4%BB%A4"><span class="toc-text">rmr命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#job%E5%91%BD%E4%BB%A4"><span class="toc-text">job命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E4%BD%93%E6%A3%80"><span class="toc-text">系统体检</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HDFS-Java-API%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-text">HDFS Java API的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81-%E7%AE%80%E4%BB%8B"><span class="toc-text">一、 简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81API%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-text">二、API的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-FileSystem"><span class="toc-text">2.1 FileSystem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95"><span class="toc-text">2.2 创建目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E5%88%9B%E5%BB%BA%E6%8C%87%E5%AE%9A%E6%9D%83%E9%99%90%E7%9A%84%E7%9B%AE%E5%BD%95"><span class="toc-text">2.3 创建指定权限的目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%EF%BC%8C%E5%B9%B6%E5%86%99%E5%85%A5%E5%86%85%E5%AE%B9"><span class="toc-text">2.4 创建文件，并写入内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E5%88%A4%E6%96%AD%E6%96%87%E4%BB%B6%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8"><span class="toc-text">2.5 判断文件是否存在</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6-%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9"><span class="toc-text">2.6 查看文件内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-7-%E6%96%87%E4%BB%B6%E9%87%8D%E5%91%BD%E5%90%8D"><span class="toc-text">2.7 文件重命名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-8-%E5%88%A0%E9%99%A4%E7%9B%AE%E5%BD%95%E6%88%96%E6%96%87%E4%BB%B6"><span class="toc-text">2.8 删除目录或文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-9-%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0HDFS"><span class="toc-text">2.9 上传文件到HDFS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-10-%E4%B8%8A%E4%BC%A0%E5%A4%A7%E6%96%87%E4%BB%B6%E5%B9%B6%E6%98%BE%E7%A4%BA%E4%B8%8A%E4%BC%A0%E8%BF%9B%E5%BA%A6"><span class="toc-text">2.10 上传大文件并显示上传进度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-11-%E4%BB%8EHDFS%E4%B8%8A%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6"><span class="toc-text">2.11 从HDFS上下载文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-12-%E6%9F%A5%E7%9C%8B%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E4%B8%8B%E6%89%80%E6%9C%89%E6%96%87%E4%BB%B6%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="toc-text">2.12 查看指定目录下所有文件的信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-13-%E9%80%92%E5%BD%92%E6%9F%A5%E7%9C%8B%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E4%B8%8B%E6%89%80%E6%9C%89%E6%96%87%E4%BB%B6%E7%9A%84%E4%BF%A1%E6%81%AF"><span class="toc-text">2.13 递归查看指定目录下所有文件的信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-14-%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E7%9A%84%E5%9D%97%E4%BF%A1%E6%81%AF"><span class="toc-text">2.14 查看文件的块信息</span></a></li></ol></li></ol></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019-2025&emsp;<a href="/" class="copyright-links" target="_blank" rel="nofollow">Ljjyy.com</a>
                </span> |
                <span>
                    <a href="/about/" class="copyright-links" target="_blank" rel="nofollow">关于我们</a>
                </span> |                
                <span>
                    <a href="/sitemap.xml" class="copyright-links" target="_blank" rel="nofollow">网站地图</a>
                </span> |
                <span>
                    <a href="/archives/" class="copyright-links" target="_blank" rel="nofollow">时间轴</a>
                </span>              
            </div>
        </div>
    </div>
</div>








<script src="/js/app.js?rev=@@hash.js"></script>


</body>
</html>
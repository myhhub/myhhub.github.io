<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="https://www.ljjyy.com">
    <!--SEO-->

    <meta name="keywords" content="hadoop,hive">


    <meta name="description" content="一 数据源的准备工作首先我们去一个网站下载相关的数据,之后通过hive导入进行实验.http://grouplens.org/

二 内部表1 创建内部表并载入数据123456789101112...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>大数据hadoop之 二十二.Hive综合案例实战 | 来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</title>


    <link rel="alternate" href="/atom.xml" title="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
        <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
        <script>LA.init({id: "JgbNOaw1xxsmUUsQ",ck: "JgbNOaw1xxsmUUsQ"})</script>
	</div>






    
    <meta name="baidu-site-verification" content="dTHILoORpx">


    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  >
    <div class="main-header-box">
        <!--a class="header-avatar" href="/" title='Ljjyy.com'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a-->
        <div class="branding">
            
                <h2> 多读书多实践，勤思考善领悟 </h2>
            
    	  </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">

        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="web-logo"  href="/" title='Ljjyy.com'></a>
                    <!--a class="navbar-brand" href="https://www.ljjyy.com">来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</a-->
                </div>
                <div class="collapse navbar-collapse" id="main-menu" style="">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/cloud/"><i class="fa "></i>云计算</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/front/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/back/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/devops/"><i class="fa "></i>运维</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/crack/"><i class="fa "></i>破解</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/penetration/"><i class="fa "></i>渗透</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tool/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/other/"><i class="fa "></i>其他</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="大数据hadoop之 二十二.Hive综合案例实战">
            
	            大数据hadoop之 二十二.Hive综合案例实战
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/cloud/">云计算</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/hadoop/">hadoop</a> <a class="tag-link" href="/tags/hive/">hive</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/06/19</span>
        </span>
        
    
</div>
            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>1854</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <h2 id="一-数据源的准备工作"><a href="#一-数据源的准备工作" class="headerlink" title="一 数据源的准备工作"></a>一 数据源的准备工作</h2><p>首先我们去一个网站下载相关的数据,之后通过hive导入进行实验.<a href="http://grouplens.org/" target="_blank" rel="noopener">http://grouplens.org/</a></p>
<p><img src="/img/hadoop/10/chapter10001.png" alt></p>
<h2 id="二-内部表"><a href="#二-内部表" class="headerlink" title="二 内部表"></a>二 内部表</h2><h3 id="1-创建内部表并载入数据"><a href="#1-创建内部表并载入数据" class="headerlink" title="1 创建内部表并载入数据"></a>1 创建内部表并载入数据</h3><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">hadoop<span class="meta">@hadoopmaster:~$</span> beeline -u jdbc:hive2://hadoopmaster:10000/</span><br><span class="line"></span><br><span class="line">Beeline version 2.1.0 by Apache Hive</span><br><span class="line">0: jdbc:hive2://hadoopmaster:10000/&gt; show databases;</span><br><span class="line">OK</span><br><span class="line">+----------------+--+</span><br><span class="line">|<span class="string"> database_name  </span>|</span><br><span class="line">+----------------+--+</span><br><span class="line">|<span class="string"> default        </span>|</span><br><span class="line">|<span class="string"> fincials       </span>|</span><br><span class="line">+----------------+--+</span><br><span class="line">2 rows selected (1.038 seconds)</span><br><span class="line">0: jdbc:hive2://hadoopmaster:10000/&gt; use default;</span><br><span class="line">OK</span><br><span class="line">No rows affected (0.034 seconds)</span><br><span class="line">0: jdbc:hive2://hadoopmaster:10000/&gt; create table u_data (userid INT, movieid INT, rating INT, unixtime STRING) row format delimited fields terminated by '\t' lines terminated by '\n';</span><br><span class="line">OK</span><br><span class="line">No rows affected (0.242 seconds)</span><br><span class="line">0: jdbc:hive2://hadoopmaster:10000/&gt; LOAD DATA LOCAL INPATH '/home/hadoop/u.data' OVERWRITE INTO TABLE u_data;</span><br><span class="line">Loading data to table default.u_data</span><br><span class="line">OK</span><br><span class="line">No rows affected (0.351 seconds)</span><br><span class="line">0: jdbc:hive2://hadoopmaster:10000/&gt; select <span class="symbol">*</span> from u_data;</span><br><span class="line">OK</span><br><span class="line">+----------------+-----------------+----------------+------------------+--+</span><br><span class="line">|<span class="string"> u_data.userid  </span>|<span class="string"> u_data.movieid  </span>|<span class="string"> u_data.rating  </span>|<span class="string"> u_data.unixtime  </span>|</span><br><span class="line">+----------------+-----------------+----------------+------------------+--+</span><br><span class="line">|<span class="string"> 196            </span>|<span class="string"> 242             </span>|<span class="string"> 3              </span>|<span class="string"> 881250949        </span>|</span><br><span class="line">|<span class="string"> 186            </span>|<span class="string"> 302             </span>|<span class="string"> 3              </span>|<span class="string"> 891717742        </span>|</span><br><span class="line">|<span class="string"> 22             </span>|<span class="string"> 377             </span>|<span class="string"> 1              </span>|<span class="string"> 878887116        </span>|</span><br><span class="line">|<span class="string"> 244            </span>|<span class="string"> 51              </span>|<span class="string"> 2              </span>|<span class="string"> 880606923        </span>|</span><br><span class="line">|<span class="string"> 166            </span>|<span class="string"> 346             </span>|<span class="string"> 1              </span>|<span class="string"> 886397596        </span>|</span><br><span class="line">|<span class="string"> 298            </span>|<span class="string"> 474             </span>|<span class="string"> 4              </span>|<span class="string"> 884182806        </span>|</span><br><span class="line">|<span class="string"> 115            </span>|<span class="string"> 265             </span>|<span class="string"> 2              </span>|<span class="string"> 881171488        </span>|</span><br><span class="line">|<span class="string"> 253            </span>|<span class="string"> 465             </span>|<span class="string"> 5              </span>|<span class="string"> 891628467        </span>|</span><br><span class="line">|<span class="string"> 305            </span>|<span class="string"> 451             </span>|<span class="string"> 3              </span>|<span class="string"> 886324817        </span>|</span><br><span class="line">|<span class="string"> 6              </span>|<span class="string"> 86              </span>|<span class="string"> 3              </span>|<span class="string"> 883603013        </span>|</span><br><span class="line">|<span class="string"> 62             </span>|<span class="string"> 257             </span>|<span class="string"> 2              </span>|<span class="string"> 879372434        </span>|</span><br><span class="line">|<span class="string"> 286            </span>|<span class="string"> 1014            </span>|<span class="string"> 5              </span>|<span class="string"> 879781125        </span>|</span><br></pre></td></tr></table></figure>
<h3 id="2-查看占用的HDFS空间"><a href="#2-查看占用的HDFS空间" class="headerlink" title="2 查看占用的HDFS空间"></a>2 查看占用的HDFS空间</h3><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop<span class="meta">@hadoopmaster</span>:~$ hdfs dfs -ls <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data</span><br><span class="line">Found <span class="number">1</span> items</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">19</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u.data</span><br></pre></td></tr></table></figure>
<h3 id="3-写脚本反复导入100次"><a href="#3-写脚本反复导入100次" class="headerlink" title="3 写脚本反复导入100次"></a>3 写脚本反复导入100次</h3><p><strong>先查看以前有多少行</strong></p>
<figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="comment">//hadoopmaster:10000/&gt; select count(*) from u_data;</span></span><br><span class="line">WARNING: Hive-<span class="keyword">on</span>-MR <span class="keyword">is</span> <span class="keyword">deprecated</span> <span class="keyword">in</span> Hive <span class="number">2</span> <span class="keyword">and</span> may <span class="keyword">not</span> be available <span class="keyword">in</span> the <span class="keyword">future</span> versions. Consider <span class="keyword">using</span> a different execution engine (i.e. tez, spark) <span class="keyword">or</span> <span class="keyword">using</span> Hive <span class="number">1</span>.X releases.</span><br><span class="line">Query ID = hadoop_20160722102853_77aa1bc6-<span class="number">79</span>c2-<span class="number">4916</span>-<span class="number">9</span>b07-a763d112ef41</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined at compile time: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Starting Job = job_1468978056881_0003, Tracking URL = http:<span class="comment">//hadoopmaster:8088/proxy/application_1468978056881_0003/</span></span><br><span class="line">Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1468978056881_0003</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage-<span class="number">1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">10</span>:<span class="number">28</span>:<span class="number">58</span>,<span class="number">786</span> Stage-<span class="number">1</span> map = <span class="number">0</span>%,  reduce = <span class="number">0</span>%</span><br><span class="line"><span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">10</span>:<span class="number">29</span>:<span class="number">03</span>,<span class="number">890</span> Stage-<span class="number">1</span> map = <span class="number">100</span>%,  reduce = <span class="number">0</span>%, Cumulative CPU <span class="number">0.89</span> sec</span><br><span class="line"><span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">10</span>:<span class="number">29</span>:<span class="number">10</span>,<span class="number">005</span> Stage-<span class="number">1</span> map = <span class="number">100</span>%,  reduce = <span class="number">100</span>%, Cumulative CPU <span class="number">1.71</span> sec</span><br><span class="line">MapReduce Total cumulative CPU time: <span class="number">1</span> seconds <span class="number">710</span> msec</span><br><span class="line">Ended Job = job_1468978056881_0003</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-<span class="number">1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">1.71</span> sec   HDFS <span class="keyword">Read</span>: <span class="number">1987050</span> HDFS <span class="keyword">Write</span>: <span class="number">106</span> SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: <span class="number">1</span> seconds <span class="number">710</span> msec</span><br><span class="line">OK</span><br><span class="line">WARNING: Hive-<span class="keyword">on</span>-MR <span class="keyword">is</span> <span class="keyword">deprecated</span> <span class="keyword">in</span> Hive <span class="number">2</span> <span class="keyword">and</span> may <span class="keyword">not</span> be available <span class="keyword">in</span> the <span class="keyword">future</span> versions. Consider <span class="keyword">using</span> a different execution engine (i.e. tez, spark) <span class="keyword">or</span> <span class="keyword">using</span> Hive <span class="number">1</span>.X releases.</span><br><span class="line">+---------+--+</span><br><span class="line">|   c0    |</span><br><span class="line">+---------+--+</span><br><span class="line">| <span class="number">100000</span>  |</span><br><span class="line">+---------+--+</span><br><span class="line"><span class="number">1</span> row selected (<span class="number">17.757</span> seconds)</span><br><span class="line"></span><br><span class="line">hive用Mapreduce引擎计算真心在速度上不行,<span class="number">10</span>W用了<span class="number">17</span>秒,比关系型数据库差不少,还是要用Spark呀</span><br></pre></td></tr></table></figure>
<p><strong>再我们需要了解如何用hive中的一次命令,我们可以这样用.</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop@hadoopmaster:~$ hive -e "<span class="keyword">LOAD</span> <span class="keyword">DATA</span> <span class="keyword">LOCAL</span> INPATH <span class="string">'/home/hadoop/u.data'</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> u_data;"</span><br><span class="line"></span><br><span class="line">Loading data to table default.u_data</span><br><span class="line">OK</span><br><span class="line">Time taken: 1.239 seconds</span><br></pre></td></tr></table></figure>
<p><strong>最后写脚本</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">for</span> (( c=1; c&lt;=10; c++ ))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">         <span class="built_in">echo</span> <span class="string">"正在写入第 <span class="variable">$c</span> 次数据..."</span></span><br><span class="line">         hive -e <span class="string">"LOAD DATA LOCAL INPATH '/home/hadoop/u.data' INTO TABLE u_data;"</span></span><br><span class="line">         <span class="built_in">wait</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p><strong>插入完,检查查询成本</strong></p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: <span class="string">jdbc:</span><span class="string">hive2:</span><span class="comment">//hadoopmaster:10000/&gt; select count(*) from u_data;</span></span><br><span class="line"><span class="string">WARNING:</span> Hive-on-MR is deprecated <span class="keyword">in</span> Hive <span class="number">2</span> and may not be available <span class="keyword">in</span> the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive <span class="number">1.</span>X releases.</span><br><span class="line">Query ID = hadoop_20160722104633_18c3467d<span class="number">-9263</span><span class="number">-4785</span><span class="number">-8714</span><span class="number">-1570</span>fc3bb9ae</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">1</span></span><br><span class="line">Number of reduce tasks determined at compile <span class="string">time:</span> <span class="number">1</span></span><br><span class="line">In order to change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  set hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line">In order to limit the maximum number of <span class="string">reducers:</span></span><br><span class="line">  set hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line">In order to set a constant number of <span class="string">reducers:</span></span><br><span class="line">  set mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Starting Job = job_1468978056881_0009, Tracking URL = <span class="string">http:</span><span class="comment">//hadoopmaster:8088/proxy/application_1468978056881_0009/</span></span><br><span class="line">Kill Command = <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>bin/hadoop job  -kill job_1468978056881_0009</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number of <span class="string">mappers:</span> <span class="number">1</span>; number of <span class="string">reducers:</span> <span class="number">1</span></span><br><span class="line"><span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">46</span>:<span class="number">39</span>,<span class="number">037</span> Stage<span class="number">-1</span> map = <span class="number">0</span>%,  reduce = <span class="number">0</span>%</span><br><span class="line"><span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">46</span>:<span class="number">46</span>,<span class="number">190</span> Stage<span class="number">-1</span> map = <span class="number">100</span>%,  reduce = <span class="number">0</span>%, Cumulative CPU <span class="number">1.82</span> sec</span><br><span class="line"><span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">46</span>:<span class="number">52</span>,<span class="number">310</span> Stage<span class="number">-1</span> map = <span class="number">100</span>%,  reduce = <span class="number">100</span>%, Cumulative CPU <span class="number">2.67</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="string">time:</span> <span class="number">2</span> seconds <span class="number">670</span> msec</span><br><span class="line">Ended Job = job_1468978056881_0009</span><br><span class="line">MapReduce Jobs <span class="string">Launched:</span> </span><br><span class="line">Stage-Stage<span class="number">-1</span>: <span class="string">Map:</span> <span class="number">1</span>  <span class="string">Reduce:</span> <span class="number">1</span>   Cumulative <span class="string">CPU:</span> <span class="number">2.67</span> sec   HDFS <span class="string">Read:</span> <span class="number">77198770</span> HDFS <span class="string">Write:</span> <span class="number">107</span> SUCCESS</span><br><span class="line">Total MapReduce CPU Time <span class="string">Spent:</span> <span class="number">2</span> seconds <span class="number">670</span> msec</span><br><span class="line">OK</span><br><span class="line"><span class="string">WARNING:</span> Hive-on-MR is deprecated <span class="keyword">in</span> Hive <span class="number">2</span> and may not be available <span class="keyword">in</span> the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive <span class="number">1.</span>X releases.</span><br><span class="line">+----------+--+</span><br><span class="line">|    c0    |</span><br><span class="line">+----------+--+</span><br><span class="line">| <span class="number">3900000</span>  |</span><br><span class="line">+----------+--+</span><br><span class="line"><span class="number">1</span> row selected (<span class="number">20.173</span> seconds)</span><br><span class="line"></span><br><span class="line">用了<span class="number">20</span>秒,看起来Mapreduce的启动成本确实有点高了</span><br><span class="line"></span><br><span class="line">hadoop<span class="meta">@hadoopmaster</span>:~$ hdfs dfs -ls <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data</span><br><span class="line">Found <span class="number">39</span> items</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">37</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">38</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_1.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">40</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_10.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">40</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_11.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">41</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_12.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">42</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_13.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">42</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_14.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">42</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_15.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">42</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_16.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">43</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_17.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">43</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_18.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">43</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_19.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">39</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_2.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">43</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_20.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">43</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_21.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">43</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_22.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">43</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_23.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">44</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_24.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">44</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_25.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">44</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_26.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">44</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_27.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">44</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_28.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">44</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_29.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">39</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_3.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">45</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_30.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">45</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_31.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">45</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_32.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">45</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_33.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">45</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_34.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">45</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_35.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">45</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_36.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">46</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_37.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">46</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_38.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">39</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_4.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">39</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_5.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">39</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_6.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">39</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_7.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">39</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_8.data</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1979173</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">10</span>:<span class="number">40</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data/u_copy_9.data</span><br></pre></td></tr></table></figure>
<h2 id="三-外部表"><a href="#三-外部表" class="headerlink" title="三 外部表"></a>三 外部表</h2><h3 id="1-创建外部表并载入数据"><a href="#1-创建外部表并载入数据" class="headerlink" title="1 创建外部表并载入数据"></a>1 创建外部表并载入数据</h3><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hadoopmaster:10000/&gt; create external table  u<span class="emphasis">_data_</span>external<span class="emphasis">_table  (userid INT, movieid INT, rating INT, unixtime STRING) row format delimited fields terminated by '\t' lines terminated by '\n';</span></span><br><span class="line"><span class="emphasis">OK</span></span><br><span class="line"><span class="emphasis">No rows affected (0.047 seconds)</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">0: jdbc:hive2://hadoopmaster:10000/&gt; show tables;</span></span><br><span class="line"><span class="emphasis">OK</span></span><br><span class="line"><span class="emphasis">+------------------------+--+</span></span><br><span class="line"><span class="emphasis">|        tab_</span>name        |</span><br><span class="line"><span class="code">+------------------------+</span>--+</span><br><span class="line">| employees              |</span><br><span class="line">| t<span class="emphasis">_hive                 |</span></span><br><span class="line"><span class="emphasis">| t_</span>hive2                |</span><br><span class="line">| u<span class="emphasis">_data                 |</span></span><br><span class="line"><span class="emphasis">| u_</span>data<span class="emphasis">_external_</span>table  |</span><br><span class="line"><span class="code">+------------------------+</span>--+</span><br><span class="line">5 rows selected (0.036 seconds)</span><br></pre></td></tr></table></figure>
<h3 id="2-导入数据"><a href="#2-导入数据" class="headerlink" title="2 导入数据"></a>2 导入数据</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive -e "<span class="keyword">LOAD</span> <span class="keyword">DATA</span> <span class="keyword">LOCAL</span> INPATH <span class="string">'/home/hadoop/u.data'</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> u_data;"</span><br></pre></td></tr></table></figure>
<h3 id="3-内部表与外部表区别"><a href="#3-内部表与外部表区别" class="headerlink" title="3 内部表与外部表区别"></a>3 内部表与外部表区别</h3><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">我用drop table 命令删除刚才创建的二张表,一个内表一个外表之后结果是.</span><br><span class="line"></span><br><span class="line">hadoop<span class="meta">@hadoopmaster</span>:~$ hdfs dfs -ls <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span></span><br><span class="line">Found <span class="number">5</span> items</span><br><span class="line">drwxrwxr-x   - hadoop supergroup          <span class="number">0</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-20</span> <span class="number">17</span>:<span class="number">25</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>employees</span><br><span class="line">drwxrwxr-x   - hadoop supergroup          <span class="number">0</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-21</span> <span class="number">15</span>:<span class="number">52</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>fincials.db</span><br><span class="line">drwxrwxr-x   - hadoop supergroup          <span class="number">0</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-20</span> <span class="number">09</span>:<span class="number">50</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>t_hive</span><br><span class="line">drwxrwxr-x   - hadoop supergroup          <span class="number">0</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-20</span> <span class="number">09</span>:<span class="number">54</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>t_hive2</span><br><span class="line">drwxrwxr-x   - hadoop supergroup          <span class="number">0</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">11</span>:<span class="number">04</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data_external_table</span><br><span class="line"></span><br><span class="line">内表的数据完全删除,而外表还有</span><br></pre></td></tr></table></figure>
<p>最后归纳一下Hive中表与外部表的区别：</p>
<ul>
<li>在导入数据到外部表，数据并没有移动到自己的数据仓库目录下，也就是说外部表中的数据并不是由它自己来管理的！而表则不一样；</li>
<li>在删除表的时候，Hive将会把属于表的元数据和数据全部删掉；而删除外部表的时候，Hive仅仅删除外部表的元数据，数据是不会删除的！<br>那么，应该如何选择使用哪种表呢？在大多数情况没有太多的区别，因此选择只是个人喜好的问题。但是作为一个经验，如果所有处理都需要由Hive完成，那么你应该创建表，否则使用外部表！</li>
</ul>
<h2 id="四-分区表"><a href="#四-分区表" class="headerlink" title="四 分区表"></a>四 分区表</h2><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: <span class="string">jdbc:</span><span class="string">hive2:</span><span class="comment">//hadoopmaster:10000/&gt; create table  u_data_partitioned_table  (userid INT, movieid INT, rating INT, unixtime STRING) partitioned by(day int) row format delimited fields terminated by '\t' lines terminated by '\n';</span></span><br><span class="line">OK</span><br><span class="line">No rows affected (<span class="number">0.256</span> seconds)</span><br><span class="line"><span class="number">0</span>: <span class="string">jdbc:</span><span class="string">hive2:</span><span class="comment">//hadoopmaster:10000/&gt; </span></span><br><span class="line"></span><br><span class="line"><span class="number">0</span>: <span class="string">jdbc:</span><span class="string">hive2:</span><span class="comment">//hadoopmaster:10000/&gt; LOAD DATA LOCAL INPATH '/home/hadoop/u.data' INTO TABLE u_data_partitioned_table partition(day=20160101);</span></span><br><span class="line">Loading data to table <span class="keyword">default</span>.u_data_partitioned_table partition (day=<span class="number">20160101</span>)</span><br><span class="line">OK</span><br><span class="line">No rows affected (<span class="number">0.424</span> seconds)</span><br><span class="line"><span class="number">0</span>: <span class="string">jdbc:</span><span class="string">hive2:</span><span class="comment">//hadoopmaster:10000/&gt; </span></span><br><span class="line"></span><br><span class="line"><span class="number">100</span>,<span class="number">000</span> rows selected (<span class="number">4.653</span> seconds)</span><br><span class="line"><span class="number">0</span>: <span class="string">jdbc:</span><span class="string">hive2:</span><span class="comment">//hadoopmaster:10000/&gt; LOAD DATA LOCAL INPATH '/home/hadoop/u.data' INTO TABLE u_data_partitioned_table partition(day=20160101);</span></span><br><span class="line">Loading data to table <span class="keyword">default</span>.u_data_partitioned_table partition (day=<span class="number">20160101</span>)</span><br><span class="line">OK</span><br><span class="line">No rows affected (<span class="number">0.424</span> seconds)</span><br><span class="line"><span class="number">0</span>: <span class="string">jdbc:</span><span class="string">hive2:</span><span class="comment">//hadoopmaster:10000/&gt; LOAD DATA LOCAL INPATH '/home/hadoop/u.data' INTO TABLE u_data_partitioned_table partition(day=20160102);</span></span><br><span class="line">Loading data to table <span class="keyword">default</span>.u_data_partitioned_table partition (day=<span class="number">20160102</span>)</span><br><span class="line">OK</span><br><span class="line">No rows affected (<span class="number">0.499</span> seconds)</span><br><span class="line"><span class="number">0</span>: <span class="string">jdbc:</span><span class="string">hive2:</span><span class="comment">//hadoopmaster:10000/&gt; </span></span><br><span class="line"></span><br><span class="line">hadoop<span class="meta">@hadoopmaster</span>:~$ hdfs dfs -ls <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data_partitioned_table</span><br><span class="line">Found <span class="number">2</span> items</span><br><span class="line">drwxrwxr-x   - hadoop supergroup          <span class="number">0</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">13</span>:<span class="number">51</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data_partitioned_table/day=<span class="number">20160101</span></span><br><span class="line">drwxrwxr-x   - hadoop supergroup          <span class="number">0</span> <span class="number">2016</span><span class="number">-07</span><span class="number">-22</span> <span class="number">13</span>:<span class="number">51</span> <span class="regexp">/user/</span>hive<span class="regexp">/warehouse/</span>u_data_partitioned_table/day=<span class="number">20160102</span></span><br></pre></td></tr></table></figure>
<h2 id="五-分桶表"><a href="#五-分桶表" class="headerlink" title="五 分桶表"></a>五 分桶表</h2><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="comment">//hadoopmaster:10000/&gt; CREATE TABLE bucketed_data_user (userid INT, movieid INT, rating INT, unixtime STRING) CLUSTERED BY (userid) INTO 4 BUCKETS row format delimited fields terminated by '\t' lines terminated by '\n';</span></span><br><span class="line">OK</span><br><span class="line">No rows affected (<span class="number">0.045</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="comment">//hadoopmaster:10000/&gt; </span></span><br><span class="line"></span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="comment">//hadoopmaster:10000/&gt; insert overwrite table bucketed_data_user select userid,movieid,rating,unixtime from u_data_partitioned_table;</span></span><br><span class="line">WARNING: Hive-<span class="keyword">on</span>-MR <span class="keyword">is</span> <span class="keyword">deprecated</span> <span class="keyword">in</span> Hive <span class="number">2</span> <span class="keyword">and</span> may <span class="keyword">not</span> be available <span class="keyword">in</span> the <span class="keyword">future</span> versions. Consider <span class="keyword">using</span> a different execution engine (i.e. tez, spark) <span class="keyword">or</span> <span class="keyword">using</span> Hive <span class="number">1</span>.X releases.</span><br><span class="line">Query ID = hadoop_20160722140142_c272bc07-b74d-<span class="number">4</span>b5b-<span class="number">9689</span>-<span class="number">0</span>bec2ce71780</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined at compile time: <span class="number">4</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Starting Job = job_1468978056881_0010, Tracking URL = http:<span class="comment">//hadoopmaster:8088/proxy/application_1468978056881_0010/</span></span><br><span class="line">Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1468978056881_0010</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage-<span class="number">1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">4</span></span><br><span class="line"><span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">01</span>:<span class="number">48</span>,<span class="number">774</span> Stage-<span class="number">1</span> map = <span class="number">0</span>%,  reduce = <span class="number">0</span>%</span><br><span class="line"><span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">01</span>:<span class="number">55</span>,<span class="number">978</span> Stage-<span class="number">1</span> map = <span class="number">100</span>%,  reduce = <span class="number">0</span>%, Cumulative CPU <span class="number">1.89</span> sec</span><br><span class="line"><span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">02</span>:<span class="number">06</span>,<span class="number">236</span> Stage-<span class="number">1</span> map = <span class="number">100</span>%,  reduce = <span class="number">50</span>%, Cumulative CPU <span class="number">5.66</span> sec</span><br><span class="line"><span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">02</span>:<span class="number">07</span>,<span class="number">272</span> Stage-<span class="number">1</span> map = <span class="number">100</span>%,  reduce = <span class="number">100</span>%, Cumulative CPU <span class="number">9.43</span> sec</span><br><span class="line">MapReduce Total cumulative CPU time: <span class="number">9</span> seconds <span class="number">430</span> msec</span><br><span class="line">Ended Job = job_1468978056881_0010</span><br><span class="line">Loading data <span class="keyword">to</span> table <span class="keyword">default</span>.bucketed_data_user</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-<span class="number">1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">4</span>   Cumulative CPU: <span class="number">9.43</span> sec   HDFS <span class="keyword">Read</span>: <span class="number">5959693</span> HDFS <span class="keyword">Write</span>: <span class="number">5937879</span> SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: <span class="number">9</span> seconds <span class="number">430</span> msec</span><br><span class="line">OK</span><br><span class="line">WARNING: Hive-<span class="keyword">on</span>-MR <span class="keyword">is</span> <span class="keyword">deprecated</span> <span class="keyword">in</span> Hive <span class="number">2</span> <span class="keyword">and</span> may <span class="keyword">not</span> be available <span class="keyword">in</span> the <span class="keyword">future</span> versions. Consider <span class="keyword">using</span> a different execution engine (i.e. tez, spark) <span class="keyword">or</span> <span class="keyword">using</span> Hive <span class="number">1</span>.X releases.</span><br><span class="line">No rows affected (<span class="number">26.251</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="comment">//hadoopmaster:10000/&gt; </span></span><br><span class="line"></span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="comment">//hadoopmaster:10000/&gt; select count(*) from bucketed_data_user ;</span></span><br><span class="line">WARNING: Hive-<span class="keyword">on</span>-MR <span class="keyword">is</span> <span class="keyword">deprecated</span> <span class="keyword">in</span> Hive <span class="number">2</span> <span class="keyword">and</span> may <span class="keyword">not</span> be available <span class="keyword">in</span> the <span class="keyword">future</span> versions. Consider <span class="keyword">using</span> a different execution engine (i.e. tez, spark) <span class="keyword">or</span> <span class="keyword">using</span> Hive <span class="number">1</span>.X releases.</span><br><span class="line">Query ID = hadoop_20160722141056_eaf582be-<span class="number">4107</span>-<span class="number">403</span>a-bacd-<span class="number">0</span>a18f567f576</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">1</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined at compile time: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max=&lt;number&gt;</span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces=&lt;number&gt;</span><br><span class="line">Starting Job = job_1468978056881_0012, Tracking URL = http:<span class="comment">//hadoopmaster:8088/proxy/application_1468978056881_0012/</span></span><br><span class="line">Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1468978056881_0012</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage-<span class="number">1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">04</span>,<span class="number">156</span> Stage-<span class="number">1</span> map = <span class="number">0</span>%,  reduce = <span class="number">0</span>%</span><br><span class="line"><span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">09</span>,<span class="number">331</span> Stage-<span class="number">1</span> map = <span class="number">100</span>%,  reduce = <span class="number">0</span>%, Cumulative CPU <span class="number">0.94</span> sec</span><br><span class="line"><span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">15</span>,<span class="number">488</span> Stage-<span class="number">1</span> map = <span class="number">100</span>%,  reduce = <span class="number">100</span>%, Cumulative CPU <span class="number">1.78</span> sec</span><br><span class="line">MapReduce Total cumulative CPU time: <span class="number">1</span> seconds <span class="number">780</span> msec</span><br><span class="line">Ended Job = job_1468978056881_0012</span><br><span class="line">MapReduce Jobs Launched: </span><br><span class="line">Stage-Stage-<span class="number">1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">1.78</span> sec   HDFS <span class="keyword">Read</span>: <span class="number">5945855</span> HDFS <span class="keyword">Write</span>: <span class="number">106</span> SUCCESS</span><br><span class="line">Total MapReduce CPU Time Spent: <span class="number">1</span> seconds <span class="number">780</span> msec</span><br><span class="line">OK</span><br><span class="line">WARNING: Hive-<span class="keyword">on</span>-MR <span class="keyword">is</span> <span class="keyword">deprecated</span> <span class="keyword">in</span> Hive <span class="number">2</span> <span class="keyword">and</span> may <span class="keyword">not</span> be available <span class="keyword">in</span> the <span class="keyword">future</span> versions. Consider <span class="keyword">using</span> a different execution engine (i.e. tez, spark) <span class="keyword">or</span> <span class="keyword">using</span> Hive <span class="number">1</span>.X releases.</span><br><span class="line">+---------+--+</span><br><span class="line">|   c0    |</span><br><span class="line">+---------+--+</span><br><span class="line">| <span class="number">300000</span>  |</span><br><span class="line">+---------+--+</span><br><span class="line"><span class="number">1</span> row selected (<span class="number">20.397</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="comment">//hadoopmaster:10000/&gt; </span></span><br><span class="line"></span><br><span class="line">hadoop@hadoopmaster:~$ hdfs dfs -ls /user/hive/warehouse/bucketed_data_user</span><br><span class="line">Found <span class="number">4</span> items</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1400994</span> <span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">02</span> /user/hive/warehouse/bucketed_data_user/<span class="number">000000</span>_0</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1493856</span> <span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">02</span> /user/hive/warehouse/bucketed_data_user/<span class="number">000001</span>_0</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1566738</span> <span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">02</span> /user/hive/warehouse/bucketed_data_user/<span class="number">000002</span>_0</span><br><span class="line">-rwxrwxr-x   <span class="number">2</span> hadoop supergroup    <span class="number">1475931</span> <span class="number">2016</span>-<span class="number">07</span>-<span class="number">22</span> <span class="number">14</span>:<span class="number">02</span> /user/hive/warehouse/bucketed_data_user/<span class="number">000003</span>_0</span><br></pre></td></tr></table></figure>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="/" target="_blank">Ljjyy.com</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/archives/2019/06/100328.html" class="pre-post btn btn-default" title='大数据hadoop之 二十三.Hive的开发'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">大数据hadoop之 二十三.Hive的开发</span>
        </a>
    
    
        <a href="/archives/2019/06/100082.html" class="next-post btn btn-default" title='大数据hadoop之 二十一.Hive优化'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">大数据hadoop之 二十一.Hive优化</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: '5MzTXYXkt03k101j0PmSDN34-gzGzoHsz',
            appKey: 'iwjYgwno6qj3wtDVVSbe8nYQ',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#一-数据源的准备工作"><span class="toc-text">一 数据源的准备工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二-内部表"><span class="toc-text">二 内部表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-创建内部表并载入数据"><span class="toc-text">1 创建内部表并载入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-查看占用的HDFS空间"><span class="toc-text">2 查看占用的HDFS空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-写脚本反复导入100次"><span class="toc-text">3 写脚本反复导入100次</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三-外部表"><span class="toc-text">三 外部表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-创建外部表并载入数据"><span class="toc-text">1 创建外部表并载入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-导入数据"><span class="toc-text">2 导入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-内部表与外部表区别"><span class="toc-text">3 内部表与外部表区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#四-分区表"><span class="toc-text">四 分区表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#五-分桶表"><span class="toc-text">五 分桶表</span></a></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019-2024&emsp;<a href="/" class="copyright-links" target="_blank" rel="nofollow">Ljjyy.com</a>
                </span> |
                <span>
                    <a href="/about/" class="copyright-links" target="_blank" rel="nofollow">关于我们</a>
                </span> |                
                <span>
                    <a href="/sitemap.xml" class="copyright-links" target="_blank" rel="nofollow">网站地图</a>
                </span> |
                <span>
                    <a href="/archives/" class="copyright-links" target="_blank" rel="nofollow">时间轴</a>
                </span>              
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>
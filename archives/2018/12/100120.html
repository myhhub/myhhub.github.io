<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="https://www.ljjyy.com">
    <!--SEO-->

    <meta name="keywords" content="kubernetes,安装,监控,prometheus,operator">


    <meta name="description" content="接上文：kubernetes集群监控之 一.Prometheus 

随着 Prometheus Operator 项目的成功，CoreOS 公司开源了一个比较厉害的工具：Operator Fr...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>kubernetes集群监控之 二.Prometheus Operator | 来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</title>


    <link rel="alternate" href="/atom.xml" title="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
        <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
        <script>LA.init({id: "JgbNOaw1xxsmUUsQ",ck: "JgbNOaw1xxsmUUsQ"})</script>
	</div>






    
    <meta name="baidu-site-verification" content="dTHILoORpx">


    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  >
    <div class="main-header-box">
        <!--a class="header-avatar" href="/" title='Ljjyy.com'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a-->
        <div class="branding">
            
                <h2> 多读书多实践，勤思考善领悟 </h2>
            
    	  </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">

        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="web-logo"  href="/" title='Ljjyy.com'></a>
                    <!--a class="navbar-brand" href="https://www.ljjyy.com">来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</a-->
                </div>
                <div class="collapse navbar-collapse" id="main-menu" style="">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/cloud/"><i class="fa "></i>云计算</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/front/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/back/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/devops/"><i class="fa "></i>运维</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/crack/"><i class="fa "></i>破解</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/penetration/"><i class="fa "></i>渗透</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tool/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/other/"><i class="fa "></i>其他</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="kubernetes集群监控之 二.Prometheus Operator">
            
	            kubernetes集群监控之 二.Prometheus Operator
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/cloud/">云计算</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/kubernetes/">kubernetes</a> <a class="tag-link" href="/tags/operator/">operator</a> <a class="tag-link" href="/tags/prometheus/">prometheus</a> <a class="tag-link" href="/tags/install/">安装</a> <a class="tag-link" href="/tags/monitor/">监控</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2018/12/11</span>
        </span>
        
    
</div>
            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>1589</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <p>接上文：<a href="100111.html">kubernetes集群监控之 一.Prometheus</a> </p>
<hr>
<p>随着 Prometheus Operator 项目的成功，CoreOS 公司开源了一个比较厉害的工具：<a href="https://github.com/operator-framework" target="_blank" rel="noopener">Operator Framework</a>，该工具可以让开发人员更加容易的开发 Operator 应用。</p>
<p>在本篇文章中我们会为大家介绍一个简单示例来演示如何使用 Operator Framework 框架来开发一个 Operator 应用。</p>
<h2 id="Operator"><a href="#Operator" class="headerlink" title="Operator"></a>Operator</h2><p><code>Operator</code>是由<a href="https://coreos.com/" target="_blank" rel="noopener">CoreOS</a>公司开发的，用来扩展 Kubernetes API，特定的应用程序控制器，它用来创建、配置和管理复杂的有状态应用，如数据库、缓存和监控系统。<code>Operator</code>基于 Kubernetes 的资源和控制器概念之上构建，但同时又包含了应用程序特定的一些专业知识，比如创建一个数据库的<code>Operator</code>，则必须对创建的数据库的各种运维方式非常了解，创建<code>Operator</code>的关键是<code>CRD</code>（自定义资源）的设计。</p>
<blockquote>
<p><code>CRD</code>是对 Kubernetes API 的扩展，Kubernetes 中的每个资源都是一个 API 对象的集合，例如我们在YAML文件里定义的那些<code>spec</code>都是对 Kubernetes 中的资源对象的定义，所有的自定义资源可以跟 Kubernetes 中内建的资源一样使用 kubectl 操作。</p>
</blockquote>
<p><code>Operator</code>是将运维人员对软件操作的知识给代码化，同时利用 Kubernetes 强大的抽象来管理大规模的软件应用。目前<code>CoreOS</code>官方提供了几种<code>Operator</code>的实现，其中就包括我们今天的主角：<code>Prometheus Operator</code>，<code>Operator</code>的核心实现就是基于 Kubernetes 的以下两个概念：</p>
<ul>
<li>资源：对象的状态定义</li>
<li>控制器：观测、分析和行动，以调节资源的分布</li>
</ul>
<p>当然我们如果有对应的需求也完全可以自己去实现一个<code>Operator</code>，接下来我们就来给大家详细介绍下<code>Prometheus-Operator</code>的使用方法。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>首先我们先来了解下<code>Prometheus-Operator</code>的架构图：</p>
<div align="center"><img src="https://www.qikqiak.com/k8s-book/docs/images/prometheus-operator.png" alt="promtheus opeator"><br>promtheus opeator</div>

<p>上图是<code>Prometheus-Operator</code>官方提供的架构图，其中<code>Operator</code>是最核心的部分，作为一个控制器，他会去创建<code>Prometheus</code>、<code>ServiceMonitor</code>、<code>AlertManager</code>以及<code>PrometheusRule</code>4个<code>CRD</code>资源对象，然后会一直监控并维持这4个资源对象的状态。</p>
<p>其中创建的<code>prometheus</code>这种资源对象就是作为<code>Prometheus Server</code>存在，而<code>ServiceMonitor</code>就是<code>exporter</code>的各种抽象，<code>exporter</code>前面我们已经学习了，是用来提供专门提供<code>metrics</code>数据接口的工具，<code>Prometheus</code>就是通过<code>ServiceMonitor</code>提供的<code>metrics</code>数据接口去 pull 数据的，当然<code>alertmanager</code>这种资源对象就是对应的<code>AlertManager</code>的抽象，而<code>PrometheusRule</code>是用来被<code>Prometheus</code>实例使用的报警规则文件。</p>
<p>这样我们要在集群中监控什么数据，就变成了直接去操作 Kubernetes 集群的资源对象了，是不是方便很多了。上图中的 Service 和 ServiceMonitor 都是 Kubernetes 的资源，一个 ServiceMonitor 可以通过 labelSelector 的方式去匹配一类 Service，Prometheus 也可以通过 labelSelector 去匹配多个ServiceMonitor。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>我们这里直接通过 Prometheus-Operator 的源码来进行安装，当然也可以用 Helm 来进行一键安装，我们采用源码安装可以去了解更多的实现细节。首页将源码 Clone 下来：</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="keyword">clone</span> <span class="title">https</span>://github.com/coreos/kube-prometheus.git</span><br><span class="line">$ cd manifests</span><br><span class="line">$ ls</span><br><span class="line"><span class="number">00</span>namespace-namespace.yaml                                         <span class="keyword">node</span><span class="title">-exporter-clusterRole</span>.yaml</span><br><span class="line"><span class="number">0</span>prometheus-operator-<span class="number">0</span>alertmanagerCustomResourceDefinition.yaml    <span class="keyword">node</span><span class="title">-exporter-daemonset</span>.yaml</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<blockquote>
<p>最新的版本官方将资源<a href="https://github.com/coreos/prometheus-operator/tree/master/contrib/kube-prometheus" target="_blank" rel="noopener">https://github.com/coreos/prometheus-operator/tree/master/contrib/kube-prometheus</a>迁移到了独立的 git 仓库中：<a href="https://github.com/coreos/kube-prometheus.git" target="_blank" rel="noopener">https://github.com/coreos/kube-prometheus.git</a></p>
</blockquote>
<p>进入到 manifests 目录下面，这个目录下面包含我们所有的资源清单文件，我们需要对其中的文件 prometheus-serviceMonitorKubelet.yaml 进行简单的修改，因为默认情况下，这个 ServiceMonitor 是关联的 kubelet 的10250端口去采集的节点数据，而我们前面说过为了安全，这个 metrics 数据已经迁移到10255这个只读端口上面去了，我们只需要将文件中的<code>https-metrics</code>更改成<code>http-metrics</code>即可，这个在 Prometheus-Operator 对节点端点同步的代码中有相关定义，感兴趣的可以<a href="https://github.com/coreos/prometheus-operator/blob/7a8bc75512e39a984f46b2788b5fa9bf64999571/pkg/prometheus/operator.go#L400" target="_blank" rel="noopener">点此查看完整代码</a>：</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">Subsets:</span> []v1.EndpointSubset&#123;</span><br><span class="line">    &#123;</span><br><span class="line"><span class="symbol">        Ports:</span> []v1.EndpointPort&#123;</span><br><span class="line">            &#123;</span><br><span class="line"><span class="symbol">                Name:</span> <span class="string">"https-metrics"</span>,</span><br><span class="line"><span class="symbol">                Port:</span> <span class="number">10250</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line"><span class="symbol">                Name:</span> <span class="string">"http-metrics"</span>,</span><br><span class="line"><span class="symbol">                Port:</span> <span class="number">10255</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line"><span class="symbol">                Name:</span> <span class="string">"cadvisor"</span>,</span><br><span class="line"><span class="symbol">                Port:</span> <span class="number">4194</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p>修改完成后，直接在该文件夹下面执行创建资源命令即可：</p>
<figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="built_in">apply</span> -f .</span><br></pre></td></tr></table></figure>
<p>部署完成后，会创建一个名为<code>monitoring</code>的 namespace，所以资源对象对将部署在改命名空间下面，此外 Operator 会自动创建4个 CRD 资源对象：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="built_in">get</span> crd |<span class="keyword">grep</span> coreos</span><br><span class="line">alertmanagers.monitoring.coreos.<span class="keyword">com</span>     <span class="number">5</span>d</span><br><span class="line">prometheuses.monitoring.coreos.<span class="keyword">com</span>      <span class="number">5</span>d</span><br><span class="line">prometheusrules.monitoring.coreos.<span class="keyword">com</span>   <span class="number">5</span>d</span><br><span class="line">servicemonitors.monitoring.coreos.<span class="keyword">com</span>   <span class="number">5</span>d</span><br></pre></td></tr></table></figure>
<p>可以在 monitoring 命名空间下面查看所有的 Pod，其中 alertmanager 和 prometheus 是用 StatefulSet 控制器管理的，其中还有一个比较核心的 prometheus-operator 的 Pod，用来控制其他资源对象和监听对象变化的：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n monitoring</span><br><span class="line">NAME                                  READY     STATUS    RESTARTS   AGE</span><br><span class="line">alertmanager-main<span class="number">-0</span>                   <span class="number">2</span>/<span class="number">2</span>       Running   <span class="number">0</span>          <span class="number">21</span>h</span><br><span class="line">alertmanager-main<span class="number">-1</span>                   <span class="number">2</span>/<span class="number">2</span>       Running   <span class="number">0</span>          <span class="number">21</span>h</span><br><span class="line">alertmanager-main<span class="number">-2</span>                   <span class="number">2</span>/<span class="number">2</span>       Running   <span class="number">0</span>          <span class="number">21</span>h</span><br><span class="line">grafana-df9bfd765-f4dvw               <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          <span class="number">22</span>h</span><br><span class="line">kube-<span class="section">state</span>-metrics<span class="number">-77</span>c9658489-ntj66   <span class="number">4</span>/<span class="number">4</span>       Running   <span class="number">0</span>          <span class="number">20</span>h</span><br><span class="line">node-exporter<span class="number">-4</span>sr7f                   <span class="number">2</span>/<span class="number">2</span>       Running   <span class="number">0</span>          <span class="number">21</span>h</span><br><span class="line">node-exporter<span class="number">-9</span>mh2r                   <span class="number">2</span>/<span class="number">2</span>       Running   <span class="number">0</span>          <span class="number">21</span>h</span><br><span class="line">node-exporter-m2gkp                   <span class="number">2</span>/<span class="number">2</span>       Running   <span class="number">0</span>          <span class="number">21</span>h</span><br><span class="line">prometheus-adapter-dc548cc6-r6lhb     <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          <span class="number">22</span>h</span><br><span class="line">prometheus-k8s<span class="number">-0</span>                      <span class="number">3</span>/<span class="number">3</span>       Running   <span class="number">1</span>          <span class="number">21</span>h</span><br><span class="line">prometheus-k8s<span class="number">-1</span>                      <span class="number">3</span>/<span class="number">3</span>       Running   <span class="number">1</span>          <span class="number">21</span>h</span><br><span class="line">prometheus-operator-bdf79ff67<span class="number">-9</span>dc48   <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          <span class="number">21</span>h</span><br></pre></td></tr></table></figure>
<p>查看创建的 Service:</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kubectl get svc -n monitoring</span><br><span class="line">NAME                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">alertmanager-main       ClusterIP   <span class="number">10.110</span><span class="number">.204</span><span class="number">.224</span>   &lt;none&gt;        <span class="number">9093</span>/TCP            <span class="number">23</span>h</span><br><span class="line">alertmanager-operated   ClusterIP   None             &lt;none&gt;        <span class="number">9093</span>/TCP,<span class="number">6783</span>/TCP   <span class="number">23</span>h</span><br><span class="line">grafana                 ClusterIP   <span class="number">10.98</span><span class="number">.191</span><span class="number">.31</span>     &lt;none&gt;        <span class="number">3000</span>/TCP            <span class="number">23</span>h</span><br><span class="line">kube-<span class="section">state</span>-metrics      ClusterIP   None             &lt;none&gt;        <span class="number">8443</span>/TCP,<span class="number">9443</span>/TCP   <span class="number">23</span>h</span><br><span class="line">node-exporter           ClusterIP   None             &lt;none&gt;        <span class="number">9100</span>/TCP            <span class="number">23</span>h</span><br><span class="line">prometheus-adapter      ClusterIP   <span class="number">10.107</span><span class="number">.201</span><span class="number">.172</span>   &lt;none&gt;        <span class="number">443</span>/TCP             <span class="number">23</span>h</span><br><span class="line">prometheus-k8s          ClusterIP   <span class="number">10.107</span><span class="number">.105</span><span class="number">.53</span>    &lt;none&gt;        <span class="number">9090</span>/TCP            <span class="number">23</span>h</span><br><span class="line">prometheus-operated     ClusterIP   None             &lt;none&gt;        <span class="number">9090</span>/TCP            <span class="number">23</span>h</span><br><span class="line">prometheus-operator     ClusterIP   None             &lt;none&gt;        <span class="number">8080</span>/TCP            <span class="number">23</span>h</span><br></pre></td></tr></table></figure>
<p>可以看到上面针对 grafana 和 prometheus 都创建了一个类型为 ClusterIP 的 Service，当然如果我们想要在外网访问这两个服务的话可以通过创建对应的 Ingress 对象或者使用 NodePort 类型的 Service，我们这里为了简单，直接使用 NodePort 类型的服务即可，编辑 grafana 和 prometheus-k8s 这两个 Service，将服务类型更改为 NodePort:</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="builtin-name">edit</span> svc grafana -n monitoring</span><br><span class="line">$ kubectl <span class="builtin-name">edit</span> svc prometheus-k8s -n monitoring</span><br><span class="line">$ kubectl <span class="builtin-name">get</span> svc -n monitoring</span><br><span class="line">NAME                   <span class="built_in"> TYPE </span>       CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">grafana                 NodePort    10.98.191.31     &lt;none&gt;        3000:32333/TCP      23h</span><br><span class="line">prometheus-k8s          NodePort    10.107.105.53    &lt;none&gt;        9090:30166/TCP      23h</span><br><span class="line"><span class="built_in">..</span><span class="built_in">..</span><span class="built_in">..</span></span><br></pre></td></tr></table></figure>
<p>更改完成后，我们就可以通过去访问上面的两个服务了，比如查看 prometheus � targets 页面：</p>
<div align="center"><img src="https://www.qikqiak.com/k8s-book/docs/images/promethues-operator-targets.png" alt="prpromtheus operator targets"><br>promtheus operator targets</div>

<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>我们可以看到大部分的配置都是正常的，只有两三个没有管理到对应的监控目标，比如 kube-controller-manager 和 kube-scheduler 这两个系统组件，这就和 ServiceMonitor 的定义有关系了，我们先来查看下 kube-scheduler 组件对应的 ServiceMonitor 资源的定义：(prometheus-serviceMonitorKubeScheduler.yaml)</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceMonitor</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kube-scheduler</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kube-scheduler</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  endpoints:</span></span><br><span class="line"><span class="attr">  - interval:</span> <span class="number">30</span><span class="string">s</span> <span class="comment"># 每30s获取一次信息</span></span><br><span class="line"><span class="attr">    port:</span> <span class="string">http-metrics</span>  <span class="comment"># 对应service的端口名</span></span><br><span class="line"><span class="attr">  jobLabel:</span> <span class="string">k8s-app</span></span><br><span class="line"><span class="attr">  namespaceSelector:</span> <span class="comment"># 表示去匹配某一命名空间中的service，如果想从所有的namespace中匹配用any: true</span></span><br><span class="line"><span class="attr">    matchNames:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  selector:</span>  <span class="comment"># 匹配的 Service 的labels，如果使用mathLabels，则下面的所有标签都匹配时才会匹配该service，如果使用matchExpressions，则至少匹配一个标签的service都会被选择</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">kube-scheduler</span></span><br></pre></td></tr></table></figure>
<p>上面是一个典型的 ServiceMonitor 资源文件的声明方式，上面我们通过<code>selector.matchLabels</code>在 kube-system 这个命名空间下面匹配具有<code>k8s-app=kube-scheduler</code>这样的 Service，但是我们系统中根本就没有对应的 Service，所以我们需要手动创建一个 Service：（prometheus-kubeSchedulerService.yaml）</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: Service</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">namespace</span>: kube-system</span><br><span class="line">  <span class="attribute">name</span>: kube-scheduler</span><br><span class="line">  <span class="attribute">labels</span>:</span><br><span class="line">    <span class="attribute">k8s-app</span>: kube-scheduler</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">selector</span>:</span><br><span class="line">    <span class="attribute">component</span>: kube-scheduler</span><br><span class="line">  <span class="attribute">ports</span>:</span><br><span class="line">  - <span class="attribute">name</span>: http-metrics</span><br><span class="line">    <span class="attribute">port</span>: <span class="number">10251</span></span><br><span class="line">    <span class="attribute">targetPort</span>: <span class="number">10251</span></span><br><span class="line">    <span class="attribute">protocol</span>: TCP</span><br></pre></td></tr></table></figure>
<blockquote>
<p>10251是<code>kube-scheduler</code>组件 metrics 数据所在的端口，10252是<code>kube-controller-manager</code>组件的监控数据所在端口。</p>
</blockquote>
<p>其中最重要的是上面 labels 和 selector 部分，labels 区域的配置必须和我们上面的 ServiceMonitor 对象中的 selector 保持一致，<code>selector</code>下面配置的是<code>component=kube-scheduler</code>，为什么会是这个 label 标签呢，我们可以去 describe 下 kube-scheduelr 这个 Pod：</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod kube-scheduler-<span class="keyword">master</span> <span class="title">-n</span> kube-system</span><br><span class="line">Name:         kube-scheduler-<span class="literal">master</span></span><br><span class="line">Namespace:    kube-system</span><br><span class="line"><span class="keyword">Node</span><span class="title">:         master</span>/<span class="number">10.151</span>.<span class="number">30.57</span></span><br><span class="line"><span class="literal">Start</span> Time:   Sun, <span class="number">05</span> Aug <span class="number">2018</span> <span class="number">18</span>:<span class="number">13</span>:<span class="number">32</span> +<span class="number">0800</span></span><br><span class="line">Labels:       <span class="attr">component=</span>kube-scheduler</span><br><span class="line">              <span class="attr">tier=</span>control-plane</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>我们可以看到这个 Pod 具有<code>component=kube-scheduler</code>和<code>tier=control-plane</code>这两个标签，而前面这个标签具有更唯一的特性，所以使用前面这个标签较好，这样上面创建的 Service 就可以和我们的 Pod 进行关联了，直接创建即可：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f prometheus-kubeSchedulerService.yaml</span><br><span class="line">$ kubectl <span class="builtin-name">get</span> svc -n kube-system -l <span class="attribute">k8s-app</span>=kube-scheduler</span><br><span class="line">NAME            <span class="built_in"> TYPE </span>       CLUSTER-IP       EXTERNAL-IP   PORT(S)     AGE</span><br><span class="line">kube-scheduler   ClusterIP   10.102.119.231   &lt;none&gt;        10251/TCP   18m</span><br></pre></td></tr></table></figure>
<p>创建完成后，隔一小会儿后去 prometheus 查看 targets 下面 kube-scheduler 的状态：</p>
<div align="center"><img src="https://www.qikqiak.com/k8s-book/docs/images/promethues-operator-kube-scheduler-error.png" alt="promethus kube-scheduler error"><br>promethus kube-scheduler error</div>

<p>我们可以看到现在已经发现了 target，但是抓取数据结果出错了，这个错误是因为我们集群是使用 kubeadm 搭建的，其中 kube-scheduler 默认是绑定在<code>127.0.0.1</code>上面的，而上面我们这个地方是想通过节点的 IP 去访问，所以访问被拒绝了，我们只要把 kube-scheduler 绑定的地址更改成<code>0.0.0.0</code>即可满足要求，由于 kube-scheduler 是以静态 Pod 的形式运行在集群中的，所以我们只需要更改静态 Pod 目录下面对应的 YAML 文件即可：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /etc/kubernetes/manifests/</span><br><span class="line">etcd<span class="selector-class">.yaml</span>  kube-apiserver<span class="selector-class">.yaml</span>  kube-controller-manager<span class="selector-class">.yaml</span>  kube-scheduler.yaml</span><br></pre></td></tr></table></figure>
<p>将 kube-scheduler.yaml 文件中<code>-command</code>的<code>--address</code>地址更改成<code>0.0.0.0</code>：</p>
<figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">containers:</span><br><span class="line">-<span class="ruby"> <span class="symbol">command:</span></span></span><br><span class="line"><span class="ruby">- kube-scheduler</span></span><br><span class="line"><span class="ruby">- --leader-elect=<span class="literal">true</span></span></span><br><span class="line"><span class="ruby">- --kubeconfig=<span class="regexp">/etc/kubernetes</span><span class="regexp">/scheduler.conf</span></span></span><br><span class="line"><span class="ruby">- --address=<span class="number">0</span>.<span class="number">0</span>.<span class="number">0</span>.<span class="number">0</span></span></span><br></pre></td></tr></table></figure>
<p>修改完成后我们将该文件从当前文件夹中移除，隔一会儿再移回该目录，就可以自动更新了，然后再去看 prometheus 中 kube-scheduler 这个 target 是否已经正常了：</p>
<div align="center"><img src="https://www.qikqiak.com/k8s-book/docs/images/promethues-operator-kube-scheduler.png" alt="promethues-operator-kube-scheduler"><br>promethues-operator-kube-scheduler</div>

<p>大家可以按照上面的方法尝试去修复下 kube-controller-manager 组件的监控。</p>
<p>上面的监控数据配置完成后，现在我们可以去查看下 grafana 下面的 dashboard，同样使用上面的 NodePort 访问即可，第一次登录使用 admin:admin 登录即可，进入首页后，可以发现已经和我们的 Prometheus 数据源关联上了，正常来说可以看到一些监控图表了：</p>
<div align="center"><img src="https://www.qikqiak.com/k8s-book/docs/images/promethues-operator-grafana.png" alt="promethues-operator-grafana"><br>promethues-operator-grafana</div>

<h2 id="自定义监控项"><a href="#自定义监控项" class="headerlink" title="自定义监控项"></a>自定义监控项</h2><p>除了 Kubernetes 集群中的一些资源对象、节点以及组件需要监控，有的时候我们可能还需要根据实际的业务需求去添加自定义的监控项，添加一个自定义监控的步骤也是非常简单的。</p>
<ul>
<li>第一步建立一个 ServiceMonitor 对象，用于 Prometheus 添加监控项</li>
<li>第二步为 ServiceMonitor 对象关联 metrics 数据接口的一个 Service 对象</li>
<li>第三步确保 Service 对象可以正确获取到 metrics 数据</li>
</ul>
<p>接下来我们就来为大家演示如何添加 etcd 集群的监控。</p>
<p>无论是 Kubernetes 集群外的还是使用 Kubeadm 安装在集群内部的 etcd 集群，我们这里都将其视作集群外的独立集群，因为对于二者的使用方法没什么特殊之处。</p>
<h3 id="etcd-证书"><a href="#etcd-证书" class="headerlink" title="etcd 证书"></a>etcd 证书</h3><p>对于 etcd 集群一般情况下，为了安全都会开启 https 证书认证的方式，所以要想让 Prometheus 访问到 etcd 集群的监控数据，就需要提供相应的证书校验。</p>
<p>由于我们这里演示环境使用的是 Kubeadm 搭建的集群，我们可以使用 kubectl 工具去获取 etcd 启动的时候使用的证书路径：</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n kube-system</span><br><span class="line">NAME                                          READY     STATUS    RESTARTS   AGE</span><br><span class="line">etcd-master                                   <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          <span class="number">2</span>h</span><br><span class="line">$ kubectl get pod etcd-master -n kube-system -o yaml</span><br><span class="line">......</span><br><span class="line"><span class="symbol">spec:</span></span><br><span class="line"><span class="symbol">  containers:</span></span><br><span class="line">  - command:</span><br><span class="line">    - etcd</span><br><span class="line">    - --peer-cert-file=<span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd/peer.crt</span><br><span class="line">    - --listen-client-urls=https:<span class="comment">//127.0.0.1:2379</span></span><br><span class="line">    - --advertise-client-urls=https:<span class="comment">//127.0.0.1:2379</span></span><br><span class="line">    - --client-cert-auth=true</span><br><span class="line">    - --peer-client-cert-auth=true</span><br><span class="line">    - --data-dir=<span class="meta-keyword">/var/</span>lib/etcd</span><br><span class="line">    - --cert-file=<span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd/server.crt</span><br><span class="line">    - --key-file=<span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd/server.key</span><br><span class="line">    - --trusted-ca-file=<span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd/ca.crt</span><br><span class="line">    - --peer-key-file=<span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd/peer.key</span><br><span class="line">    - --peer-trusted-ca-file=<span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd/ca.crt</span><br><span class="line"><span class="symbol">    image:</span> k8s.gcr.io/etcd-amd64:<span class="number">3.1</span><span class="number">.12</span></span><br><span class="line"><span class="symbol">    imagePullPolicy:</span> IfNotPresent</span><br><span class="line"><span class="symbol">    livenessProbe:</span></span><br><span class="line"><span class="symbol">      exec:</span></span><br><span class="line"><span class="symbol">        command:</span></span><br><span class="line">        - <span class="meta-keyword">/bin/</span>sh</span><br><span class="line">        - -ec</span><br><span class="line">        - ETCDCTL_API=<span class="number">3</span> etcdctl --endpoints=<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">2379</span> --cacert=<span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd/ca.crt</span><br><span class="line">          --cert=<span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd/healthcheck-client.crt --key=<span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd/healthcheck-client.key</span><br><span class="line">          get foo</span><br><span class="line"><span class="symbol">      failureThreshold:</span> <span class="number">8</span></span><br><span class="line"><span class="symbol">      initialDelaySeconds:</span> <span class="number">15</span></span><br><span class="line"><span class="symbol">      periodSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="symbol">      successThreshold:</span> <span class="number">1</span></span><br><span class="line"><span class="symbol">      timeoutSeconds:</span> <span class="number">15</span></span><br><span class="line"><span class="symbol">    name:</span> etcd</span><br><span class="line"><span class="symbol">    resources:</span> &#123;&#125;</span><br><span class="line"><span class="symbol">    terminationMessagePath:</span> <span class="meta-keyword">/dev/</span>termination-log</span><br><span class="line"><span class="symbol">    terminationMessagePolicy:</span> File</span><br><span class="line"><span class="symbol">    volumeMounts:</span></span><br><span class="line">    - mountPath: <span class="meta-keyword">/var/</span>lib/etcd</span><br><span class="line"><span class="symbol">      name:</span> etcd-data</span><br><span class="line">    - mountPath: <span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd</span><br><span class="line"><span class="symbol">      name:</span> etcd-certs</span><br><span class="line">......</span><br><span class="line"><span class="symbol">  tolerations:</span></span><br><span class="line">  - effect: NoExecute</span><br><span class="line"><span class="symbol">    operator:</span> Exists</span><br><span class="line"><span class="symbol">  volumes:</span></span><br><span class="line">  - hostPath:</span><br><span class="line"><span class="symbol">      path:</span> <span class="meta-keyword">/var/</span>lib/etcd</span><br><span class="line"><span class="symbol">      type:</span> DirectoryOrCreate</span><br><span class="line"><span class="symbol">    name:</span> etcd-data</span><br><span class="line">  - hostPath:</span><br><span class="line"><span class="symbol">      path:</span> <span class="meta-keyword">/etc/</span>kubernetes<span class="meta-keyword">/pki/</span>etcd</span><br><span class="line"><span class="symbol">      type:</span> DirectoryOrCreate</span><br><span class="line"><span class="symbol">    name:</span> etcd-certs</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>我们可以看到 etcd 使用的证书都对应在节点的 /etc/kubernetes/pki/etcd 这个路径下面，所以首先我们将需要使用到的证书通过 secret 对象保存到集群中去：(在 etcd 运行的节点)</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n monitoring create<span class="built_in"> secret </span>generic etcd-certs <span class="attribute">--from-file</span>=/etc/kubernetes/pki/etcd/healthcheck-client.crt <span class="attribute">--from-file</span>=/etc/kubernetes/pki/etcd/healthcheck-client.key <span class="attribute">--from-file</span>=/etc/kubernetes/pki/etcd/ca.crt</span><br><span class="line">secret <span class="string">"etcd-certs"</span> created</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果你是独立的二进制方式启动的 etcd 集群，同样将对应的证书保存到集群中的一个 secret 对象中去即可。</p>
</blockquote>
<p>然后将上面创建的 etcd-certs 对象配置到 prometheus 资源对象中，直接更新 prometheus 资源对象即可：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="builtin-name">edit</span> prometheus k8s -n monitoring</span><br></pre></td></tr></table></figure>
<p>添加如下的 secrets 属性：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">nodeSelector:</span></span><br><span class="line">  beta.kubernetes.io/<span class="string">os:</span> linux</span><br><span class="line"><span class="string">replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="string">secrets:</span></span><br><span class="line">- etcd-certs</span><br></pre></td></tr></table></figure>
<p>更新完成后，我们就可以在 Prometheus 的 Pod 中获取到上面创建的 etcd 证书文件了，具体的路径我们可以进入 Pod 中查看：</p>
<figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl exec -<span class="literal">it</span> prometheus-k8s-<span class="number">0</span> /bin/sh -n monitoring</span><br><span class="line">Defaulting container name <span class="keyword">to</span> prometheus.</span><br><span class="line">Use <span class="string">'kubectl describe pod/prometheus-k8s-0 -n monitoring'</span> <span class="keyword">to</span> see all <span class="keyword">of</span> the containers <span class="keyword">in</span> <span class="keyword">this</span> pod.</span><br><span class="line">/ $ ls <span class="regexp">/etc/prometheus/secrets/etcd-certs/</span></span><br><span class="line">ca.crt      healthcheck-client.crt  healthcheck-client.key</span><br></pre></td></tr></table></figure>
<h3 id="创建-ServiceMonitor"><a href="#创建-ServiceMonitor" class="headerlink" title="创建 ServiceMonitor"></a>创建 ServiceMonitor</h3><p>现在 Prometheus 访问 etcd 集群的证书已经准备好了，接下来创建 ServiceMonitor 对象即可（prometheus-serviceMonitorEtcd.yaml）</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">apiVersion:</span> monitoring.coreos.com/v1</span><br><span class="line"><span class="symbol">kind:</span> ServiceMonitor</span><br><span class="line"><span class="symbol">metadata:</span></span><br><span class="line"><span class="symbol">  name:</span> etcd-k8s</span><br><span class="line"><span class="symbol">  namespace:</span> monitoring</span><br><span class="line"><span class="symbol">  labels:</span></span><br><span class="line">    k8s-app: etcd-k8s</span><br><span class="line"><span class="symbol">spec:</span></span><br><span class="line"><span class="symbol">  jobLabel:</span> k8s-app</span><br><span class="line"><span class="symbol">  endpoints:</span></span><br><span class="line">  - port: port</span><br><span class="line"><span class="symbol">    interval:</span> <span class="number">30</span>s</span><br><span class="line"><span class="symbol">    scheme:</span> https</span><br><span class="line"><span class="symbol">    tlsConfig:</span></span><br><span class="line"><span class="symbol">      caFile:</span> <span class="meta-keyword">/etc/</span>prometheus<span class="meta-keyword">/secrets/</span>etcd-certs/ca.crt</span><br><span class="line"><span class="symbol">      certFile:</span> <span class="meta-keyword">/etc/</span>prometheus<span class="meta-keyword">/secrets/</span>etcd-certs/healthcheck-client.crt</span><br><span class="line"><span class="symbol">      keyFile:</span> <span class="meta-keyword">/etc/</span>prometheus<span class="meta-keyword">/secrets/</span>etcd-certs/healthcheck-client.key</span><br><span class="line"><span class="symbol">      insecureSkipVerify:</span> true</span><br><span class="line"><span class="symbol">  selector:</span></span><br><span class="line"><span class="symbol">    matchLabels:</span></span><br><span class="line">      k8s-app: etcd</span><br><span class="line"><span class="symbol">  namespaceSelector:</span></span><br><span class="line"><span class="symbol">    matchNames:</span></span><br><span class="line">    - kube-system</span><br></pre></td></tr></table></figure>
<p>上面我们在 monitoring 命名空间下面创建了名为 etcd-k8s 的 ServiceMonitor 对象，基本属性和前面章节中的一致，匹配 kube-system 这个命名空间下面的具有 k8s-app=etcd 这个 label 标签的 Service，jobLabel 表示用于检索 job 任务名称的标签，和前面不太一样的地方是 endpoints 属性的写法，配置上访问 etcd 的相关证书，endpoints 属性下面可以配置很多抓取的参数，比如 relabel、proxyUrl，tlsConfig 表示用于配置抓取监控数据端点的 tls 认证，由于证书 serverName 和 etcd 中签发的可能不匹配，所以加上了 insecureSkipVerify=true</p>
<div align="center"><img src="/img/posts/mI32WB.jpg" alt="tlsConfig"><br>tlsConfig</div>

<blockquote>
<p>关于 ServiceMonitor 属性的更多用法可以查看文档：<a href="https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md" target="_blank" rel="noopener">https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md</a> 了解更多</p>
</blockquote>
<p>直接创建这个 ServiceMonitor 对象：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f prometheus-serviceMonitorEtcd.yaml</span><br><span class="line">servicemonitor<span class="selector-class">.monitoring</span><span class="selector-class">.coreos</span><span class="selector-class">.com</span> <span class="string">"etcd-k8s"</span> created</span><br></pre></td></tr></table></figure>
<h3 id="创建-Service"><a href="#创建-Service" class="headerlink" title="创建 Service"></a>创建 Service</h3><p>ServiceMonitor 创建完成了，但是现在还没有关联的对应的 Service 对象，所以需要我们去手动创建一个 Service 对象（prometheus-etcdService.yaml）：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-k8s</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">etcd</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">ClusterIP</span></span><br><span class="line"><span class="attr">  clusterIP:</span> <span class="string">None</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">port</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">2379</span></span><br><span class="line"><span class="attr">    protocol:</span> <span class="string">TCP</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Endpoints</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-k8s</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">etcd</span></span><br><span class="line"><span class="attr">subsets:</span></span><br><span class="line"><span class="attr">- addresses:</span></span><br><span class="line"><span class="attr">  - ip:</span> <span class="number">10.151</span><span class="number">.30</span><span class="number">.57</span></span><br><span class="line"><span class="attr">    nodeName:</span> <span class="string">etc-master</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">port</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">2379</span></span><br><span class="line"><span class="attr">    protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>
<p>我们这里创建的 Service 没有采用前面通过 label 标签的形式去匹配 Pod 的做法，因为前面我们说过很多时候我们创建的 etcd 集群是独立于集群之外的，这种情况下面我们就需要自定义一个 Endpoints，要注意 metadata 区域的内容要和 Service 保持一致，Service 的 clusterIP 设置为 None，对改知识点不太熟悉的，可以去查看我们前面关于 Service 部分的讲解。</p>
<p>Endpoints 的 subsets 中填写 etcd 集群的地址即可，我们这里是单节点的，填写一个即可，直接创建该 Service 资源：</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>kubectl create -f prometheus-etcdService.yaml</span><br></pre></td></tr></table></figure>
<p>创建完成后，隔一会儿去 Prometheus 的 Dashboard 中查看 targets，便会有 etcd 的监控项了：</p>
<div align="center"><img src="/img/posts/5BQRte.jpg" alt="prometheus etcd"><br>prometheus etcd</div>

<p>可以看到还是有一个明显的错误，和我们上节课监控 kube-scheduler 的错误比较类似于，因为我们这里的 etcd 的是监听在 127.0.0.1 这个 IP 上面的，所以访问会拒绝：</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--<span class="built_in">listen</span>-client-urls=https:<span class="comment">//127.0.0.1:2379</span></span><br></pre></td></tr></table></figure>
<p>同样我们只需要在 /etc/kubernetes/manifest/ 目录下面（static pod 默认的目录）的 etcd.yaml 文件中将上面的<code>listen-client-urls</code>更改成 0.0.0.0 即可：</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--<span class="built_in">listen</span>-client-urls=https:<span class="comment">//0.0.0.0:2379</span></span><br></pre></td></tr></table></figure>
<p>重启 etcd，生效后，查看 etcd 这个监控任务就正常了：</p>
<div align="center"><img src="/img/posts/EmEn6b.jpg" alt="prometheus etcd"><br>prometheus etcd</div>

<p>数据采集到后，可以在 grafana 中导入编号为<code>3070</code>的 dashboard，获取到 etcd 的监控图表。</p>
<div align="center"><img src="/img/posts/yQgrwt.jpg" alt="grafana etcd dashboard"><br>grafana etcd dashboard</div>

<h3 id="配置-PrometheusRule"><a href="#配置-PrometheusRule" class="headerlink" title="配置 PrometheusRule"></a>配置 PrometheusRule</h3><p>现在我们知道怎么自定义一个 ServiceMonitor 对象了，但是如果需要自定义一个报警规则的话呢？比如现在我们去查看 Prometheus Dashboard 的 Alert 页面下面就已经有一些报警规则了，还有一些是已经触发规则的了：</p>
<div align="center"><img src="/img/posts/DADO6K.jpg" alt="alerts"><br>alerts</div>

<p>但是这些报警信息是哪里来的呢？他们应该用怎样的方式通知我们呢？我们知道之前我们使用自定义的方式可以在 Prometheus 的配置文件之中指定 AlertManager 实例和 报警的 rules 文件，现在我们通过 Operator 部署的呢？我们可以在 Prometheus Dashboard 的 Config 页面下面查看关于 AlertManager 的配置：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">alerting:</span></span><br><span class="line"><span class="attr">  alert_relabel_configs:</span></span><br><span class="line"><span class="attr">  - separator:</span> <span class="string">;</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">prometheus_replica</span></span><br><span class="line"><span class="attr">    replacement:</span> <span class="string">$1</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">labeldrop</span></span><br><span class="line"><span class="attr">  alertmanagers:</span></span><br><span class="line"><span class="attr">  - kubernetes_sd_configs:</span></span><br><span class="line"><span class="attr">    - role:</span> <span class="string">endpoints</span></span><br><span class="line"><span class="attr">      namespaces:</span></span><br><span class="line"><span class="attr">        names:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">    scheme:</span> <span class="string">http</span></span><br><span class="line"><span class="attr">    path_prefix:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">    timeout:</span> <span class="number">10</span><span class="string">s</span></span><br><span class="line"><span class="attr">    relabel_configs:</span></span><br><span class="line"><span class="attr">    - source_labels:</span> <span class="string">[__meta_kubernetes_service_name]</span></span><br><span class="line"><span class="attr">      separator:</span> <span class="string">;</span></span><br><span class="line"><span class="attr">      regex:</span> <span class="string">alertmanager-main</span></span><br><span class="line"><span class="attr">      replacement:</span> <span class="string">$1</span></span><br><span class="line"><span class="attr">      action:</span> <span class="string">keep</span></span><br><span class="line"><span class="attr">    - source_labels:</span> <span class="string">[__meta_kubernetes_endpoint_port_name]</span></span><br><span class="line"><span class="attr">      separator:</span> <span class="string">;</span></span><br><span class="line"><span class="attr">      regex:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">      replacement:</span> <span class="string">$1</span></span><br><span class="line"><span class="attr">      action:</span> <span class="string">keep</span></span><br><span class="line"><span class="attr">rule_files:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">/etc/prometheus/rules/prometheus-k8s-rulefiles-0/*.yaml</span></span><br></pre></td></tr></table></figure>
<p>上面 alertmanagers 实例的配置我们可以看到是通过角色为 endpoints 的 kubernetes 的服务发现机制获取的，匹配的是服务名为 alertmanager-main，端口名未 web 的 Service 服务，我们查看下 alertmanager-main 这个 Service：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="keyword">describe</span> svc alertmanager-<span class="keyword">main</span> -n <span class="keyword">monitoring</span></span><br><span class="line"><span class="keyword">Name</span>:                     alertmanager-<span class="keyword">main</span></span><br><span class="line">Namespace:                <span class="keyword">monitoring</span></span><br><span class="line">Labels:                   alertmanager=<span class="keyword">main</span></span><br><span class="line">Annotations:              kubectl.kubernetes.io/<span class="keyword">last</span>-applied-configuration=&#123;<span class="string">"apiVersion"</span>:<span class="string">"v1"</span>,<span class="string">"kind"</span>:<span class="string">"Service"</span>,<span class="string">"metadata"</span>:&#123;<span class="string">"annotations"</span>:&#123;&#125;,<span class="string">"labels"</span>:&#123;<span class="string">"alertmanager"</span>:<span class="string">"main"</span>&#125;,<span class="string">"name"</span>:<span class="string">"alertmanager-main"</span>,<span class="string">"namespace"</span>:<span class="string">"monitoring"</span>&#125;,...</span><br><span class="line">Selector:                 alertmanager=<span class="keyword">main</span>,app=alertmanager</span><br><span class="line"><span class="keyword">Type</span>:                     NodePort</span><br><span class="line">IP:                       <span class="number">10.104</span><span class="number">.156</span><span class="number">.29</span></span><br><span class="line">Port:                     web  <span class="number">9093</span>/TCP</span><br><span class="line">TargetPort:               web/TCP</span><br><span class="line">NodePort:                 web  <span class="number">31918</span>/TCP</span><br><span class="line">Endpoints:                <span class="number">10.244</span><span class="number">.2</span><span class="number">.34</span>:<span class="number">9093</span>,<span class="number">10.244</span><span class="number">.2</span><span class="number">.37</span>:<span class="number">9093</span>,<span class="number">10.244</span><span class="number">.4</span><span class="number">.109</span>:<span class="number">9093</span></span><br><span class="line"><span class="keyword">Session</span> Affinity:         <span class="keyword">None</span></span><br><span class="line"><span class="keyword">External</span> Traffic <span class="keyword">Policy</span>:  Cluster</span><br><span class="line"><span class="keyword">Events</span>:                   &lt;<span class="keyword">none</span>&gt;</span><br></pre></td></tr></table></figure>
<p>可以看到服务名正是 alertmanager-main，Port 定义的名称也是 web，符合上面的规则，所以 Prometheus 和 AlertManager 组件就正确关联上了。而对应的报警规则文件位于：<code>/etc/prometheus/rules/prometheus-k8s-rulefiles-0/</code>目录下面所有的 YAML 文件。我们可以进入 Prometheus 的 Pod 中验证下该目录下面是否有 YAML 文件：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl exec -it prometheus-k8s-0 /bin/sh -n monitoring</span><br><span class="line">Defaulting container name to prometheus.</span><br><span class="line"><span class="keyword">Use</span> <span class="string">'kubectl describe pod/prometheus-k8s-0 -n monitoring'</span> <span class="keyword">to</span> see <span class="keyword">all</span> <span class="keyword">of</span> the containers <span class="keyword">in</span> this pod.</span><br><span class="line">/prometheus $ ls /etc/prometheus/<span class="keyword">rules</span>/prometheus-k8s-rulefiles<span class="number">-0</span>/</span><br><span class="line"><span class="keyword">monitoring</span>-prometheus-k8s-rules.yaml</span><br><span class="line">/prometheus $ cat /etc/prometheus/<span class="keyword">rules</span>/prometheus-k8s-rulefiles<span class="number">-0</span>/<span class="keyword">monitoring</span>-pr</span><br><span class="line">ometheus-k8s-rules.yaml</span><br><span class="line"><span class="keyword">groups</span>:</span><br><span class="line">- <span class="keyword">name</span>: k8s.rules</span><br><span class="line">  <span class="keyword">rules</span>:</span><br><span class="line">  - expr: |</span><br><span class="line">      <span class="keyword">sum</span>(rate(container_cpu_usage_seconds_total&#123;job=<span class="string">"kubelet"</span>, image!=<span class="string">""</span>, container_name!=<span class="string">""</span>&#125;[<span class="number">5</span>m])) <span class="keyword">by</span> (namespace)</span><br><span class="line">    <span class="built_in">record</span>: namespace:container_cpu_usage_seconds_total:sum_rate</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>这个 YAML 文件实际上就是我们之前创建的一个 PrometheusRule 文件包含的：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">cat</span> <span class="string">prometheus-rules.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PrometheusRule</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    prometheus:</span> <span class="string">k8s</span></span><br><span class="line"><span class="attr">    role:</span> <span class="string">alert-rules</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prometheus-k8s-rules</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  groups:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">k8s.rules</span></span><br><span class="line"><span class="attr">    rules:</span></span><br><span class="line"><span class="attr">    - expr:</span> <span class="string">|</span></span><br><span class="line"><span class="string">        sum(rate(container_cpu_usage_seconds_total&#123;job="kubelet", image!="", container_name!=""&#125;[5m])) by (namespace)</span></span><br><span class="line"><span class="string"></span><span class="attr">      record:</span> <span class="attr">namespace:container_cpu_usage_seconds_total:sum_rate</span></span><br></pre></td></tr></table></figure>
<p>我们这里的 PrometheusRule 的 name 为 prometheus-k8s-rules，namespace 为 monitoring，我们可以猜想到我们创建一个 PrometheusRule 资源对象后，会自动在上面的 prometheus-k8s-rulefiles-0 目录下面生成一个对应的<code>&lt;namespace&gt;-&lt;name&gt;.yaml</code>文件，所以如果以后我们需要自定义一个报警选项的话，只需要定义一个 PrometheusRule 资源对象即可。至于为什么 Prometheus 能够识别这个 PrometheusRule 资源对象呢？这就需要查看我们创建的 prometheus 这个资源对象了，里面有非常重要的一个属性 ruleSelector，用来匹配 rule 规则的过滤器，要求匹配具有 prometheus=k8s 和 role=alert-rules 标签的 PrometheusRule 资源对象，现在明白了吧？</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">ruleSelector:</span></span><br><span class="line"><span class="symbol">  matchLabels:</span></span><br><span class="line"><span class="symbol">    prometheus:</span> k8s</span><br><span class="line"><span class="symbol">    role:</span> alert-rules</span><br></pre></td></tr></table></figure>
<p>所以我们要想自定义一个报警规则，只需要创建一个具有 prometheus=k8s 和 role=alert-rules 标签的 PrometheusRule 对象就行了，比如现在我们添加一个 etcd 是否可用的报警，我们知道 etcd 整个集群有一半以上的节点可用的话集群就是可用的，所以我们判断如果不可用的 etcd 数量超过了一半那么就触发报警，创建文件 prometheus-etcdRules.yaml：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: monitoring.coreos.com/v1</span><br><span class="line"><span class="attribute">kind</span>: PrometheusRule</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">labels</span>:</span><br><span class="line">    <span class="attribute">prometheus</span>: k8s</span><br><span class="line">    <span class="attribute">role</span>: alert-rules</span><br><span class="line">  <span class="attribute">name</span>: etcd-rules</span><br><span class="line">  <span class="attribute">namespace</span>: monitoring</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">groups</span>:</span><br><span class="line">  - <span class="attribute">name</span>: etcd</span><br><span class="line">    <span class="attribute">rules</span>:</span><br><span class="line">    - <span class="attribute">alert</span>: EtcdClusterUnavailable</span><br><span class="line">      <span class="attribute">annotations</span>:</span><br><span class="line">        <span class="attribute">summary</span>: etcd cluster small</span><br><span class="line">        <span class="attribute">description</span>: If one more etcd peer goes down the cluster will be unavailable</span><br><span class="line">      <span class="attribute">expr</span>: |</span><br><span class="line">        count(up&#123;job=<span class="string">"etcd"</span>&#125; == <span class="number">0</span>) &gt; (count(up&#123;job=<span class="string">"etcd"</span>&#125;) / <span class="number">2</span> - <span class="number">1</span>)</span><br><span class="line">      <span class="attribute">for</span>: <span class="number">3</span>m</span><br><span class="line">      <span class="attribute">labels</span>:</span><br><span class="line">        <span class="attribute">severity</span>: critical</span><br></pre></td></tr></table></figure>
<p>注意 label 标签一定至少要有 prometheus=k8s 和 role=alert-rules，创建完成后，隔一会儿再去容器中查看下 rules 文件夹：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl exec -it prometheus-k8s-0 /bin/sh -n monitoring</span><br><span class="line">Defaulting container name to prometheus.</span><br><span class="line"><span class="keyword">Use</span> <span class="string">'kubectl describe pod/prometheus-k8s-0 -n monitoring'</span> <span class="keyword">to</span> see <span class="keyword">all</span> <span class="keyword">of</span> the containers <span class="keyword">in</span> this pod.</span><br><span class="line">/prometheus $ ls /etc/prometheus/<span class="keyword">rules</span>/prometheus-k8s-rulefiles<span class="number">-0</span>/</span><br><span class="line"><span class="keyword">monitoring</span>-etcd-rules.yaml            <span class="keyword">monitoring</span>-prometheus-k8s-rules.yaml</span><br></pre></td></tr></table></figure>
<p>可以看到我们创建的 rule 文件已经被注入到了对应的 rulefiles 文件夹下面了，证明我们上面的设想是正确的。然后再去 Prometheus Dashboard 的 Alert 页面下面就可以查看到上面我们新建的报警规则了：</p>
<div align="center"><img src="/img/posts/n68RSK.jpg" alt="etcd cluster"><br>etcd cluster</div>

<h3 id="配置报警"><a href="#配置报警" class="headerlink" title="配置报警"></a>配置报警</h3><p>我们知道了如何去添加一个报警规则配置项，但是这些报警信息用怎样的方式去发送呢？前面的课程中我们知道我们可以通过 AlertManager 的配置文件去配置各种报警接收器，现在我们是通过 Operator 提供的 alertmanager 资源对象创建的组件，应该怎样去修改配置呢？</p>
<p>首先我们将 alertmanager-main 这个 Service 改为 NodePort 类型的 Service，修改完成后我们可以在页面上的 status 路径下面查看 AlertManager 的配置信息:</p>
<div align="center"><img src="/img/posts/Ty1Gxu.jpg" alt="alertmanager config"><br>alertmanager config</div>

<p>这些配置信息实际上是来自于我们之前在<code>prometheus-operator/contrib/kube-prometheus/manifests</code>目录下面创建的 alertmanager-secret.yaml 文件：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  alertmanager.yaml: <span class="attribute">Imdsb2JhbCI6IAogICJyZXNvbHZlX3RpbWVvdXQiOiAiNW0iCiJyZWNlaXZlcnMiOiAKLSAibmFtZSI6ICJudWxsIgoicm91dGUiOiAKICAiZ3JvdXBfYnkiOiAKICAtICJqb2IiCiAgImdyb3VwX2ludGVydmFsIjogIjVtIgogICJncm91cF93YWl0IjogIjMwcyIKICAicmVjZWl2ZXIiOiAibnVsbCIKICAicmVwZWF0X2ludGVydmFsIjogIjEyaCIKICAicm91dGVzIjogCiAgLSAibWF0Y2giOiAKICAgICAgImFsZXJ0bmFtZSI6ICJEZWFkTWFuc1N3aXRjaCIKICAgICJyZWNlaXZlciI6ICJudWxsIg</span>==</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: alertmanager-main</span><br><span class="line">  namespace: monitoring</span><br><span class="line">type: Opaque</span><br></pre></td></tr></table></figure>
<p>可以将 alertmanager.yaml 对应的 value 值做一个 base64 解码：</p>
<figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ echo <span class="string">"Imdsb2JhbCI6IAogICJyZXNvbHZlX3RpbWVvdXQiOiAiNW0iCiJyZWNlaXZlcnMiOiAKLSAibmFtZSI6ICJudWxsIgoicm91dGUiOiAKICAiZ3JvdXBfYnkiOiAKICAtICJqb2IiCiAgImdyb3VwX2ludGVydmFsIjogIjVtIgogICJncm91cF93YWl0IjogIjMwcyIKICAicmVjZWl2ZXIiOiAibnVsbCIKICAicmVwZWF0X2ludGVydmFsIjogIjEyaCIKICAicm91dGVzIjogCiAgLSAibWF0Y2giOiAKICAgICAgImFsZXJ0bmFtZSI6ICJEZWFkTWFuc1N3aXRjaCIKICAgICJyZWNlaXZlciI6ICJudWxsIg=="</span> <span class="string">| base64 -d</span></span><br><span class="line"><span class="string">"global"</span>:</span><br><span class="line">  <span class="string">"resolve_timeout"</span>: <span class="string">"5m"</span></span><br><span class="line"><span class="string">"receivers"</span>:</span><br><span class="line">- <span class="string">"name"</span>: <span class="string">"null"</span></span><br><span class="line"><span class="string">"route"</span>:</span><br><span class="line">  <span class="string">"group_by"</span>:</span><br><span class="line">  - <span class="string">"job"</span></span><br><span class="line">  <span class="string">"group_interval"</span>: <span class="string">"5m"</span></span><br><span class="line">  <span class="string">"group_wait"</span>: <span class="string">"30s"</span></span><br><span class="line">  <span class="string">"receiver"</span>: <span class="string">"null"</span></span><br><span class="line">  <span class="string">"repeat_interval"</span>: <span class="string">"12h"</span></span><br><span class="line">  <span class="string">"routes"</span>:</span><br><span class="line">  - <span class="string">"match"</span>:</span><br><span class="line">      <span class="string">"alertname"</span>: <span class="string">"DeadMansSwitch"</span></span><br><span class="line">    <span class="string">"receiver"</span>: <span class="string">"null"</span></span><br></pre></td></tr></table></figure>
<p>我们可以看到内容和上面查看的配置信息是一致的，所以如果我们想要添加自己的接收器，或者模板消息，我们就可以更改这个文件：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">global</span>:</span><br><span class="line">  <span class="attribute">resolve_timeout</span>: <span class="number">5</span>m</span><br><span class="line">  <span class="attribute">smtp_smarthost</span>: <span class="string">'smtp.163.com:25'</span></span><br><span class="line">  <span class="attribute">smtp_from</span>: <span class="string">'ych_1024@163.com'</span></span><br><span class="line">  <span class="attribute">smtp_auth_username</span>: <span class="string">'ych_1024@163.com'</span></span><br><span class="line">  <span class="attribute">smtp_auth_password</span>: <span class="string">'&lt;邮箱密码&gt;'</span></span><br><span class="line">  <span class="attribute">smtp_hello</span>: <span class="string">'163.com'</span></span><br><span class="line">  <span class="attribute">smtp_require_tls</span>: false</span><br><span class="line"><span class="attribute">route</span>:</span><br><span class="line">  <span class="attribute">group_by</span>: [<span class="string">'job'</span>, <span class="string">'severity'</span>]</span><br><span class="line">  <span class="attribute">group_wait</span>: <span class="number">30s</span></span><br><span class="line">  <span class="attribute">group_interval</span>: <span class="number">5</span>m</span><br><span class="line">  <span class="attribute">repeat_interval</span>: <span class="number">12</span>h</span><br><span class="line">  <span class="attribute">receiver</span>: default</span><br><span class="line">  <span class="attribute">routes</span>:</span><br><span class="line">  - <span class="attribute">receiver</span>: webhook</span><br><span class="line">    <span class="attribute">match</span>:</span><br><span class="line">      <span class="attribute">alertname</span>: CoreDNSDown</span><br><span class="line"><span class="attribute">receivers</span>:</span><br><span class="line">- <span class="attribute">name</span>: <span class="string">'default'</span></span><br><span class="line">  <span class="attribute">email_configs</span>:</span><br><span class="line">  - <span class="attribute">to</span>: <span class="string">'517554016@qq.com'</span></span><br><span class="line">    <span class="attribute">send_resolved</span>: true</span><br><span class="line">- <span class="attribute">name</span>: <span class="string">'webhook'</span></span><br><span class="line">  <span class="attribute">webhook_configs</span>:</span><br><span class="line">  - <span class="attribute">url</span>: <span class="string">'http://dingtalk-hook.kube-ops:5000'</span></span><br><span class="line">    <span class="attribute">send_resolved</span>: true</span><br></pre></td></tr></table></figure>
<p>将上面文件保存为 alertmanager.yaml，然后使用这个文件创建一个 Secret 对象：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先将之前的 secret 对象删除</span></span><br><span class="line">$ kubectl delete<span class="built_in"> secret </span>alertmanager-main -n monitoring</span><br><span class="line">secret <span class="string">"alertmanager-main"</span> deleted</span><br><span class="line">$ kubectl create<span class="built_in"> secret </span>generic alertmanager-main <span class="attribute">--from-file</span>=alertmanager.yaml -n monitoring</span><br><span class="line">secret <span class="string">"alertmanager-main"</span> created</span><br></pre></td></tr></table></figure>
<p>我们添加了两个接收器，默认的通过邮箱进行发送，对于 CoreDNSDown 这个报警我们通过 webhook 来进行发送，这个 webhook 就是我们前面课程中定义的一个钉钉接收的 Server，上面的步骤创建完成后，很快我们就会收到一条钉钉消息：</p>
<div align="center"><img src="/img/posts/Of4GIB.jpg" alt="钉钉"><br>钉钉</div>

<p>同样邮箱中也会收到报警信息：</p>
<div align="center"><img src="/img/posts/NjnV2X.jpg" alt="邮箱"><br>邮箱</div>

<p>我们再次查看 AlertManager 页面的 status 页面的配置信息可以看到已经变成上面我们的配置信息了：</p>
<div align="center"><img src="/img/posts/gKhiPI.jpg" alt="alertmanager config"><br>alertmanager config</div>

<p>AlertManager 配置也可以使用模板(.tmpl文件)，这些模板可以与 alertmanager.yaml 配置文件一起添加到 Secret 对象中，比如：</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">apiVersion</span>：<span class="built_in">v1</span></span><br><span class="line"><span class="symbol">kind</span>：secret</span><br><span class="line"><span class="symbol">metadata</span>：</span><br><span class="line">   name：alertmanager-example</span><br><span class="line"><span class="symbol">data</span>：</span><br><span class="line">  alertmanager.yaml：&#123;<span class="keyword">BASE64_CONFIG&#125;</span></span><br><span class="line"><span class="keyword"> </span> template_1.tmpl：&#123;<span class="keyword">BASE64_TEMPLATE_1&#125;</span></span><br><span class="line"><span class="keyword"> </span> template_2.tmpl：&#123;<span class="keyword">BASE64_TEMPLATE_2&#125;</span></span><br><span class="line"><span class="keyword"> </span> ...</span><br></pre></td></tr></table></figure>
<p>模板会被放置到与配置文件相同的路径，当然要使用这些模板文件，还需要在 alertmanager.yaml 配置文件中指定：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">templates:</span></span><br><span class="line">- <span class="string">'*.tmpl'</span></span><br></pre></td></tr></table></figure>
<p>创建成功后，Secret 对象将会挂载到 AlertManager 对象创建的 AlertManager Pod 中去。</p>
<h2 id="高级配置"><a href="#高级配置" class="headerlink" title="高级配置"></a>高级配置</h2><p>上节课我们一起学习了如何在 Prometheus Operator 下面自定义一个监控选项，以及自定义报警规则的使用。那么我们还能够直接使用前面课程中的自动发现功能吗？如果在我们的 Kubernetes 集群中有了很多的 Service/Pod，那么我们都需要一个一个的去建立一个对应的 ServiceMonitor 对象来进行监控吗？这样岂不是又变得麻烦起来了？</p>
<h3 id="自动发现配置"><a href="#自动发现配置" class="headerlink" title="自动发现配置"></a>自动发现配置</h3><p>为解决上面的问题，Prometheus Operator 为我们提供了一个额外的抓取配置的来解决这个问题，我们可以通过添加额外的配置来进行服务发现进行自动监控。和前面自定义的方式一样，我们想要在 Prometheus Operator 当中去自动发现并监控具有<code>prometheus.io/scrape=true</code>这个 annotations 的 Service，之前我们定义的 Prometheus 的配置如下：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- job_name:</span> <span class="string">'kubernetes-service-endpoints'</span></span><br><span class="line"><span class="attr">  kubernetes_sd_configs:</span></span><br><span class="line"><span class="attr">  - role:</span> <span class="string">endpoints</span></span><br><span class="line"><span class="attr">  relabel_configs:</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__meta_kubernetes_service_annotation_prometheus_io_scrape]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">keep</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__meta_kubernetes_service_annotation_prometheus_io_scheme]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">__scheme__</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">(https?)</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__meta_kubernetes_service_annotation_prometheus_io_path]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">__metrics_path__</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">(.+)</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__address__,</span> <span class="string">__meta_kubernetes_service_annotation_prometheus_io_port]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">__address__</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">([^:]+)(?::\d+)?;(\d+)</span></span><br><span class="line"><span class="attr">    replacement:</span> <span class="string">$1:$2</span></span><br><span class="line"><span class="attr">  - action:</span> <span class="string">labelmap</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">__meta_kubernetes_service_label_(.+)</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__meta_kubernetes_namespace]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">kubernetes_namespace</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__meta_kubernetes_service_name]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">kubernetes_name</span></span><br></pre></td></tr></table></figure>
<p>如果你对上面这个配置还不是很熟悉的话，建议去查看下前面关于 <a href="https:" target="_blank" rel="noopener">Kubernetes常用资源对象监控章节的介绍</a>，要想自动发现集群中的 Service，就需要我们在 Service 的<code>annotation</code>区域添加<code>prometheus.io/scrape=true</code>的声明，将上面文件直接保存为 prometheus-additional.yaml，然后通过这个文件创建一个对应的 Secret 对象：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create<span class="built_in"> secret </span>generic additional-configs <span class="attribute">--from-file</span>=prometheus-additional.yaml -n monitoring</span><br><span class="line">secret <span class="string">"additional-configs"</span> created</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意我们所有的操作都在 Prometheus Operator 源码<code>contrib/kube-prometheus/manifests/</code>目录下面。</p>
</blockquote>
<p>创建完成后，会将上面配置信息进行 base64 编码后作为 prometheus-additional.yaml 这个 key 对应的值存在：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="builtin-name">get</span><span class="built_in"> secret </span>additional-configs -n monitoring -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">  prometheus-additional.yaml: LSBqb2JfbmFtZTogJ2t1YmVybmV0ZXMtc2VydmljZS1lbmRwb2ludHMnCiAga3ViZXJuZXRlc19zZF9jb25maWdzOgogIC0gcm9sZTogZW5kcG9pbnRzCiAgcmVsYWJlbF9jb25maWdzOgogIC0gc291cmNlX2xhYmVsczogW19fbWV0YV9rdWJlcm5ldGVzX3NlcnZpY2VfYW5ub3RhdGlvbl9wcm9tZXRoZXVzX2lvX3NjcmFwZV0KICAgIGFjdGlvbjoga2VlcAogICAgcmVnZXg6IHRydWUKICAtIHNvdXJjZV9sYWJlbHM6IFtfX21ldGFfa3ViZXJuZXRlc19zZXJ2aWNlX2Fubm90YXRpb25fcHJvbWV0aGV1c19pb19zY2hlbWVdCiAgICBhY3Rpb246IHJlcGxhY2UKICAgIHRhcmdldF9sYWJlbDogX19zY2hlbWVfXwogICAgcmVnZXg6IChodHRwcz8pCiAgLSBzb3VyY2VfbGFiZWxzOiBbX19tZXRhX2t1YmVybmV0ZXNfc2VydmljZV9hbm5vdGF0aW9uX3Byb21ldGhldXNfaW9fcGF0aF0KICAgIGFjdGlvbjogcmVwbGFjZQogICAgdGFyZ2V0X2xhYmVsOiBfX21ldHJpY3NfcGF0aF9fCiAgICByZWdleDogKC4rKQogIC0gc291cmNlX2xhYmVsczogW19fYWRkcmVzc19fLCBfX21ldGFfa3ViZXJuZXRlc19zZXJ2aWNlX2Fubm90YXRpb25fcHJvbWV0aGV1c19pb19wb3J0XQogICAgYWN0aW9uOiByZXBsYWNlCiAgICB0YXJnZXRfbGFiZWw6IF9fYWRkcmVzc19fCiAgICByZWdleDogKFteOl0rKSg/OjpcZCspPzsoXGQrKQogICAgcmVwbGFjZW1lbnQ6ICQxOiQyCiAgLSBhY3Rpb246IGxhYmVsbWFwCiAgICByZWdleDogX19tZXRhX2t1YmVybmV0ZXNfc2VydmljZV9sYWJlbF8oLispCiAgLSBzb3VyY2VfbGFiZWxzOiBbX19tZXRhX2t1YmVybmV0ZXNfbmFtZXNwYWNlXQogICAgYWN0aW9uOiByZXBsYWNlCiAgICB0YXJnZXRfbGFiZWw6IGt1YmVybmV0ZXNfbmFtZXNwYWNlCiAgLSBzb3VyY2VfbGFiZWxzOiBbX19tZXRhX2t1YmVybmV0ZXNfc2VydmljZV9uYW1lXQogICAgYWN0aW9uOiByZXBsYWNlCiAgICB0YXJnZXRfbGFiZWw6IGt1YmVybmV0ZXNfbmFtZQo=</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: 2018-12-20T14:50:35Z</span><br><span class="line">  name: additional-configs</span><br><span class="line">  namespace: monitoring</span><br><span class="line">  resourceVersion: <span class="string">"41814998"</span></span><br><span class="line">  selfLink: /api/v1/namespaces/monitoring/secrets/additional-configs</span><br><span class="line">  uid: 9bbe22c5-0466-11e9-a777-525400db4df7</span><br><span class="line">type: Opaque</span><br></pre></td></tr></table></figure>
<p>然后我们只需要在声明 prometheus 的资源对象文件中添加上这个额外的配置：(prometheus-prometheus.yaml)</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Prometheus</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    prometheus:</span> <span class="string">k8s</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">k8s</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  alerting:</span></span><br><span class="line"><span class="attr">    alertmanagers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">alertmanager-main</span></span><br><span class="line"><span class="attr">      namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">      port:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">  baseImage:</span> <span class="string">quay.io/prometheus/prometheus</span></span><br><span class="line"><span class="attr">  nodeSelector:</span></span><br><span class="line">    <span class="string">beta.kubernetes.io/os:</span> <span class="string">linux</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  secrets:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">etcd-certs</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      memory:</span> <span class="number">400</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">  ruleSelector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      prometheus:</span> <span class="string">k8s</span></span><br><span class="line"><span class="attr">      role:</span> <span class="string">alert-rules</span></span><br><span class="line"><span class="attr">  securityContext:</span></span><br><span class="line"><span class="attr">    fsGroup:</span> <span class="number">2000</span></span><br><span class="line"><span class="attr">    runAsNonRoot:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    runAsUser:</span> <span class="number">1000</span></span><br><span class="line"><span class="attr">  additionalScrapeConfigs:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">additional-configs</span></span><br><span class="line"><span class="attr">    key:</span> <span class="string">prometheus-additional.yaml</span></span><br><span class="line"><span class="attr">  serviceAccountName:</span> <span class="string">prometheus-k8s</span></span><br><span class="line"><span class="attr">  serviceMonitorNamespaceSelector:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">  serviceMonitorSelector:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">  version:</span> <span class="string">v2.5.0</span></span><br></pre></td></tr></table></figure>
<p>添加完成后，直接更新 prometheus 这个 CRD 资源对象：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f prometheus-prometheus.yaml</span><br><span class="line">prometheus<span class="selector-class">.monitoring</span><span class="selector-class">.coreos</span><span class="selector-class">.com</span> <span class="string">"k8s"</span> configured</span><br></pre></td></tr></table></figure>
<p>隔一小会儿，可以前往 Prometheus 的 Dashboard 中查看配置是否生效：</p>
<div align="center"><img src="/img/posts/jmiqaD.jpg" alt="config"><br>config</div>

<p>在 Prometheus Dashboard 的配置页面下面我们可以看到已经有了对应的的配置信息了，但是我们切换到 targets 页面下面却并没有发现对应的监控任务，查看 Prometheus 的 Pod 日志：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl logs -f prometheus-k8s-0 prometheus -n monitoring</span><br><span class="line"><span class="attribute">level</span>=error <span class="attribute">ts</span>=2018-12-20T15:14:06.772903214Z <span class="attribute">caller</span>=main.go:240 <span class="attribute">component</span>=k8s_client_runtime <span class="attribute">err</span>=<span class="string">"github.com/prometheus/prometheus/discovery/kubernetes/kubernetes.go:302: Failed to list *v1.Pod: pods is forbidden: User \"system:serviceaccount:monitoring:prometheus-k8s\" cannot list pods at the cluster scope"</span></span><br><span class="line"><span class="attribute">level</span>=error <span class="attribute">ts</span>=2018-12-20T15:14:06.773096875Z <span class="attribute">caller</span>=main.go:240 <span class="attribute">component</span>=k8s_client_runtime <span class="attribute">err</span>=<span class="string">"github.com/prometheus/prometheus/discovery/kubernetes/kubernetes.go:301: Failed to list *v1.Service: services is forbidden: User \"system:serviceaccount:monitoring:prometheus-k8s\" cannot list services at the cluster scope"</span></span><br><span class="line"><span class="attribute">level</span>=error <span class="attribute">ts</span>=2018-12-20T15:14:06.773212629Z <span class="attribute">caller</span>=main.go:240 <span class="attribute">component</span>=k8s_client_runtime <span class="attribute">err</span>=<span class="string">"github.com/prometheus/prometheus/discovery/kubernetes/kubernetes.go:300: Failed to list *v1.Endpoints: endpoints is forbidden: User \"system:serviceaccount:monitoring:prometheus-k8s\" cannot list endpoints at the cluster scope"</span></span><br><span class="line"><span class="built_in">..</span><span class="built_in">..</span><span class="built_in">..</span></span><br></pre></td></tr></table></figure>
<p>可以看到有很多错误日志出现，都是<code>xxx is forbidden</code>，这说明是 RBAC 权限的问题，通过 prometheus 资源对象的配置可以知道 Prometheus 绑定了一个名为 prometheus-k8s 的 ServiceAccount 对象，而这个对象绑定的是一个名为 prometheus-k8s 的 ClusterRole：（prometheus-clusterRole.yaml）</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadat<span class="variable">a:</span></span><br><span class="line">  name: prometheus-k8s</span><br><span class="line">rule<span class="variable">s:</span></span><br><span class="line">- apiGroup<span class="variable">s:</span></span><br><span class="line">  - <span class="string">""</span></span><br><span class="line">  resource<span class="variable">s:</span></span><br><span class="line">  - nodes/metrics</span><br><span class="line">  <span class="keyword">verb</span><span class="variable">s:</span></span><br><span class="line">  - <span class="built_in">get</span></span><br><span class="line">- nonResourceURL<span class="variable">s:</span></span><br><span class="line">  - /metrics</span><br><span class="line">  <span class="keyword">verb</span><span class="variable">s:</span></span><br><span class="line">  - <span class="built_in">get</span></span><br></pre></td></tr></table></figure>
<p>上面的权限规则中我们可以看到明显没有对 Service 或者 Pod 的 list 权限，所以报错了，要解决这个问题，我们只需要添加上需要的权限即可：</p>
<figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-k8s</span><br><span class="line">rules:</span><br><span class="line">-<span class="ruby"> <span class="symbol">apiGroups:</span></span></span><br><span class="line"><span class="ruby">  - <span class="string">""</span></span></span><br><span class="line"><span class="ruby">  <span class="symbol">resources:</span></span></span><br><span class="line"><span class="ruby">  - nodes</span></span><br><span class="line"><span class="ruby">  - services</span></span><br><span class="line"><span class="ruby">  - endpoints</span></span><br><span class="line"><span class="ruby">  - pods</span></span><br><span class="line"><span class="ruby">  - nodes/proxy</span></span><br><span class="line"><span class="ruby">  <span class="symbol">verbs:</span></span></span><br><span class="line"><span class="ruby">  - get</span></span><br><span class="line"><span class="ruby">  - list</span></span><br><span class="line"><span class="ruby">  - watch</span></span><br><span class="line"><span class="ruby">- <span class="symbol">apiGroups:</span></span></span><br><span class="line"><span class="ruby">  - <span class="string">""</span></span></span><br><span class="line"><span class="ruby">  <span class="symbol">resources:</span></span></span><br><span class="line"><span class="ruby">  - configmaps</span></span><br><span class="line"><span class="ruby">  - nodes/metrics</span></span><br><span class="line"><span class="ruby">  <span class="symbol">verbs:</span></span></span><br><span class="line"><span class="ruby">  - get</span></span><br><span class="line"><span class="ruby">- <span class="symbol">nonResourceURLs:</span></span></span><br><span class="line"><span class="ruby">  - <span class="regexp">/metrics</span></span></span><br><span class="line"><span class="ruby">  <span class="symbol">verbs:</span></span></span><br><span class="line"><span class="ruby">  - get</span></span><br></pre></td></tr></table></figure>
<p>更新上面的 ClusterRole 这个资源对象，然后重建下 Prometheus 的所有 Pod，正常就可以看到 targets 页面下面有 kubernetes-service-endpoints 这个监控任务了：</p>
<div align="center"><img src="/img/posts/R38S3q.jpg" alt="endpoints"><br>endpoints</div>

<p>我们这里自动监控了两个 Service，第一个就是我们之前创建的 Redis 的服务，我们在 Redis Service 中有两个特殊的 annotations：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">annotations:</span></span><br><span class="line">  prometheus.io/<span class="string">scrape:</span> <span class="string">"true"</span></span><br><span class="line">  prometheus.io/<span class="string">port:</span> <span class="string">"9121"</span></span><br></pre></td></tr></table></figure>
<p>所以被自动发现了，当然我们也可以用同样的方式去配置 Pod、Ingress 这些资源对象的自动发现。</p>
<h3 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h3><p>上面我们在修改完权限的时候，重启了 Prometheus 的 Pod，如果我们仔细观察的话会发现我们之前采集的数据已经没有了，这是因为我们通过 prometheus 这个 CRD 创建的 Prometheus 并没有做数据的持久化，我们可以直接查看生成的 Prometheus Pod 的挂载情况就清楚了：</p>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod prometheus-k8s-0 -n monitoring -o yaml</span><br><span class="line">......</span><br><span class="line"><span class="code">    volumeMounts:</span></span><br><span class="line"><span class="code">    - mountPath: /etc/prometheus/config_out</span></span><br><span class="line"><span class="code">      name: config-out</span></span><br><span class="line"><span class="code">      readOnly: true</span></span><br><span class="line"><span class="code">    - mountPath: /prometheus</span></span><br><span class="line"><span class="code">      name: prometheus-k8s-db</span></span><br><span class="line">......</span><br><span class="line"><span class="code">  volumes:</span></span><br><span class="line">......</span><br><span class="line"><span class="code">  - emptyDir: &#123;&#125;</span></span><br><span class="line"><span class="code">    name: prometheus-k8s-db</span></span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>我们可以看到 Prometheus 的数据目录 /prometheus 实际上是通过 emptyDir 进行挂载的，我们知道 emptyDir 挂载的数据的生命周期和 Pod 生命周期一致的，所以如果 Pod 挂掉了，数据也就丢失了，这也就是为什么我们重建 Pod 后之前的数据就没有了的原因，对应线上的监控数据肯定需要做数据的持久化的，同样的 prometheus 这个 CRD 资源也为我们提供了数据持久化的配置方法，由于我们的 Prometheus 最终是通过 Statefulset 控制器进行部署的，所以我们这里需要通过 storageclass 来做数据持久化，首先创建一个 StorageClass 对象：</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">apiVersion:</span> storage.k8s.io/v1</span><br><span class="line"><span class="symbol">kind:</span> StorageClass</span><br><span class="line"><span class="symbol">metadata:</span></span><br><span class="line"><span class="symbol">  name:</span> prometheus-data-db</span><br><span class="line"><span class="symbol">provisioner:</span> fuseim.pri/ifs</span><br></pre></td></tr></table></figure>
<p>这里我们声明一个 StorageClass 对象，其中 provisioner=fuseim.pri/ifs，则是因为我们集群中使用的是 nfs 作为存储后端，而前面我们课程中创建的 nfs-client-provisioner 中指定的 PROVISIONER_NAME 就为 fuseim.pri/ifs，这个名字不能随便更改，将该文件保存为 prometheus-storageclass.yaml:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f prometheus-storageclass.yaml</span><br><span class="line">storageclass<span class="selector-class">.storage</span><span class="selector-class">.k8s</span><span class="selector-class">.io</span> <span class="string">"prometheus-data-db"</span> created</span><br></pre></td></tr></table></figure>
<p>然后在 prometheus 的 CRD 资源对象中添加如下配置：</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">storage:</span></span><br><span class="line"><span class="symbol">  volumeClaimTemplate:</span></span><br><span class="line"><span class="symbol">    spec:</span></span><br><span class="line"><span class="symbol">      storageClassName:</span> prometheus-data-db</span><br><span class="line"><span class="symbol">      resources:</span></span><br><span class="line"><span class="symbol">        requests:</span></span><br><span class="line"><span class="symbol">          storage:</span> <span class="number">10</span>Gi</span><br></pre></td></tr></table></figure>
<p>注意这里的 storageClassName 名字为上面我们创建的 StorageClass 对象名称，然后更新 prometheus 这个 CRD 资源。更新完成后会自动生成两个 PVC 和 PV 资源对象：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pvc -n monitoring</span><br><span class="line">NAME                                 STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS         AGE</span><br><span class="line">prometheus-k8s-db-prometheus-k8s<span class="number">-0</span>   Bound     pvc<span class="number">-0</span>cc03d41<span class="number">-047</span>a<span class="number">-11e9</span>-a777<span class="number">-525400</span>db4df7   <span class="number">10</span>Gi       RWO            prometheus-data-db   <span class="number">8</span>m</span><br><span class="line">prometheus-k8s-db-prometheus-k8s<span class="number">-1</span>   Bound     pvc<span class="number">-1938</span>de6b<span class="number">-047</span>b<span class="number">-11e9</span>-a777<span class="number">-525400</span>db4df7   <span class="number">10</span>Gi       RWO            prometheus-data-db   <span class="number">1</span>m</span><br><span class="line">$ kubectl get pv</span><br><span class="line">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                                           STORAGECLASS         REASON    AGE</span><br><span class="line">pvc<span class="number">-0</span>cc03d41<span class="number">-047</span>a<span class="number">-11e9</span>-a777<span class="number">-525400</span>db4df7   <span class="number">10</span>Gi       RWO            Delete           Bound       monitoring/prometheus-k8s-db-prometheus-k8s<span class="number">-0</span>   prometheus-data-db             <span class="number">2</span>m</span><br><span class="line">pvc<span class="number">-1938</span>de6b<span class="number">-047</span>b<span class="number">-11e9</span>-a777<span class="number">-525400</span>db4df7   <span class="number">10</span>Gi       RWO            Delete           Bound       monitoring/prometheus-k8s-db-prometheus-k8s<span class="number">-1</span>   prometheus-data-db             <span class="number">1</span>m</span><br></pre></td></tr></table></figure>
<p>现在我们再去看 Prometheus Pod 的数据目录就可以看到是关联到一个 PVC 对象上了。</p>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod prometheus-k8s-0 -n monitoring -o yaml</span><br><span class="line">......</span><br><span class="line"><span class="code">    volumeMounts:</span></span><br><span class="line"><span class="code">    - mountPath: /etc/prometheus/config_out</span></span><br><span class="line"><span class="code">      name: config-out</span></span><br><span class="line"><span class="code">      readOnly: true</span></span><br><span class="line"><span class="code">    - mountPath: /prometheus</span></span><br><span class="line"><span class="code">      name: prometheus-k8s-db</span></span><br><span class="line">......</span><br><span class="line"><span class="code">  volumes:</span></span><br><span class="line">......</span><br><span class="line"><span class="code">  - name: prometheus-k8s-db</span></span><br><span class="line"><span class="code">    persistentVolumeClaim:</span></span><br><span class="line"><span class="code">      claimName: prometheus-k8s-db-prometheus-k8s-0</span></span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>现在即使我们的 Pod 挂掉了，数据也不会丢失了，最后，下面是我们 Prometheus Operator 系列课程中最终的创建资源清单文件，更多的信息可以在<a href="https://github.com/myhhub/kubernetes-learning" target="_blank" rel="noopener">https://github.com/myhhub/kubernetes-learning</a> 下面查看。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">monitoring.coreos.com/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Prometheus</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    prometheus:</span> <span class="string">k8s</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">k8s</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  alerting:</span></span><br><span class="line"><span class="attr">    alertmanagers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">alertmanager-main</span></span><br><span class="line"><span class="attr">      namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">      port:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">  storage:</span></span><br><span class="line"><span class="attr">    volumeClaimTemplate:</span></span><br><span class="line"><span class="attr">      spec:</span></span><br><span class="line"><span class="attr">        storageClassName:</span> <span class="string">prometheus-data-db</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            storage:</span> <span class="number">10</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">  baseImage:</span> <span class="string">quay.io/prometheus/prometheus</span></span><br><span class="line"><span class="attr">  nodeSelector:</span></span><br><span class="line">    <span class="string">beta.kubernetes.io/os:</span> <span class="string">linux</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  secrets:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">etcd-certs</span></span><br><span class="line"><span class="attr">  additionalScrapeConfigs:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">additional-configs</span></span><br><span class="line"><span class="attr">    key:</span> <span class="string">prometheus-additional.yaml</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      memory:</span> <span class="number">400</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">  ruleSelector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      prometheus:</span> <span class="string">k8s</span></span><br><span class="line"><span class="attr">      role:</span> <span class="string">alert-rules</span></span><br><span class="line"><span class="attr">  securityContext:</span></span><br><span class="line"><span class="attr">    fsGroup:</span> <span class="number">2000</span></span><br><span class="line"><span class="attr">    runAsNonRoot:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    runAsUser:</span> <span class="number">1000</span></span><br><span class="line"><span class="attr">  serviceAccountName:</span> <span class="string">prometheus-k8s</span></span><br><span class="line"><span class="attr">  serviceMonitorNamespaceSelector:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">  serviceMonitorSelector:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">  version:</span> <span class="string">v2.5.0</span></span><br></pre></td></tr></table></figure>
<hr>
<p>接下文：<a href="100121.html">kubernetes集群监控之 三.Grafana</a> </p>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="/" target="_blank">Ljjyy.com</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/archives/2018/12/100121.html" class="pre-post btn btn-default" title='kubernetes集群监控之 三.Grafana'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">kubernetes集群监控之 三.Grafana</span>
        </a>
    
    
        <a href="/archives/2018/12/100111.html" class="next-post btn btn-default" title='Kubernetes集群监控之 一.Prometheus'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">Kubernetes集群监控之 一.Prometheus</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: '5MzTXYXkt03k101j0PmSDN34-gzGzoHsz',
            appKey: 'iwjYgwno6qj3wtDVVSbe8nYQ',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Operator"><span class="toc-text">Operator</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#介绍"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装"><span class="toc-text">安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#配置"><span class="toc-text">配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#自定义监控项"><span class="toc-text">自定义监控项</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#etcd-证书"><span class="toc-text">etcd 证书</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#创建-ServiceMonitor"><span class="toc-text">创建 ServiceMonitor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#创建-Service"><span class="toc-text">创建 Service</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置-PrometheusRule"><span class="toc-text">配置 PrometheusRule</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置报警"><span class="toc-text">配置报警</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#高级配置"><span class="toc-text">高级配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#自动发现配置"><span class="toc-text">自动发现配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据持久化"><span class="toc-text">数据持久化</span></a></li></ol></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019-2023&emsp;<a href="/" class="copyright-links" target="_blank" rel="nofollow">Ljjyy.com</a>
                </span> |
                <span>
                    <a href="/about/" class="copyright-links" target="_blank" rel="nofollow">关于我们</a>
                </span> |                
                <span>
                    <a href="/sitemap.xml" class="copyright-links" target="_blank" rel="nofollow">网站地图</a>
                </span> |
                <span>
                    <a href="/archives/" class="copyright-links" target="_blank" rel="nofollow">时间轴</a>
                </span>              
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>
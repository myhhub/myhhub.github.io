<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <meta name="theme-version" content="1.2.3">
    <meta name="root" content="/">
    <link rel="dns-prefetch" href="https://www.ljjyy.com">
    <!--SEO-->

    <meta name="keywords" content="kubernetes,安装,监控,prometheus">


    <meta name="description" content="一起来学习 Kubernetes 中监控系统的搭建，我们知道监控是保证系统运行必不可少的功能，特别是对于 Kubernetes 这种比较庞大的系统来说，监控报警更是不可或缺，我们需要时刻了解系统...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>Kubernetes集群监控之 一.Prometheus | 来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</title>


    <link rel="alternate" href="/atom.xml" title="来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
        <script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script>
        <script>LA.init({id: "JgbNOaw1xxsmUUsQ",ck: "JgbNOaw1xxsmUUsQ"})</script>
	</div>






    
    <meta name="baidu-site-verification" content="dTHILoORpx">


    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script>

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  >
    <div class="main-header-box">
        <!--a class="header-avatar" href="/" title='Ljjyy.com'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a-->
        <div class="branding">
            
                <h2> 多读书多实践，勤思考善领悟 </h2>
            
    	  </div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">

        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="web-logo"  href="/" title='Ljjyy.com'></a>
                    <!--a class="navbar-brand" href="https://www.ljjyy.com">来唧唧歪歪(Ljjyy.com) - 多读书多实践，勤思考善领悟</a-->
                </div>
                <div class="collapse navbar-collapse" id="main-menu" style="">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/cloud/"><i class="fa "></i>云计算</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/front/"><i class="fa "></i>前端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/back/"><i class="fa "></i>后端</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/devops/"><i class="fa "></i>运维</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/crack/"><i class="fa "></i>破解</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/penetration/"><i class="fa "></i>渗透</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tool/"><i class="fa "></i>工具</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/other/"><i class="fa "></i>其他</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="Kubernetes集群监控之 一.Prometheus">
            
	            Kubernetes集群监控之 一.Prometheus
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/cloud/">云计算</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/kubernetes/">kubernetes</a> <a class="tag-link" href="/tags/prometheus/">prometheus</a> <a class="tag-link" href="/tags/install/">安装</a> <a class="tag-link" href="/tags/monitor/">监控</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2018/12/11</span>
        </span>
        
    
</div>
            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>2043</strong>天之前发表，文中内容可能已经过时。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <p>一起来学习 Kubernetes 中监控系统的搭建，我们知道监控是保证系统运行必不可少的功能，特别是对于 Kubernetes 这种比较庞大的系统来说，监控报警更是不可或缺，我们需要时刻了解系统的各种运行指标，也需要时刻了解我们的 Pod 的各种指标，更需要在出现问题的时候有报警信息通知到我们。</p>
<p>在早期的版本中 Kubernetes 提供了 heapster、influxDB、grafana 的组合来监控系统，所以我们可以在 Dashboard 中看到 heapster 提供的一些图表信息，在后续的版本中会陆续移除掉 heapster，现在更加流行的监控工具是 <a href="https://prometheus.io/" target="_blank" rel="noopener">prometheus</a>，prometheus 是 Google 内部监控报警系统的开源版本，是 Google SRE 思想在其内部不断完善的产物，它的存在是为了更快和高效的发现问题，快速的接入速度，简单灵活的配置都很好的解决了这一切，而且是已经毕业的 CNCF 项目。</p>
<blockquote>
<p>这里推荐一本书了解 Goolge 运维的秘密：《SRE: Google运维解密》</p>
</blockquote>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Prometheus 最初是 SoundCloud 构建的开源系统监控和报警工具，是一个独立的开源项目，于2016年加入了 CNCF 基金会，作为继 Kubernetes 之后的第二个托管项目。</p>
<h2 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h2><p>Prometheus 相比于其他传统监控工具主要有以下几个特点：</p>
<ul>
<li>具有由 metric 名称和键/值对标识的时间序列数据的多维数据模型</li>
<li>有一个灵活的查询语言</li>
<li>不依赖分布式存储，只和本地磁盘有关</li>
<li>通过 HTTP 的服务拉取时间序列数据</li>
<li>也支持推送的方式来添加时间序列数据</li>
<li>还支持通过服务发现或静态配置发现目标</li>
<li>多种图形和仪表板支持</li>
</ul>
<h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><p>Prometheus 由多个组件组成，但是其中许多组件是可选的：</p>
<ul>
<li>Prometheus Server：用于抓取指标、存储时间序列数据</li>
<li>exporter：暴露指标让任务来抓</li>
<li>pushgateway：push 的方式将指标数据推送到该网关</li>
<li>alertmanager：处理报警的报警组件</li>
<li>adhoc：用于数据查询</li>
</ul>
<p>大多数 Prometheus 组件都是用 Go 编写的，因此很容易构建和部署为静态的二进制文件。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>下图是 Prometheus 官方提供的架构及其一些相关的生态系统组件：</p>
<div align="center"><img src="/img/posts/prometheus-architecture.png" alt="架构"><br>架构</div>

<p>整体流程比较简单，Prometheus 直接接收或者通过中间的 Pushgateway 网关被动获取指标数据，在本地存储所有的获取的指标数据，并对这些数据进行一些规则整理，用来生成一些聚合数据或者报警信息，Grafana 或者其他工具用来可视化这些数据。</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>由于 Prometheus 是 Golang 编写的程序，所以要安装的话也非常简单，只需要将二进制文件下载下来直接执行即可，前往地址：<a href="https://prometheus.io/download" target="_blank" rel="noopener">https://prometheus.io/download</a> 下载我们对应的版本即可。</p>
<p>Prometheus 是通过一个 YAML 配置文件来进行启动的，如果我们使用二进制的方式来启动的话，可以使用下面的命令：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">$</span> ./prometheus --config.<span class="keyword">file</span>=prometheus.yml</span><br></pre></td></tr></table></figure>
<p>其中 prometheus.yml 文件的基本配置如下：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">global</span>:</span><br><span class="line">  <span class="attribute">scrape_interval</span>:     <span class="number">15s</span></span><br><span class="line">  <span class="attribute">evaluation_interval</span>: <span class="number">15s</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">rule_files</span>:</span><br><span class="line">  # - <span class="string">"first.rules"</span></span><br><span class="line">  # - <span class="string">"second.rules"</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">scrape_configs</span>:</span><br><span class="line">  - <span class="attribute">job_name</span>: prometheus</span><br><span class="line">    <span class="attribute">static_configs</span>:</span><br><span class="line">      - <span class="attribute">targets</span>: [<span class="string">'localhost:9090'</span>]</span><br></pre></td></tr></table></figure>
<p>上面这个配置文件中包含了3个模块：global、rule_files 和 scrape_configs。</p>
<p>其中 global 模块控制 Prometheus Server 的全局配置：</p>
<ul>
<li>scrape_interval：表示 prometheus 抓取指标数据的频率，默认是15s，我们可以覆盖这个值</li>
<li>evaluation_interval：用来控制评估规则的频率，prometheus 使用规则产生新的时间序列数据或者产生警报</li>
</ul>
<p>rule_files 模块制定了规则所在的位置，prometheus 可以根据这个配置加载规则，用于生成新的时间序列数据或者报警信息，当前我们没有配置任何规则。</p>
<p>scrape_configs 用于控制 prometheus 监控哪些资源。由于 prometheus 通过 HTTP 的方式来暴露的它本身的监控数据，prometheus 也能够监控本身的健康情况。在默认的配置里有一个单独的 job，叫做prometheus，它采集 prometheus 服务本身的时间序列数据。这个 job 包含了一个单独的、静态配置的目标：监听 localhost 上的9090端口。prometheus 默认会通过目标的<code>/metrics</code>路径采集 metrics。所以，默认的 job 通过 URL：<code>http://localhost:9090/metrics</code>采集 metrics。收集到的时间序列包含 prometheus 服务本身的状态和性能。如果我们还有其他的资源需要监控的话，直接配置在该模块下面就可以了。</p>
<p>由于我们这里是要跑在 Kubernetes 系统中，所以我们直接用 Docker 镜像的方式运行即可。</p>
<blockquote>
<p>为了方便管理，我们将所有的资源对象都安装在<code>kube-ops</code>的 namespace 下面，没有的话需要提前安装。</p>
</blockquote>
<p>为了能够方便的管理配置文件，我们这里将 prometheus.yml 文件用 ConfigMap 的形式进行管理：（prometheus-cm.yaml）</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: ConfigMap</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: prometheus-config</span><br><span class="line">  <span class="attribute">namespace</span>: kube-ops</span><br><span class="line"><span class="attribute">data</span>:</span><br><span class="line">  prometheus.<span class="attribute">yml</span>: |</span><br><span class="line">    <span class="attribute">global</span>:</span><br><span class="line">      <span class="attribute">scrape_interval</span>: <span class="number">15s</span></span><br><span class="line">      <span class="attribute">scrape_timeout</span>: <span class="number">15s</span></span><br><span class="line">    <span class="attribute">scrape_configs</span>:</span><br><span class="line">    - <span class="attribute">job_name</span>: <span class="string">'prometheus'</span></span><br><span class="line">      <span class="attribute">static_configs</span>:</span><br><span class="line">      - <span class="attribute">targets</span>: [<span class="string">'localhost:9090'</span>]</span><br></pre></td></tr></table></figure>
<p>我们这里暂时只配置了对 prometheus 的监控，然后创建该资源对象：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f prometheus-cm.yaml</span><br><span class="line">configmap <span class="string">"prometheus-config"</span> created</span><br></pre></td></tr></table></figure>
<p>配置文件创建完成了，以后如果我们有新的资源需要被监控，我们只需要将上面的 ConfigMap 对象更新即可。现在我们来创建 prometheus 的 Pod 资源：(prometheus-deploy.yaml)</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: extensions/v1beta1</span><br><span class="line"><span class="attribute">kind</span>: Deployment</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: prometheus</span><br><span class="line">  <span class="attribute">namespace</span>: kube-ops</span><br><span class="line">  <span class="attribute">labels</span>:</span><br><span class="line">    <span class="attribute">app</span>: prometheus</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">template</span>:</span><br><span class="line">    <span class="attribute">metadata</span>:</span><br><span class="line">      <span class="attribute">labels</span>:</span><br><span class="line">        <span class="attribute">app</span>: prometheus</span><br><span class="line">    <span class="attribute">spec</span>:</span><br><span class="line">      <span class="attribute">serviceAccountName</span>: prometheus</span><br><span class="line">      <span class="attribute">containers</span>:</span><br><span class="line">      - <span class="attribute">image</span>: prom/<span class="attribute">prometheus</span>:v2.<span class="number">4.3</span></span><br><span class="line">        <span class="attribute">name</span>: prometheus</span><br><span class="line">        <span class="attribute">command</span>:</span><br><span class="line">        - <span class="string">"/bin/prometheus"</span></span><br><span class="line">        <span class="attribute">args</span>:</span><br><span class="line">        - <span class="string">"--config.file=/etc/prometheus/prometheus.yml"</span></span><br><span class="line">        - <span class="string">"--storage.tsdb.path=/prometheus"</span></span><br><span class="line">        - <span class="string">"--storage.tsdb.retention=24h"</span></span><br><span class="line">        - <span class="string">"--web.enable-admin-api"</span>  # 控制对admin HTTP API的访问，其中包括删除时间序列等功能</span><br><span class="line">        - <span class="string">"--web.enable-lifecycle"</span>  # 支持热更新，直接执行<span class="attribute">localhost</span>:<span class="number">9090</span>/-/reload立即生效</span><br><span class="line">        <span class="attribute">ports</span>:</span><br><span class="line">        - <span class="attribute">containerPort</span>: <span class="number">9090</span></span><br><span class="line">          <span class="attribute">protocol</span>: TCP</span><br><span class="line">          <span class="attribute">name</span>: http</span><br><span class="line">        <span class="attribute">volumeMounts</span>:</span><br><span class="line">        - <span class="attribute">mountPath</span>: <span class="string">"/prometheus"</span></span><br><span class="line">          <span class="attribute">subPath</span>: prometheus</span><br><span class="line">          <span class="attribute">name</span>: data</span><br><span class="line">        - <span class="attribute">mountPath</span>: <span class="string">"/etc/prometheus"</span></span><br><span class="line">          <span class="attribute">name</span>: config-volume</span><br><span class="line">        <span class="attribute">resources</span>:</span><br><span class="line">          <span class="attribute">requests</span>:</span><br><span class="line">            <span class="attribute">cpu</span>: <span class="number">100</span>m</span><br><span class="line">            <span class="attribute">memory</span>: <span class="number">512</span>Mi</span><br><span class="line">          <span class="attribute">limits</span>:</span><br><span class="line">            <span class="attribute">cpu</span>: <span class="number">100</span>m</span><br><span class="line">            <span class="attribute">memory</span>: <span class="number">512</span>Mi</span><br><span class="line">      <span class="attribute">securityContext</span>:</span><br><span class="line">        <span class="attribute">runAsUser</span>: <span class="number">0</span></span><br><span class="line">      <span class="attribute">volumes</span>:</span><br><span class="line">      - <span class="attribute">name</span>: data</span><br><span class="line">        <span class="attribute">persistentVolumeClaim</span>:</span><br><span class="line">          <span class="attribute">claimName</span>: prometheus</span><br><span class="line">      - <span class="attribute">configMap</span>:</span><br><span class="line">          <span class="attribute">name</span>: prometheus-config</span><br><span class="line">        <span class="attribute">name</span>: config-volume</span><br></pre></td></tr></table></figure>
<p>我们在启动程序的时候，除了指定了 prometheus.yml 文件之外，还通过参数<code>storage.tsdb.path</code>指定了 TSDB 数据的存储路径、通过<code>storage.tsdb.retention</code>设置了保留多长时间的数据，还有下面的<code>web.enable-admin-api</code>参数可以用来开启对 admin api 的访问权限，参数<code>web.enable-lifecycle</code>非常重要，用来开启支持热更新的，有了这个参数之后，prometheus.yml 配置文件只要更新了，通过执行<code>localhost:9090/-/reload</code>就会立即生效，所以一定要加上这个参数。</p>
<p>我们这里将 prometheus.yml 文件对应的 ConfigMap 对象通过 volume 的形式挂载进了 Pod，这样 ConfigMap 更新后，对应的 Pod 里面的文件也会热更新的，然后我们再执行上面的 reload 请求，Prometheus 配置就生效了，除此之外，为了将时间序列数据进行持久化，我们将数据目录和一个 pvc 对象进行了绑定，所以我们需要提前创建好这个 pvc 对象：(prometheus-volume.yaml)</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prometheus</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  capacity:</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="number">10</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">ReadWriteOnce</span></span><br><span class="line"><span class="attr">  persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span></span><br><span class="line"><span class="attr">  nfs:</span></span><br><span class="line"><span class="attr">    server:</span> <span class="number">10.151</span><span class="number">.30</span><span class="number">.57</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/data/k8s</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prometheus</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">ReadWriteOnce</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      storage:</span> <span class="number">10</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure>
<p>我们这里简单的通过 NFS 作为存储后端创建一个 pv、pvc 对象：</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f prometheus-<span class="keyword">volume</span>.<span class="bash">yaml</span></span><br></pre></td></tr></table></figure>
<p>除了上面的注意事项外，我们这里还需要配置 rbac 认证，因为我们需要在 prometheus 中去访问 Kubernetes 的相关信息，所以我们这里管理了一个名为 prometheus 的 serviceAccount 对象：(prometheus-rbac.yaml)</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prometheus</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prometheus</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">nodes</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">services</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">endpoints</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">pods</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">nodes/proxy</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">get</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">list</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">watch</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">configmaps</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">nodes/metrics</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">get</span></span><br><span class="line"><span class="attr">- nonResourceURLs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">/metrics</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">get</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prometheus</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prometheus</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">prometheus</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br></pre></td></tr></table></figure>
<p>由于我们要获取的资源信息，在每一个 namespace 下面都有可能存在，所以我们这里使用的是 ClusterRole 的资源对象，值得一提的是我们这里的权限规则声明中有一个<code>nonResourceURLs</code>的属性，是用来对非资源型 metrics 进行操作的权限声明，这个在以前我们很少遇到过，然后直接创建上面的资源对象即可：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f prometheus-rbac.yaml</span><br><span class="line">serviceaccount <span class="string">"prometheus"</span> created</span><br><span class="line">clusterrole<span class="selector-class">.rbac</span><span class="selector-class">.authorization</span><span class="selector-class">.k8s</span><span class="selector-class">.io</span> <span class="string">"prometheus"</span> created</span><br><span class="line">clusterrolebinding<span class="selector-class">.rbac</span><span class="selector-class">.authorization</span><span class="selector-class">.k8s</span><span class="selector-class">.io</span> <span class="string">"prometheus"</span> created</span><br></pre></td></tr></table></figure>
<p>还有一个要注意的地方是我们这里必须要添加一个<code>securityContext</code>的属性，将其中的<code>runAsUser</code>设置为0，这是因为现在的 prometheus 运行过程中使用的用户是 <a href="https://github.com/prometheus/prometheus/blob/master/Dockerfile" target="_blank" rel="noopener">nobody</a>，否则会出现下面的<code>permission denied</code>之类的权限错误：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">level</span>=error <span class="attribute">ts</span>=2018-10-22T14:34:58.632016274Z <span class="attribute">caller</span>=main.go:617 <span class="attribute">err</span>=<span class="string">"opening storage failed: lock DB directory: open /data/lock: permission denied"</span></span><br></pre></td></tr></table></figure>
<p>现在我们就可以添加 promethues 的资源对象了：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f prometheus-deploy.yaml</span><br><span class="line">deployment.extensions <span class="string">"prometheus"</span> created</span><br><span class="line">$ kubectl <span class="builtin-name">get</span> pods -n kube-ops</span><br><span class="line">NAME                          READY     STATUS    RESTARTS   AGE</span><br><span class="line">prometheus-6dd775cbff-zb69l   1/1       Running   0          20m</span><br><span class="line">$ kubectl logs -f prometheus-6dd775cbff-zb69l -n kube-ops</span><br><span class="line"><span class="built_in">..</span><span class="built_in">..</span><span class="built_in">..</span></span><br><span class="line"><span class="attribute">level</span>=info <span class="attribute">ts</span>=2018-10-22T14:44:40.535385503Z <span class="attribute">caller</span>=main.go:523 <span class="attribute">msg</span>=<span class="string">"Server is ready to receive web requests."</span></span><br></pre></td></tr></table></figure>
<p>Pod 创建成功后，为了能够在外部访问到 prometheus 的 webui 服务，我们还需要创建一个 Service 对象：(prometheus-svc.yaml)</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: Service</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: prometheus</span><br><span class="line">  <span class="attribute">namespace</span>: kube-ops</span><br><span class="line">  <span class="attribute">labels</span>:</span><br><span class="line">    <span class="attribute">app</span>: prometheus</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">selector</span>:</span><br><span class="line">    <span class="attribute">app</span>: prometheus</span><br><span class="line">  <span class="attribute">type</span>: NodePort</span><br><span class="line">  <span class="attribute">ports</span>:</span><br><span class="line">    - <span class="attribute">name</span>: web</span><br><span class="line">      <span class="attribute">port</span>: <span class="number">9090</span></span><br><span class="line">      <span class="attribute">targetPort</span>: http</span><br></pre></td></tr></table></figure>
<p>为了方便测试，我们这里创建一个<code>NodePort</code>类型的服务，当然我们可以创建一个<code>Ingress</code>对象，通过域名来进行访问：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f prometheus-svc.yaml</span><br><span class="line">service <span class="string">"prometheus"</span> created</span><br><span class="line">$ kubectl <span class="builtin-name">get</span> svc -n kube-ops</span><br><span class="line">NAME        <span class="built_in"> TYPE </span>      CLUSTER-IP       EXTERNAL-IP   PORT(S)                          AGE</span><br><span class="line">prometheus   NodePort   10.111.118.104   &lt;none&gt;        9090:30987/TCP                   24s</span><br></pre></td></tr></table></figure>
<p>然后我们就可以通过<strong>http://任意节点IP:30987</strong>访问 prometheus 的 webui 服务了。</p>
<div align="center"><img src="/img/posts/prometheus-webui.png" alt="prometheus webui"><br>prometheus webui</div>

<p>为了数据的一致性，prometheus 所有的数据都是使用的 UTC 时间，所以我们默认打开的 dashboard 中有这样一个警告，我们需要在查询的时候指定我们当前的时间才可以。然后我们可以查看当前监控系统中的一些监控目标：</p>
<div align="center"><img src="/img/posts/prometheus-menu.png" alt="prometheus targets"></div>

<p>由于我们现在还没有配置任何的报警信息，所以 Alerts 菜单下面现在没有任何数据，隔一会儿，我们可以去 Graph 菜单下面查看我们抓取的 prometheus 本身的一些监控数据了，其中<code>- insert metrics at cursor -</code>下面就是我们搜集到的一些监控数据指标： </p>
<div align="center"><img src="/img/posts/prometheus-metrics-menu.png" alt="prometheus metrics"></div>

<p>比如我们这里就选择<code>scrape_duration_seconds</code>这个指标，然后点击<code>Execute</code>，如果这个时候没有查询到任何数据，我们可以切换到<code>Graph</code>这个 tab 下面重新选择下时间，选择到当前的时间点，重新执行，就可以看到类似于下面的图表数据了： </p>
<div align="center"><img src="/img/posts/prometheus-metrics-graph.png" alt="prometheus graph"></div>

<p>除了简单的直接使用采集到的一些监控指标数据之外，这个时候也可以使用强大的 PromQL 工具，PromQL其实就是 prometheus 便于数据聚合展示开发的一套 ad hoc 查询语言的，你想要查什么找对应函数取你的数据好了。</p>
<h1 id="监控Kubernetes普通应用"><a href="#监控Kubernetes普通应用" class="headerlink" title="监控Kubernetes普通应用"></a>监控Kubernetes普通应用</h1><p>上面介绍了<code>Prometheus</code>的数据指标是通过一个公开的 HTTP(S) 数据接口获取到的，我们不需要单独安装监控的 agent，只需要暴露一个 metrics 接口，Prometheus 就会定期去拉取数据；对于一些普通的 HTTP 服务，我们完全可以直接重用这个服务，添加一个<code>/metrics</code>接口暴露给 Prometheus；而且获取到的指标数据格式是非常易懂的，不需要太高的学习成本。</p>
<p>现在很多服务从一开始就内置了一个<code>/metrics</code>接口，比如 Kubernetes 的各个组件、istio 服务网格都直接提供了数据指标接口。有一些服务即使没有原生集成该接口，也完全可以使用一些 exporter 来获取到指标数据，比如 mysqld_exporter、node_exporter，这些 exporter 就有点类似于传统监控服务中的 agent，作为一直服务存在，用来收集目标服务的指标数据然后直接暴露给 Prometheus。</p>
<p>前面我们已经和大家学习了 ingress 的使用，我们采用的是<code>Traefik</code>作为我们的 ingress-controller，是我们 Kubernetes 集群内部服务和外部用户之间的桥梁。Traefik 本身内置了一个<code>/metrics</code>的接口，但是需要我们在参数中配置开启:</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[metrics]</span><br><span class="line">  [metrics.prometheus]</span><br><span class="line">    entryPoint = <span class="string">"traefik"</span></span><br><span class="line">    buckets = [<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">1.2</span>, <span class="number">5.0</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>之前的版本中是通过<code>--web</code>和<code>--web.metrics.prometheus</code>两个参数进行开启的，要注意查看对应版本的文档。</p>
</blockquote>
<p>我们需要在<code>traefik.toml</code>的配置文件中添加上上面的配置信息，然后更新 ConfigMap 和 Pod 资源对象即可，Traefik Pod 运行后，我们可以看到我们的服务 IP：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="builtin-name">get</span> svc -n kube-system</span><br><span class="line">NAME                     <span class="built_in"> TYPE </span>       CLUSTER-IP       EXTERNAL-IP   PORT(S)                       AGE</span><br><span class="line"><span class="built_in">..</span><span class="built_in">..</span><span class="built_in">..</span></span><br><span class="line">traefik-ingress-service   NodePort    10.101.33.56     &lt;none&gt;        80:31692/TCP,8080:32115/TCP   63d</span><br></pre></td></tr></table></figure>
<p>然后我们可以使用<code>curl</code>检查是否开启了 Prometheus 指标数据接口，或者通过 NodePort 访问也可以：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ curl 10.101.33.56:8080/metrics</span><br><span class="line"><span class="comment"># HELP go_gc_duration_seconds A summary of the GC invocation durations.</span></span><br><span class="line"><span class="comment"># TYPE go_gc_duration_seconds summary</span></span><br><span class="line">go_gc_duration_seconds&#123;<span class="attribute">quantile</span>=<span class="string">"0"</span>&#125; 0.000121036</span><br><span class="line">go_gc_duration_seconds&#123;<span class="attribute">quantile</span>=<span class="string">"0.25"</span>&#125; 0.000210328</span><br><span class="line">go_gc_duration_seconds&#123;<span class="attribute">quantile</span>=<span class="string">"0.5"</span>&#125; 0.000279974</span><br><span class="line">go_gc_duration_seconds&#123;<span class="attribute">quantile</span>=<span class="string">"0.75"</span>&#125; 0.000420738</span><br><span class="line">go_gc_duration_seconds&#123;<span class="attribute">quantile</span>=<span class="string">"1"</span>&#125; 0.001191494</span><br><span class="line">go_gc_duration_seconds_sum 0.004353914</span><br><span class="line">go_gc_duration_seconds_count 12</span><br><span class="line"><span class="comment"># HELP go_goroutines Number of goroutines that currently exist.</span></span><br><span class="line"><span class="comment"># TYPE go_goroutines gauge</span></span><br><span class="line">go_goroutines 63</span><br><span class="line"><span class="built_in">..</span><span class="built_in">..</span><span class="built_in">..</span></span><br></pre></td></tr></table></figure>
<p>从这里可以看到 Traefik 的监控数据接口已经开启成功了，然后我们就可以将这个<code>/metrics</code>接口配置到<code>prometheus.yml</code>中去了，直接加到默认的<code>prometheus</code>这个 job 下面：(prome-cm.yaml)</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: ConfigMap</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: prometheus-config</span><br><span class="line">  <span class="attribute">namespace</span>: kube-ops</span><br><span class="line"><span class="attribute">data</span>:</span><br><span class="line">  prometheus.<span class="attribute">yml</span>: |</span><br><span class="line">    <span class="attribute">global</span>:</span><br><span class="line">      <span class="attribute">scrape_interval</span>: <span class="number">30s</span></span><br><span class="line">      <span class="attribute">scrape_timeout</span>: <span class="number">30s</span></span><br><span class="line"></span><br><span class="line">    <span class="attribute">scrape_configs</span>:</span><br><span class="line">    - <span class="attribute">job_name</span>: <span class="string">'prometheus'</span></span><br><span class="line">      <span class="attribute">static_configs</span>:</span><br><span class="line">        - <span class="attribute">targets</span>: [<span class="string">'localhost:9090'</span>]</span><br><span class="line"></span><br><span class="line">    - <span class="attribute">job_name</span>: <span class="string">'traefik'</span></span><br><span class="line">      <span class="attribute">static_configs</span>:</span><br><span class="line">        - <span class="attribute">targets</span>: [<span class="string">'traefik-ingress-service.kube-system.svc.cluster.local:8080'</span>]</span><br></pre></td></tr></table></figure>
<p>当然，我们这里只是一个很简单的配置，scrape_configs 下面可以支持很多参数，例如：</p>
<ul>
<li>basic_auth 和 bearer_token：比如我们提供的<code>/metrics</code>接口需要 basic 认证的时候，通过传统的用户名/密码或者在请求的header中添加对应的 token 都可以支持</li>
<li>kubernetes_sd_configs 或 consul_sd_configs：可以用来自动发现一些应用的监控数据</li>
</ul>
<p>由于我们这里 Traefik 对应的 servicename 是<code>traefik-ingress-service</code>，并且在 kube-system 这个 namespace 下面，所以我们这里的<code>targets</code>的路径配置则需要使用<code>FQDN</code>的形式：<code>traefik-ingress-service.kube-system.svc.cluster.local</code>，当然如果你的 Traefik 和 Prometheus 都部署在同一个命名空间的话，则直接填 <code>servicename:serviceport</code>即可。然后我们重新更新这个 ConfigMap 资源对象：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl delete -f prome-cm.yaml</span><br><span class="line">configmap <span class="string">"prometheus-config"</span> deleted</span><br><span class="line">$ kubectl create -f prome-cm.yaml</span><br><span class="line">configmap <span class="string">"prometheus-config"</span> created</span><br></pre></td></tr></table></figure>
<p>现在 Prometheus 的配置文件内容已经更改了，隔一会儿被挂载到 Pod 中的 prometheus.yml 文件也会更新，由于我们之前的 Prometheus 启动参数中添加了<code>--web.enable-lifecycle</code>参数，所以现在我们只需要执行一个 reload 命令即可让配置生效：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="builtin-name">get</span> svc -n kube-ops</span><br><span class="line">NAME        <span class="built_in"> TYPE </span>      CLUSTER-IP     EXTERNAL-IP   PORT(S)                          AGE</span><br><span class="line">prometheus   NodePort   10.102.74.90   &lt;none&gt;        9090:30358/TCP                   3d</span><br><span class="line">$ curl -X POST <span class="string">"http://10.102.74.90:9090/-/reload"</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>由于 ConfigMap 通过 Volume 的形式挂载到 Pod 中去的热更新需要一定的间隔时间才会生效，所以需要稍微等一小会儿。</p>
</blockquote>
<p>reload 这个 url 是一个 POST 请求，所以这里我们通过 service 的 CLUSTER-IP:PORT 就可以访问到这个重载的接口，这个时候我们再去看 Prometheus 的 Dashboard 中查看采集的目标数据：</p>
<div align="center"><img src="/img/posts/prometheus-dashboard-targets.png" alt="prometheus dashboard targets"></div>

<p>可以看到我们刚刚添加的<code>traefik</code>这个任务已经出现了，然后同样的我们可以切换到 Graph 下面去，我们可以找到一些 Traefik 的指标数据，至于这些指标数据代表什么意义，一般情况下，我们可以去查看对应的<code>/metrics</code>接口，里面一般情况下都会有对应的注释。</p>
<p>到这里我们就在 Prometheus 上配置了第一个 Kubernetes 应用。</p>
<h1 id="使用-exporter-监控应用"><a href="#使用-exporter-监控应用" class="headerlink" title="使用 exporter 监控应用"></a>使用 exporter 监控应用</h1><p>上面我们也说过有一些应用可能没有自带<code>/metrics</code>接口供 Prometheus 使用，在这种情况下，我们就需要利用 exporter 服务来为 Prometheus 提供指标数据了。Prometheus 官方为许多应用就提供了对应的 exporter 应用，也有许多第三方的实现，我们可以前往官方网站进行查看：<a href="https://prometheus.io/docs/instrumenting/exporters/" target="_blank" rel="noopener">exporters</a></p>
<p>比如我们这里通过一个<a href="https://github.com/oliver006/redis_exporter" target="_blank" rel="noopener">redis-exporter</a>的服务来监控 redis 服务，对于这类应用，我们一般会以 sidecar 的形式和主应用部署在同一个 Pod 中，比如我们这里来部署一个 redis 应用，并用 redis-exporter 的方式来采集监控数据供 Prometheus 使用，如下资源清单文件：（prome-redis.yaml）</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line">        <span class="string">prometheus.io/scrape:</span> <span class="string">"true"</span></span><br><span class="line">        <span class="string">prometheus.io/port:</span> <span class="string">"9121"</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">redis:4</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">100</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">6379</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">redis-exporter</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">oliver006/redis_exporter:latest</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">100</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">9121</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">redis</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">6379</span></span><br><span class="line"><span class="attr">    targetPort:</span> <span class="number">6379</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">prom</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">9121</span></span><br><span class="line"><span class="attr">    targetPort:</span> <span class="number">9121</span></span><br></pre></td></tr></table></figure>
<p>可以看到上面我们在 redis 这个 Pod 中包含了两个容器，一个就是 redis 本身的主应用，另外一个容器就是 redis_exporter。现在直接创建上面的应用：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f prome-redis.yaml</span><br><span class="line">deployment.extensions <span class="string">"redis"</span> created</span><br><span class="line">service <span class="string">"redis"</span> created</span><br></pre></td></tr></table></figure>
<p>创建完成后，我们可以看到 redis 的 Pod 里面包含有两个容器：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="builtin-name">get</span> pods -n kube-ops</span><br><span class="line">NAME                          READY     STATUS    RESTARTS   AGE</span><br><span class="line">prometheus-8566cd9699-gt9wh   1/1       Running   0          3d</span><br><span class="line">redis-544b6c8c54-8xd2g        2/2       Running   0          3m</span><br><span class="line">$ kubectl <span class="builtin-name">get</span> svc -n kube-ops</span><br><span class="line">NAME        <span class="built_in"> TYPE </span>       CLUSTER-IP      EXTERNAL-IP   PORT(S)                          AGE</span><br><span class="line">prometheus   NodePort    10.102.74.90    &lt;none&gt;        9090:30358/TCP                   3d</span><br><span class="line">redis        ClusterIP   10.104.131.44   &lt;none&gt;        6379/TCP,9121/TCP                5m</span><br></pre></td></tr></table></figure>
<p>我们可以通过 9121 端口来校验是否能够采集到数据：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ curl 10.104.131.44:9121/metrics</span><br><span class="line"><span class="comment"># HELP go_gc_duration_seconds A summary of the GC invocation durations.</span></span><br><span class="line"><span class="comment"># TYPE go_gc_duration_seconds summary</span></span><br><span class="line">go_gc_duration_seconds&#123;<span class="attribute">quantile</span>=<span class="string">"0"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds&#123;<span class="attribute">quantile</span>=<span class="string">"0.25"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds&#123;<span class="attribute">quantile</span>=<span class="string">"0.5"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds&#123;<span class="attribute">quantile</span>=<span class="string">"0.75"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds&#123;<span class="attribute">quantile</span>=<span class="string">"1"</span>&#125; 0</span><br><span class="line">go_gc_duration_seconds_sum 0</span><br><span class="line">go_gc_duration_seconds_count 0</span><br><span class="line"><span class="built_in">..</span><span class="built_in">..</span><span class="built_in">..</span></span><br><span class="line"><span class="comment"># HELP redis_used_cpu_user_children used_cpu_user_childrenmetric</span></span><br><span class="line"><span class="comment"># TYPE redis_used_cpu_user_children gauge</span></span><br><span class="line">redis_used_cpu_user_children&#123;<span class="attribute">addr</span>=<span class="string">"redis://localhost:6379"</span>,alias=""&#125; 0</span><br></pre></td></tr></table></figure>
<p>同样的，现在我们只需要更新 Prometheus 的配置文件：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- <span class="string">job_name:</span> <span class="string">'redis'</span></span><br><span class="line"><span class="symbol">  static_configs:</span></span><br><span class="line">  - <span class="string">targets:</span> [<span class="string">'redis:9121'</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>由于我们这里的 redis 服务和 Prometheus 处于同一个 namespace，所以我们直接使用 servicename 即可。</p>
</blockquote>
<p>配置文件更新后，重新加载：</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>kubectl delete -f prome-cm.yaml</span><br><span class="line">configmap <span class="string">"prometheus-config"</span> deleted</span><br><span class="line"><span class="variable">$ </span>kubectl create -f prome-cm.yaml</span><br><span class="line">configmap <span class="string">"prometheus-config"</span> created</span><br><span class="line"><span class="comment"># 隔一会儿执行reload操作</span></span><br><span class="line"><span class="variable">$ </span>curl -X POST <span class="string">"http://10.102.74.90:9090/-/reload"</span></span><br></pre></td></tr></table></figure>
<p>这个时候我们再去看 Prometheus 的 Dashboard 中查看采集的目标数据：</p>
<div align="center"><img src="/img/posts/prometheus-targets-redis.png" alt="prometheus targets redis"></div>

<p>可以看到配置的 redis 这个 job 已经生效了。切换到 Graph 下面可以看到很多关于 redis 的指标数据：</p>
<div align="center"><img src="/img/posts/redis-metrics.png" alt="redis metrics"></div>

<p>我们选择任意一个指标，比如<code>redis_exporter_scrapes_total</code>，然后点击执行就可以看到对应的数据图表了：</p>
<div align="center"><img src="/img/posts/redis-graph.png" alt="redis scrapes total"></div>

<blockquote>
<p>注意，如果时间有问题，我们需要手动在 Graph 下面调整下时间</p>
</blockquote>
<h1 id="监控Kubernetes集群节点"><a href="#监控Kubernetes集群节点" class="headerlink" title="监控Kubernetes集群节点"></a>监控Kubernetes集群节点</h1><p>对于集群的监控一般我们需要考虑以下几个方面：</p>
<ul>
<li>Kubernetes 节点的监控：比如节点的 cpu、load、disk、memory 等指标</li>
<li>内部系统组件的状态：比如 kube-scheduler、kube-controller-manager、kubedns/coredns 等组件的详细运行状态</li>
<li>编排级的 metrics：比如 Deployment 的状态、资源请求、调度和 API 延迟等数据指标</li>
</ul>
<h2 id="监控方案"><a href="#监控方案" class="headerlink" title="监控方案"></a>监控方案</h2><p>Kubernetes 集群的监控方案目前主要有以下集中方案：</p>
<ul>
<li>Heapster：Heapster 是一个集群范围的监控和数据聚合工具，以 Pod 的形式运行在集群中。<div align="center"><img src="/img/posts/kubernetes_monitoring_heapster.png" alt="heapster"></div>

</li>
</ul>
<p>除了 Kubelet/cAdvisor 之外，我们还可以向 Heapster 添加其他指标源数据，比如 kube-state-metrics，我们会在下面和大家讲解的</p>
<blockquote>
<p>需要注意的是 Heapster 已经被废弃了，后续版本中会使用 metrics-server 代替。</p>
</blockquote>
<ul>
<li>cAdvisor：<a href="https://github.com/google/cadvisor" target="_blank" rel="noopener">cAdvisor</a>是<code>Google</code>开源的容器资源监控和性能分析工具，它是专门为容器而生，本身也支持 Docker 容器，在 Kubernetes 中，我们不需要单独去安装，cAdvisor 作为 kubelet 内置的一部分程序可以直接使用。</li>
<li>Kube-state-metrics：<a href="https://github.com/kubernetes/kube-state-metrics" target="_blank" rel="noopener">kube-state-metrics</a>通过监听 API Server 生成有关资源对象的状态指标，比如 Deployment、Node、Pod，需要注意的是 kube-state-metrics 只是简单提供一个 metrics 数据，并不会存储这些指标数据，所以我们可以使用 Prometheus 来抓取这些数据然后存储。</li>
<li>metrics-server：metrics-server 也是一个集群范围内的资源数据聚合工具，是 Heapster 的替代品，同样的，metrics-server 也只是显示数据，并不提供数据存储服务。</li>
</ul>
<p>不过 kube-state-metrics 和 metrics-server 之间还是有很大不同的，二者的主要区别如下：</p>
<ul>
<li>kube-state-metrics 主要关注的是业务相关的一些元数据，比如 Deployment、Pod、副本状态等</li>
<li>metrics-server 主要关注的是<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/resource-metrics-api.md" target="_blank" rel="noopener">资源度量 API</a> 的实现，比如 CPU、文件描述符、内存、请求延时等指标。</li>
</ul>
<h2 id="监控集群节点"><a href="#监控集群节点" class="headerlink" title="监控集群节点"></a>监控集群节点</h2><p>现在我们就来开始我们集群的监控工作，首先来监控我们集群的节点，要监控节点其实我们已经有很多非常成熟的方案了，比如 Nagios、zabbix，甚至我们自己来收集数据也可以，我们这里通过 Prometheus 来采集节点的监控指标数据，可以通过<a href="https://github.com/prometheus/node_exporter" target="_blank" rel="noopener">node_exporter</a>来获取，顾名思义，node_exporter 抓哟就是用于采集服务器节点的各种运行指标的，目前 node_exporter 支持几乎所有常见的监控点，比如 conntrack，cpu，diskstats，filesystem，loadavg，meminfo，netstat等，详细的监控点列表可以参考其<a href="https://github.com/prometheus/node_exporter" target="_blank" rel="noopener">Github repo</a>。</p>
<p>我们可以通过 DaemonSet 控制器来部署该服务，这样每一个节点都会自动运行一个这样的 Pod，如果我们从集群中删除或者添加节点后，也会进行自动扩展。</p>
<p>在部署 node-exporter 的时候有一些细节需要注意，如下资源清单文件：(prome-node-exporter.yaml)</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">node-exporter</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">node-exporter</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">node-exporter</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      hostPID:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      hostIPC:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      hostNetwork:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">node-exporter</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">prom/node-exporter:v0.16.0</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">9100</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">0.15</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          privileged:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">        args:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="bullet">--path.procfs</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">/host/proc</span></span><br><span class="line"><span class="bullet">        -</span> <span class="bullet">--path.sysfs</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">/host/sys</span></span><br><span class="line"><span class="bullet">        -</span> <span class="bullet">--collector.filesystem.ignored-mount-points</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">'"^/(sys|proc|dev|host|etc)($|/)"'</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/host/dev</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">proc</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/host/proc</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">sys</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/host/sys</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">rootfs</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/rootfs</span></span><br><span class="line"><span class="attr">      tolerations:</span></span><br><span class="line"><span class="attr">      - key:</span> <span class="string">"node-role.kubernetes.io/master"</span></span><br><span class="line"><span class="attr">        operator:</span> <span class="string">"Exists"</span></span><br><span class="line"><span class="attr">        effect:</span> <span class="string">"NoSchedule"</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">proc</span></span><br><span class="line"><span class="attr">          hostPath:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/proc</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">          hostPath:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/dev</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">sys</span></span><br><span class="line"><span class="attr">          hostPath:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/sys</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">rootfs</span></span><br><span class="line"><span class="attr">          hostPath:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/</span></span><br></pre></td></tr></table></figure>
<p>由于我们要获取到的数据是主机的监控指标数据，而我们的 node-exporter 是运行在容器中的，所以我们在 Pod 中需要配置一些 Pod 的安全策略，这里我们就添加了<code>hostPID: true</code>、<code>hostIPC: true</code>、<code>hostNetwork: true</code>3个策略，用来使用主机的 PID namespace、IPC namespace 以及主机网络，这些 namespace 就是用于容器隔离的关键技术，要注意这里的 namespace 和集群中的 namespace 是两个完全不相同的概念。</p>
<p>另外我们还将主机的<code>/dev</code>、<code>/proc</code>、<code>/sys</code>这些目录挂载到容器中，这些因为我们采集的很多节点数据都是通过这些文件夹下面的文件来获取到的，比如我们在使用<code>top</code>命令可以查看当前<code>cpu</code>使用情况，数据就来源于文件<code>/proc/stat</code>，使用<code>free</code>命令可以查看当前内存使用情况，其数据来源是来自<code>/proc/meminfo</code>文件。</p>
<p>另外由于我们集群使用的是 kubeadm 搭建的，所以如果希望 master 节点也一起被监控，则需要添加响应的容忍，对于污点和容忍还不是很熟悉的同学可以在前面的章节中回顾下。</p>
<p>然后直接创建上面的资源对象即可：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f prome-node-exporter.yaml</span><br><span class="line">daemonset.extensions <span class="string">"node-exporter"</span> created</span><br><span class="line">$ kubectl get pods -n kube-ops -o wide</span><br><span class="line">NAME                          READY     STATUS    RESTARTS   AGE       IP             NODE</span><br><span class="line">node-exporter-jfwfv           <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          <span class="number">30</span>m       <span class="number">10.151</span><span class="number">.30</span><span class="number">.63</span>   node02</span><br><span class="line">node-exporter-kr8rt           <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          <span class="number">30</span>m       <span class="number">10.151</span><span class="number">.30</span><span class="number">.64</span>   node03</span><br><span class="line">node-exporter-whb7n           <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          <span class="number">20</span>m       <span class="number">10.151</span><span class="number">.30</span><span class="number">.57</span>   master</span><br><span class="line">prometheus<span class="number">-8566</span>cd9699-gt9wh   <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          <span class="number">4</span>d        <span class="number">10.244</span><span class="number">.4</span><span class="number">.39</span>    node02</span><br><span class="line">redis<span class="number">-544</span>b6c8c54<span class="number">-8</span>xd2g        <span class="number">2</span>/<span class="number">2</span>       Running   <span class="number">0</span>          <span class="number">23</span>h       <span class="number">10.244</span><span class="number">.2</span><span class="number">.87</span>    node03</span><br></pre></td></tr></table></figure>
<p>部署完成后，我们可以看到在3个节点上都运行了一个 Pod，有的同学可能会说我们这里不需要创建一个 Service 吗？我们应该怎样去获取<code>/metrics</code>数据呢？我们上面是不是指定了<code>hostNetwork=true</code>，所以在每个节点上就会绑定一个端口 9100，我们可以通过这个端口去获取到监控指标数据：</p>
<figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ curl <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">9100</span>/metrics</span><br><span class="line">...</span><br><span class="line">node_filesystem_device_error&#123;device=<span class="string">"shm"</span>,fstype=<span class="string">"tmpfs"</span>,mountpoint=<span class="string">"/rootfs/var/lib/docker/containers/aefe8b1b63c3aa5f27766053ec817415faf8f6f417bb210d266fef0c2da64674/shm"</span>&#125; <span class="number">1</span></span><br><span class="line">node_filesystem_device_error&#123;device=<span class="string">"shm"</span>,fstype=<span class="string">"tmpfs"</span>,mountpoint=<span class="string">"/rootfs/var/lib/docker/containers/c8652ca72230496038a07e4fe4ee47046abb5f88d9d2440f0c8a923d5f3e133c/shm"</span>&#125; <span class="number">1</span></span><br><span class="line">node_filesystem_device_error&#123;device=<span class="string">"tmpfs"</span>,fstype=<span class="string">"tmpfs"</span>,mountpoint=<span class="string">"/dev"</span>&#125; <span class="number">0</span></span><br><span class="line">node_filesystem_device_error&#123;device=<span class="string">"tmpfs"</span>,fstype=<span class="string">"tmpfs"</span>,mountpoint=<span class="string">"/dev/shm"</span>&#125; <span class="number">0</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>当然如果你觉得上面的手动安装方式比较麻烦，我们也可以使用 Helm 的方式来安装：</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ helm install --name <span class="keyword">node</span><span class="title">-exporter</span> stable/prometheus-<span class="keyword">node</span><span class="title">-exporter</span> --namespace kube-ops</span><br></pre></td></tr></table></figure>
<h2 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h2><p>由于我们这里3个节点上面都运行了 node-exporter 程序，如果我们通过一个 Service 来将数据收集到一起用静态配置的方式配置到 Prometheus 去中，就只会显示一条数据，我们得自己在指标数据中去过滤每个节点的数据，那么有没有一种方式可以让 Prometheus 去自动发现我们节点的 node-exporter 程序，并且按节点进行分组呢？是有的，就是我们前面和大家提到过的<strong>服务发现</strong>。</p>
<p>在 Kubernetes 下，Promethues 通过与 Kubernetes API 集成，目前主要支持5中服务发现模式，分别是：Node、Service、Pod、Endpoints、Ingress。</p>
<p>我们通过 kubectl 命令可以很方便的获取到当前集群中的所有节点信息：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get nodes</span><br><span class="line">NAME      STATUS    ROLES     AGE       VERSION</span><br><span class="line">master    Ready     master    <span class="number">165</span>d      v1<span class="number">.10</span><span class="number">.0</span></span><br><span class="line">node02    Ready     &lt;none&gt;    <span class="number">85</span>d       v1<span class="number">.10</span><span class="number">.0</span></span><br><span class="line">node03    Ready     &lt;none&gt;    <span class="number">145</span>d      v1<span class="number">.10</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>
<p>但是要让 Prometheus 也能够获取到当前集群中的所有节点信息的话，我们就需要利用 Node 的服务发现模式，同样的，在 prometheus.yml 文件中配置如下的 job 任务即可：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- <span class="string">job_name:</span> <span class="string">'kubernetes-nodes'</span></span><br><span class="line"><span class="symbol">  tls_config:</span></span><br><span class="line"><span class="symbol">    ca_file:</span> <span class="regexp">/var/</span>run<span class="regexp">/secrets/</span>kubernetes.io<span class="regexp">/serviceaccount/</span>ca.crt</span><br><span class="line"><span class="symbol">  bearer_token_file:</span> <span class="regexp">/var/</span>run<span class="regexp">/secrets/</span>kubernetes.io<span class="regexp">/serviceaccount/</span>token</span><br><span class="line"><span class="symbol">  kubernetes_sd_configs:</span></span><br><span class="line">  - <span class="string">role:</span> node</span><br></pre></td></tr></table></figure>
<p>通过指定<code>kubernetes_sd_configs</code>的模式为<code>node</code>，Prometheus 就会自动从 Kubernetes 中发现所有的 node 节点并作为当前 job 监控的目标实例，发现的节点<code>/metrics</code>接口是默认的 kubelet 的 HTTP 接口，另外这里还需要指定用于访问 Kubernetes API 的 ca 以及 token 文件路径，ca 证书和 token 文件都是 Pod 启动后集群自动注入到 Pod 中的文件。</p>
<p>prometheus 的 ConfigMap 更新完成后，同样的我们执行 reload 操作，让配置生效：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl delete -f prome-cm.yaml</span><br><span class="line">configmap <span class="string">"prometheus-config"</span> deleted</span><br><span class="line">$ kubectl create -f prome-cm.yaml</span><br><span class="line">configmap <span class="string">"prometheus-config"</span> created</span><br><span class="line"><span class="comment"># 隔一会儿再执行下面的 reload 操作</span></span><br><span class="line">$ kubectl <span class="builtin-name">get</span> svc -n kube-ops</span><br><span class="line">NAME           <span class="built_in"> TYPE </span>       CLUSTER-IP      EXTERNAL-IP   PORT(S)                          AGE</span><br><span class="line">prometheus      NodePort    10.102.74.90    &lt;none&gt;        9090:30358/TCP                   5d</span><br><span class="line"><span class="built_in">..</span><span class="built_in">..</span><span class="built_in">..</span></span><br><span class="line">$ curl -X POST <span class="string">"http://10.102.74.90:9090/-/reload"</span></span><br></pre></td></tr></table></figure>
<p>配置生效后，我们再去 prometheus 的 dashboard 中查看 Targets 是否能够正常抓取数据，访问<strong>任意节点IP:30358</strong>：</p>
<div align="center"><img src="/img/posts/prometheus-nodes-target.png" alt="prometheus nodes target"><br>prometheus nodes target</div>

<p>我们可以看到上面的<code>kubernetes-nodes</code>这个 job 任务已经自动发现了我们3个 node 节点，但是在获取数据的时候失败了，出现了类似于下面的错误信息：</p>
<figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Get http://10.151.30.57:10250/metrics: net/http: HTTP/1.x transport connection broken: malformed HTTP response "<span class="symbol">\x</span>15<span class="symbol">\x</span>03<span class="symbol">\x</span>01<span class="symbol">\x</span>00<span class="symbol">\x</span>02<span class="symbol">\x</span>02"</span><br></pre></td></tr></table></figure>
<p>这个是因为 prometheus 去发现 Node 模式的服务的时候，访问的端口默认是<strong>10250</strong>，而现在该端口下面已经没有了<code>/metrics</code>指标数据了，现在 kubelet 只读的数据接口统一通过<strong>10255</strong>端口进行暴露了，所以我们应该去替换掉这里的端口，但是我们是要替换成<strong>10255</strong>端口吗？不是的，因为我们是要去配置上面通过<code>node-exporter</code>抓取到的节点指标数据，而我们上面是不是指定了<code>hostNetwork=true</code>，所以在每个节点上就会绑定一个端口<strong>9100</strong>，所以我们应该将这里的<strong>10250</strong>替换成<strong>9100</strong>，但是应该怎样替换呢？</p>
<p>这里我们就需要使用到 Prometheus 提供的<code>relabel_configs</code>中的<code>replace</code>能力了，relabel 可以在 Prometheus 采集数据之前，通过Target 实例的 Metadata 信息，动态重新写入 Label 的值。除此之外，我们还能根据 Target 实例的 Metadata 信息选择是否采集或者忽略该 Target 实例。比如我们这里就可以去匹配<code>__address__</code>这个 Label 标签，然后替换掉其中的端口：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">- <span class="string">job_name:</span> <span class="string">'kubernetes-nodes'</span></span><br><span class="line"><span class="symbol">  tls_config:</span></span><br><span class="line"><span class="symbol">    ca_file:</span> <span class="regexp">/var/</span>run<span class="regexp">/secrets/</span>kubernetes.io<span class="regexp">/serviceaccount/</span>ca.crt</span><br><span class="line"><span class="symbol">  bearer_token_file:</span> <span class="regexp">/var/</span>run<span class="regexp">/secrets/</span>kubernetes.io<span class="regexp">/serviceaccount/</span>token</span><br><span class="line"><span class="symbol">  kubernetes_sd_configs:</span></span><br><span class="line">  - <span class="string">role:</span> node</span><br><span class="line"><span class="symbol">  relabel_configs:</span></span><br><span class="line">  - <span class="string">source_labels:</span> [__address__]</span><br><span class="line"><span class="symbol">    regex:</span> <span class="string">'(.*):10250'</span></span><br><span class="line"><span class="symbol">    replacement:</span> <span class="string">'$&#123;1&#125;:9100'</span></span><br><span class="line"><span class="symbol">    target_label:</span> __address__</span><br><span class="line"><span class="symbol">    action:</span> replace</span><br></pre></td></tr></table></figure>
<p>这里就是一个正则表达式，去匹配<code>__address__</code>，然后将 host 部分保留下来，port 替换成了<strong>9100</strong>，现在我们重新更新配置文件，执行 reload 操作，然后再去看 Prometheus 的 Dashboard 的 Targets 路径下面 kubernetes-nodes 这个 job 任务是否正常了：</p>
<div align="center"><img src="/img/posts/promethues-nodes-target2.png" alt="prometheus nodes target2"><br>prometheus nodes target2</div>

<p>我们可以看到现在已经正常了，但是还有一个问题就是我们采集的指标数据 Label 标签就只有一个节点的 hostname，这对于我们在进行监控分组分类查询的时候带来了很多不方便的地方，要是我们能够将集群中 Node 节点的 Label 标签也能获取到就很好了。</p>
<p>这里我们可以通过<code>labelmap</code>这个属性来将 Kubernetes 的 Label 标签添加为 Prometheus 的指标标签：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- job_name:</span> <span class="string">'kubernetes-nodes'</span></span><br><span class="line"><span class="attr">  tls_config:</span></span><br><span class="line"><span class="attr">    ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span></span><br><span class="line"><span class="attr">  bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span></span><br><span class="line"><span class="attr">  kubernetes_sd_configs:</span></span><br><span class="line"><span class="attr">  - role:</span> <span class="string">node</span></span><br><span class="line"><span class="attr">  relabel_configs:</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__address__]</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">'(.*):10250'</span></span><br><span class="line"><span class="attr">    replacement:</span> <span class="string">'$&#123;1&#125;:9100'</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">__address__</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">  - action:</span> <span class="string">labelmap</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span></span><br></pre></td></tr></table></figure>
<p>添加了一个 action 为<code>labelmap</code>，正则表达式是<code>__meta_kubernetes_node_label_(.+)</code>的配置，这里的意思就是表达式中匹配都的数据也添加到指标数据的 Label 标签中去。</p>
<p>对于 kubernetes_sd_configs 下面可用的标签如下： 可用元标签：</p>
<ul>
<li>__meta_kubernetes_node_name：节点对象的名称</li>
<li>__meta_kubernetes_node<em>label</em>：节点对象中的每个标签</li>
<li>__meta_kubernetes_node<em>annotation</em>：来自节点对象的每个注释</li>
<li>__meta_kubernetes_node<em>address</em>：每个节点地址类型的第一个地址（如果存在）</li>
</ul>
<blockquote>
<p>关于 kubernets_sd_configs 更多信息可以查看官方文档：<a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#" target="_blank" rel="noopener">kubernetes_sd_config</a></p>
</blockquote>
<p>另外由于 kubelet 也自带了一些监控指标数据，就上面我们提到的<strong>10255</strong>端口，所以我们这里也把 kubelet 的监控任务也一并配置上：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- job_name:</span> <span class="string">'kubernetes-nodes'</span></span><br><span class="line"><span class="attr">  tls_config:</span></span><br><span class="line"><span class="attr">    ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span></span><br><span class="line"><span class="attr">  bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span></span><br><span class="line"><span class="attr">  kubernetes_sd_configs:</span></span><br><span class="line"><span class="attr">  - role:</span> <span class="string">node</span></span><br><span class="line"><span class="attr">  relabel_configs:</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__address__]</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">'(.*):10250'</span></span><br><span class="line"><span class="attr">    replacement:</span> <span class="string">'$&#123;1&#125;:9100'</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">__address__</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">  - action:</span> <span class="string">labelmap</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- job_name:</span> <span class="string">'kubernetes-kubelet'</span></span><br><span class="line"><span class="attr">  tls_config:</span></span><br><span class="line"><span class="attr">    ca_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span></span><br><span class="line"><span class="attr">  bearer_token_file:</span> <span class="string">/var/run/secrets/kubernetes.io/serviceaccount/token</span></span><br><span class="line"><span class="attr">  kubernetes_sd_configs:</span></span><br><span class="line"><span class="attr">  - role:</span> <span class="string">node</span></span><br><span class="line"><span class="attr">  relabel_configs:</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__address__]</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">'(.*):10250'</span></span><br><span class="line"><span class="attr">    replacement:</span> <span class="string">'$&#123;1&#125;:10255'</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">__address__</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">  - action:</span> <span class="string">labelmap</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">__meta_kubernetes_node_label_(.+)</span></span><br></pre></td></tr></table></figure>
<p>现在我们再去更新下配置文件，执行 reload 操作，让配置生效，然后访问 Prometheus 的 Dashboard 查看 Targets 路径：</p>
<div align="center"><img src="/img/posts/prometheus-nodes-target2.png" alt="prometheus node targets"><br>prometheus node targets</div>

<p>现在可以看到我们上面添加的<code>kubernetes-kubelet</code>和<code>kubernetes-nodes</code>这两个 job 任务都已经配置成功了，而且二者的 Labels 标签都和集群的 node 节点标签保持一致了。</p>
<p>现在我们就可以切换到 Graph 路径下面查看采集的一些指标数据了，比如查询 node_load1 指标：</p>
<div align="center"><img src="/img/posts/prometheus-nodes-graph1.png" alt="prometheus nodes graph1"><br>prometheus nodes graph1</div>

<p>我们可以看到将3个 node 节点对应的 node_load1 指标数据都查询出来了，同样的，我们还可以使用 PromQL 语句来进行更复杂的一些聚合查询操作，还可以根据我们的 Labels 标签对指标数据进行聚合，比如我们这里只查询 node03 节点的数据，可以使用表达式<code>node_load1{instance=&quot;node03&quot;}</code>来进行查询：</p>
<div align="center"><img src="/img/posts/prometheus-nodes-graph2.png" alt="prometheus nodes graph2"><br>prometheus nodes graph2</div>

<p>到这里我们就把 Kubernetes 集群节点的使用 Prometheus 监控起来了，下节课我们再来和大家学习怎样监控 Pod 或者 Service 之类的资源对象。</p>
<h1 id="监控Kubernetes常用资源对象"><a href="#监控Kubernetes常用资源对象" class="headerlink" title="监控Kubernetes常用资源对象"></a>监控Kubernetes常用资源对象</h1><p>怎样在 Prometheus 中来自动监控 Kubernetes 中的一些常用资源对象。</p>
<p>前面我们和大家介绍过了在 Prometheus 中用静态的方式来监控 Kubernetes 集群中的普通应用，但是如果针对集群中众多的资源对象都采用静态的方式来进行配置的话显然是不现实的，所以同样我们需要使用到 Prometheus 提供的其他类型的服务发现机制。</p>
<h2 id="容器监控"><a href="#容器监控" class="headerlink" title="容器监控"></a>容器监控</h2><p>说到容器监控我们自然会想到<code>cAdvisor</code>，我们前面也说过<code>cAdvisor</code>已经内置在了 kubelet 组件之中，所以我们不需要单独去安装，<code>cAdvisor</code>的数据路径为<code>/api/v1/nodes/&lt;node&gt;/proxy/metrics</code>，同样我们这里使用 node 的服务发现模式，因为每一个节点下面都有 kubelet，自然都有<code>cAdvisor</code>采集到的数据指标，配置如下：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">- <span class="string">job_name:</span> <span class="string">'kubernetes-cadvisor'</span></span><br><span class="line"><span class="symbol">  kubernetes_sd_configs:</span></span><br><span class="line">  - <span class="string">role:</span> node</span><br><span class="line"><span class="symbol">  scheme:</span> https</span><br><span class="line"><span class="symbol">  tls_config:</span></span><br><span class="line"><span class="symbol">    ca_file:</span> <span class="regexp">/var/</span>run<span class="regexp">/secrets/</span>kubernetes.io<span class="regexp">/serviceaccount/</span>ca.crt</span><br><span class="line"><span class="symbol">  bearer_token_file:</span> <span class="regexp">/var/</span>run<span class="regexp">/secrets/</span>kubernetes.io<span class="regexp">/serviceaccount/</span>token</span><br><span class="line"><span class="symbol">  relabel_configs:</span></span><br><span class="line">  - <span class="string">action:</span> labelmap</span><br><span class="line"><span class="symbol">    regex:</span> __meta_kubernetes_node_label_(.+)</span><br><span class="line">  - <span class="string">target_label:</span> __address__</span><br><span class="line"><span class="symbol">    replacement:</span> kubernetes.<span class="keyword">default</span>.<span class="string">svc:</span><span class="number">443</span></span><br><span class="line">  - <span class="string">source_labels:</span> [__meta_kubernetes_node_name]</span><br><span class="line"><span class="symbol">    regex:</span> (.+)</span><br><span class="line"><span class="symbol">    target_label:</span> __metrics_path__</span><br><span class="line"><span class="symbol">    replacement:</span> <span class="regexp">/api/</span>v1<span class="regexp">/nodes/</span>$&#123;<span class="number">1</span>&#125;<span class="regexp">/proxy/</span>metrics/cadvisor</span><br></pre></td></tr></table></figure>
<p>上面的配置和我们之前配置 node-exporter 的时候几乎是一样的，区别是我们这里使用了 https 的协议，另外需要注意的是配置了 ca.cart 和 token 这两个文件，这两个文件是 Pod 启动后自动注入进来的，通过这两个文件我们可以在 Pod 中访问 apiserver，比如我们这里的<code>__address__</code>不在是 nodeip 了，而是 kubernetes 在集群中的服务地址，然后加上<code>__metrics_path__</code>的访问路径：<code>/api/v1/nodes/${1}/proxy/metrics/cadvisor</code>，现在同样更新下配置，然后查看 Targets 路径： </p>
<div align="center"><img src="/img/posts/prometheus-cadvisor.png" alt="prometheus cAdvisor"></div>

<p>然后我们可以切换到 Graph 路径下面查询容器相关数据，比如我们这里来查询集群中所有 Pod 的 CPU 使用情况，这里用的数据指标是 container_cpu_usage_seconds_total，然后去除一些无效的数据，查询1分钟内的数据，由于查询到的数据都是容器相关的，最好要安装 Pod 来进行聚合，对应的<code>promQL</code>语句如下：</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum by (<span class="name">pod_name</span>)(<span class="name">rate</span>(<span class="name">container_cpu_usage_seconds_total</span>&#123;image!=<span class="string">""</span>, pod_name!=<span class="string">""</span>&#125;[<span class="number">1</span>m] ))</span><br></pre></td></tr></table></figure>
<div align="center"><img src="/img/posts/prometheus-cadvisor-graph.png" alt="prometheus cadvisor graph"><br>prometheus cadvisor graph</div>

<p>我们可以看到上面的结果就是集群中的所有 Pod 在1分钟之内的 CPU 使用情况的曲线图，当然还有很多数据可以获取到，我们后面在需要的时候再和大家介绍。</p>
<h2 id="apiserver-监控"><a href="#apiserver-监控" class="headerlink" title="apiserver 监控"></a>apiserver 监控</h2><p>apiserver 作为 Kubernetes 最核心的组件，当然他的监控也是非常有必要的，对于 apiserver 的监控我们可以直接通过 kubernetes 的 Service 来获取：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="builtin-name">get</span> svc</span><br><span class="line">NAME           <span class="built_in"> TYPE </span>       CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">kubernetes      ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP    175d</span><br></pre></td></tr></table></figure>
<p>上面这个 Service 就是我们集群的 apiserver 在集群内部的 Service 地址，要自动发现 Service 类型的服务，我们就需要用到 role 为 Endpoints 的 kubernetes_sd_configs，我们可以在 ConfigMap 对象中添加上一个 Endpoints 类型的服务的监控任务：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- <span class="string">job_name:</span> <span class="string">'kubernetes-apiservers'</span></span><br><span class="line"><span class="symbol">  kubernetes_sd_configs:</span></span><br><span class="line">  - <span class="string">role:</span> endpoints</span><br></pre></td></tr></table></figure>
<p>上面这个任务是定义的一个类型为<code>endpoints</code>的<code>kubernetes_sd_configs</code>，添加到 Prometheus 的 ConfigMap 的配置文件中，然后更新配置：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl delete -f prome-cm.yaml</span><br><span class="line">$ kubectl create -f prome-cm.yaml</span><br><span class="line">$ # 隔一会儿执行reload操作</span><br><span class="line">$ kubectl <span class="builtin-name">get</span> svc -n kube-ops</span><br><span class="line">NAME        <span class="built_in"> TYPE </span>       CLUSTER-IP      EXTERNAL-IP   PORT(S)                          AGE</span><br><span class="line">prometheus   NodePort    10.102.74.90    &lt;none&gt;        9090:30358/TCP                   14d</span><br><span class="line">$ curl -X POST <span class="string">"http://10.102.74.90:9090/-/reload"</span></span><br></pre></td></tr></table></figure>
<p>更新完成后，我们再去查看 Prometheus 的 Dashboard 的 target 页面： </p>
<div align="center"><img src="/img/posts/prometheus-apiserver.png" alt="prometheus apiserver"></div>

<p>我们可以看到 kubernetes-apiservers 下面出现了很多实例，这是因为这里我们使用的是 Endpoints 类型的服务发现，所以 Prometheus 把所有的 Endpoints 服务都抓取过来了，同样的，上面我们需要的服务名为<code>kubernetes</code>这个 apiserver 的服务也在这个列表之中，那么我们应该怎样来过滤出这个服务来呢？还记得上节课的<code>relabel_configs</code>吗？没错，同样我们需要使用这个配置，只是我们这里不是使用<code>replace</code>这个动作了，而是<code>keep</code>，就是只把符合我们要求的给保留下来，哪些才是符合我们要求的呢？我们可以把鼠标放置在任意一个 target 上，可以查看到<code>Before relabeling</code>里面所有的元数据，比如我们要过滤的服务是 default 这个 namespace 下面，服务名为 kubernetes 的元数据，所以这里我们就可以根据对应的<code>__meta_kubernetes_namespace</code>和<code>__meta_kubernetes_service_name</code>这两个元数据来 relabel</p>
<div align="center"><img src="/img/posts/promtheus-before-label.png" alt="prometheus before lable"><br>prometheus before lable</div>

<p>另外由于 kubernetes 这个服务对应的端口是443，需要使用 https 协议，所以这里我们需要使用 https 的协议，对应的就需要将对应的 ca 证书配置上，如下：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- <span class="string">job_name:</span> <span class="string">'kubernetes-apiservers'</span></span><br><span class="line"><span class="symbol">  kubernetes_sd_configs:</span></span><br><span class="line">  - <span class="string">role:</span> endpoints</span><br><span class="line"><span class="symbol">  scheme:</span> https</span><br><span class="line"><span class="symbol">  tls_config:</span></span><br><span class="line"><span class="symbol">    ca_file:</span> <span class="regexp">/var/</span>run<span class="regexp">/secrets/</span>kubernetes.io<span class="regexp">/serviceaccount/</span>ca.crt</span><br><span class="line"><span class="symbol">  bearer_token_file:</span> <span class="regexp">/var/</span>run<span class="regexp">/secrets/</span>kubernetes.io<span class="regexp">/serviceaccount/</span>token</span><br><span class="line"><span class="symbol">  relabel_configs:</span></span><br><span class="line">  - <span class="string">source_labels:</span> [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]</span><br><span class="line"><span class="symbol">    action:</span> keep</span><br><span class="line"><span class="symbol">    regex:</span> <span class="keyword">default</span>;kubernetes;https</span><br></pre></td></tr></table></figure>
<p>现在重新更新配置文件、重新加载 Prometheus，切换到 Prometheus 的 Targets 路径下查看：</p>
<div align="center"><img src="/img/posts/prometheus-apiserver2.png" alt="promethues apiserver"><br>promethues apiserver</div>

<p>现在可以看到 kubernetes-apiserver 这个任务下面只有 apiserver 这一个实例了，证明我们的 relabel 是成功的，现在我们切换到 graph 路径下面查看下采集到数据，比如查询 apiserver 的总的请求数：</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(<span class="name">rate</span>(<span class="name">apiserver_request_count</span>[<span class="number">1</span>m]))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里我们使用到了 promql 里面的 rate 和 sum函数，表示的意思是 apiserver 在1分钟内总的请求数。</p>
</blockquote>
<div align="center"><img src="/img/posts/prometheus-apiserver-request.png" alt="apiserver request count"><br>apiserver request count</div>

<p>这样我们就完成了对 Kubernetes APIServer 的监控。</p>
<p>另外如果我们要来监控其他系统组件，比如 kube-controller-manager、kube-scheduler 的话应该怎么做呢？由于 apiserver 服务 namespace 在 default 使用默认的 Service kubernetes，而其余组件服务在 kube-system 这个 namespace 下面，如果我们想要来监控这些组件的话，需要手动创建单独的 Service，其中 kube-sheduler 的指标数据端口为 10251，kube-controller-manager 对应的端口为 10252，大家可以尝试下自己来配置下这几个系统组件。</p>
<h2 id="Service-的监控"><a href="#Service-的监控" class="headerlink" title="Service 的监控"></a>Service 的监控</h2><p>上面的 apiserver 实际上是一种特殊的 Service，现在我们同样来配置一个任务用来专门发现普通类型的 Service：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- job_name:</span> <span class="string">'kubernetes-service-endpoints'</span></span><br><span class="line"><span class="attr">  kubernetes_sd_configs:</span></span><br><span class="line"><span class="attr">  - role:</span> <span class="string">endpoints</span></span><br><span class="line"><span class="attr">  relabel_configs:</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__meta_kubernetes_service_annotation_prometheus_io_scrape]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">keep</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__meta_kubernetes_service_annotation_prometheus_io_scheme]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">__scheme__</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">(https?)</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__meta_kubernetes_service_annotation_prometheus_io_path]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">__metrics_path__</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">(.+)</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__address__,</span> <span class="string">__meta_kubernetes_service_annotation_prometheus_io_port]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">__address__</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">([^:]+)(?::\d+)?;(\d+)</span></span><br><span class="line"><span class="attr">    replacement:</span> <span class="string">$1:$2</span></span><br><span class="line"><span class="attr">  - action:</span> <span class="string">labelmap</span></span><br><span class="line"><span class="attr">    regex:</span> <span class="string">__meta_kubernetes_service_label_(.+)</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__meta_kubernetes_namespace]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">kubernetes_namespace</span></span><br><span class="line"><span class="attr">  - source_labels:</span> <span class="string">[__meta_kubernetes_service_name]</span></span><br><span class="line"><span class="attr">    action:</span> <span class="string">replace</span></span><br><span class="line"><span class="attr">    target_label:</span> <span class="string">kubernetes_name</span></span><br></pre></td></tr></table></figure>
<p>注意我们这里在<code>relabel_configs</code>区域做了大量的配置，特别是第一个保留<code>__meta_kubernetes_service_annotation_prometheus_io_scrape</code>为<code>true</code>的才保留下来，这就是说要想自动发现集群中的 Service，就需要我们在 Service 的<code>annotation</code>区域添加<code>prometheus.io/scrape=true</code>的声明，现在我们先将上面的配置更新，查看下效果：</p>
<div align="center"><img src="/img/posts/prometheus-service-endpoints.png" alt="service endpoints"><br>service endpoints</div>

<p>我们可以看到<code>kubernetes-service-endpoints</code>这一个任务下面只发现了一个服务，这是因为我们在<code>relabel_configs</code>中过滤了 annotation 有<code>prometheus.io/scrape=true</code>的 Service，而现在我们系统中只有这样一个服务符合要求，所以只出现了一个实例。</p>
<p>现在我们在之前创建的 redis 这个 Service 中添加上<code>prometheus.io/scrape=true</code>这个 annotation：(prome-redis-exporter.yaml)</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">kind</span>: Service</span><br><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: redis</span><br><span class="line">  <span class="attribute">namespace</span>: kube-ops</span><br><span class="line">  <span class="attribute">annotations</span>:</span><br><span class="line">    prometheus.io/<span class="attribute">scrape</span>: <span class="string">"true"</span></span><br><span class="line">    prometheus.io/<span class="attribute">port</span>: <span class="string">"9121"</span></span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">selector</span>:</span><br><span class="line">    <span class="attribute">app</span>: redis</span><br><span class="line">  <span class="attribute">ports</span>:</span><br><span class="line">  - <span class="attribute">name</span>: redis</span><br><span class="line">    <span class="attribute">port</span>: <span class="number">6379</span></span><br><span class="line">    <span class="attribute">targetPort</span>: <span class="number">6379</span></span><br><span class="line">  - <span class="attribute">name</span>: prom</span><br><span class="line">    <span class="attribute">port</span>: <span class="number">9121</span></span><br><span class="line">    <span class="attribute">targetPort</span>: <span class="number">9121</span></span><br></pre></td></tr></table></figure>
<p>由于 redis 服务的 metrics 接口在9121这个 redis-exporter 服务上面，所以我们还需要添加一个<code>prometheus.io/port=9121</code>这样的<code>annotations</code>，然后更新这个 Service：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f prome-redis-exporter.yaml</span><br><span class="line">deployment.extensions <span class="string">"redis"</span> unchanged</span><br><span class="line">service <span class="string">"redis"</span> changed</span><br></pre></td></tr></table></figure>
<p>更新完成后，去 Prometheus 查看 Targets 路径，可以看到 redis 服务自动出现在了<code>kubernetes-service-endpoints</code>这个任务下面：</p>
<div align="center"><img src="/img/posts/prometheus-service-endpoints2.png" alt="kubernetes service endpoints"><br>kubernetes service endpoints</div>

<p>这样以后我们有了新的服务，服务本身提供了<code>/metrics</code>接口，我们就完全不需要用静态的方式去配置了，到这里我们就可以将之前配置的 redis 的静态配置去掉了。</p>
<blockquote>
<p>大家可以尝试去将之前配置的 traefik 服务用动态发现的方式重新配置到上面的 service-endpoints 中。</p>
</blockquote>
<p>同样的，大家可以自己去尝试下去配置下自动发现 Pod、ingress 这些资源对象。</p>
<h2 id="kube-state-metrics"><a href="#kube-state-metrics" class="headerlink" title="kube-state-metrics"></a>kube-state-metrics</h2><p>上面我们配置了自动发现 Service（Pod也是一样的）的监控，但是这些监控数据都是应用内部的监控，需要应用本身提供一个<code>/metrics</code>接口，或者对应的 exporter 来暴露对应的指标数据，但是在 Kubernetes 集群上 Pod、DaemonSet、Deployment、Job、CronJob 等各种资源对象的状态也需要监控，这也反映了使用这些资源部署的应用的状态。但通过查看前面从集群中拉取的指标(这些指标主要来自 apiserver 和 kubelet 中集成的 cAdvisor)，并没有具体的各种资源对象的状态指标。对于 Prometheus 来说，当然是需要引入新的 exporter 来暴露这些指标，Kubernetes 提供了一个<a href="https://github.com/kubernetes/kube-state-metrics" target="_blank" rel="noopener">kube-state-metrics</a>就是我们需要的。</p>
<p>kube-state-metrics 已经给出了在 Kubernetes 部署的 manifest 定义文件，我们直接将代码 Clone 到集群中(能用 kubectl 工具操作就行):</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https:<span class="comment">//github.com/kubernetes/kube-state-metrics.git</span></span><br><span class="line">$ cd kube-state-metrics/kubernetes</span><br><span class="line">$ kubectl create -f .</span><br><span class="line">clusterrolebinding<span class="selector-class">.rbac</span><span class="selector-class">.authorization</span><span class="selector-class">.k8s</span><span class="selector-class">.io</span> <span class="string">"kube-state-metrics"</span> created</span><br><span class="line">clusterrole<span class="selector-class">.rbac</span><span class="selector-class">.authorization</span><span class="selector-class">.k8s</span><span class="selector-class">.io</span> <span class="string">"kube-state-metrics"</span> created</span><br><span class="line">deployment<span class="selector-class">.apps</span> <span class="string">"kube-state-metrics"</span> created</span><br><span class="line">rolebinding<span class="selector-class">.rbac</span><span class="selector-class">.authorization</span><span class="selector-class">.k8s</span><span class="selector-class">.io</span> <span class="string">"kube-state-metrics"</span> created</span><br><span class="line">role<span class="selector-class">.rbac</span><span class="selector-class">.authorization</span><span class="selector-class">.k8s</span><span class="selector-class">.io</span> <span class="string">"kube-state-metrics-resizer"</span> created</span><br><span class="line">serviceaccount <span class="string">"kube-state-metrics"</span> created</span><br><span class="line">service <span class="string">"kube-state-metrics"</span> created</span><br></pre></td></tr></table></figure>
<p>将 kube-state-metrics 部署到 Kubernetes 上之后，就会发现 Kubernetes 集群中的 Prometheus 会在kubernetes-service-endpoints 这个 job 下自动服务发现 kube-state-metrics，并开始拉取 metrics，这是因为部署 kube-state-metrics 的 manifest 定义文件 kube-state-metrics-service.yaml 对 Service 的定义包含<code>prometheus.io/scrape: &#39;true&#39;</code>这样的一个<code>annotation</code>，因此 kube-state-metrics 的 endpoint 可以被 Prometheus 自动服务发现。</p>
<p>关于 kube-state-metrics 暴露的所有监控指标可以参考 kube-state-metrics 的文档<a href="https://github.com/kubernetes/kube-state-metrics/tree/master/Documentation" target="_blank" rel="noopener">kube-state-metrics Documentation</a>。</p>
<hr>
<p>接下文：<a href="100120.html">kubernetes集群监控之 二.Prometheus Operator</a></p>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="/" target="_blank">Ljjyy.com</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/archives/2018/12/100120.html" class="pre-post btn btn-default" title='kubernetes集群监控之 二.Prometheus Operator'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">kubernetes集群监控之 二.Prometheus Operator</span>
        </a>
    
    
        <a href="/archives/2018/12/100109.html" class="next-post btn btn-default" title='Kubernetes服务质量Qos解析'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">Kubernetes服务质量Qos解析</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: '5MzTXYXkt03k101j0PmSDN34-gzGzoHsz',
            appKey: 'iwjYgwno6qj3wtDVVSbe8nYQ',
            placeholder: '说点什么吧',
            notify: false,
            verify: true,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#简介"><span class="toc-text">简介</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#特征"><span class="toc-text">特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#组件"><span class="toc-text">组件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#架构"><span class="toc-text">架构</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#安装"><span class="toc-text">安装</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#监控Kubernetes普通应用"><span class="toc-text">监控Kubernetes普通应用</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用-exporter-监控应用"><span class="toc-text">使用 exporter 监控应用</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#监控Kubernetes集群节点"><span class="toc-text">监控Kubernetes集群节点</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#监控方案"><span class="toc-text">监控方案</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#监控集群节点"><span class="toc-text">监控集群节点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#服务发现"><span class="toc-text">服务发现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#监控Kubernetes常用资源对象"><span class="toc-text">监控Kubernetes常用资源对象</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#容器监控"><span class="toc-text">容器监控</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#apiserver-监控"><span class="toc-text">apiserver 监控</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Service-的监控"><span class="toc-text">Service 的监控</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kube-state-metrics"><span class="toc-text">kube-state-metrics</span></a></li></ol></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2019-2024&emsp;<a href="/" class="copyright-links" target="_blank" rel="nofollow">Ljjyy.com</a>
                </span> |
                <span>
                    <a href="/about/" class="copyright-links" target="_blank" rel="nofollow">关于我们</a>
                </span> |                
                <span>
                    <a href="/sitemap.xml" class="copyright-links" target="_blank" rel="nofollow">网站地图</a>
                </span> |
                <span>
                    <a href="/archives/" class="copyright-links" target="_blank" rel="nofollow">时间轴</a>
                </span>              
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>